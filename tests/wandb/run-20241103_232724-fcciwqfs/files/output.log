
 step 2. noise scheduler and solver
 (1) teacher pipe
Loading pipeline components...:  83%|██████████████████████████████████████████████████████████████████████████████████████████████████▎                   | 5/6 [00:00<00:00,  6.26it/s]/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/transformers/models/clip/feature_extraction_clip.py:28: FutureWarning: The class CLIPFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use CLIPImageProcessor instead.
  warnings.warn(
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00,  7.66it/s]
 (2) student pipe
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00,  8.43it/s]
 (3.2) student model
 (3.3) sub models

 step 3. optimizer
It seems like you have activated model offloading by calling `enable_model_cpu_offload`, but are now manually moving the pipeline to GPU. It is strongly recommended against doing so as memory gains from offloading are likely to be lost. Offloading automatically takes care of moving the individual components vae, text_encoder, tokenizer, unet, motion_adapter, scheduler, feature_extractor, image_encoder to GPU when needed. To make sure offloading works as expected, you should consider moving the pipeline back to CPU: `pipeline.to('cpu')` or removing the move altogether if you use offloading.

 step 4. target unet
 step 5. weight and device
 final weight_dtype : torch.float16
 step 6. move to device
 step 7. Enable optimizations
loading annotations from /scratch2/dreamyou070/MyData/video/panda/test_sample_trimmed/sample.csv ...
Traceback (most recent call last):
  File "/home/dreamyou070/Prun/tests/sy.py", line 530, in <module>
    main(args)
  File "/home/dreamyou070/Prun/tests/sy.py", line 417, in main
    student_output = student_unet(noisy_model_input.to(dtype=student_unet.dtype),
  File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/accelerate/utils/operations.py", line 823, in forward
    return model_forward(*args, **kwargs)
  File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/accelerate/utils/operations.py", line 811, in __call__
    return convert_to_fp32(self.model_forward(*args, **kwargs))
  File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/torch/amp/autocast_mode.py", line 44, in decorate_autocast
    return func(*args, **kwargs)
  File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home/dreamyou070/Prun/src/prun/third_party/diffusers/src/diffusers/models/unets/unet_motion_model.py", line 1089, in forward
    sample, res_samples = downsample_block(
  File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/dreamyou070/Prun/src/prun/third_party/diffusers/src/diffusers/models/unets/unet_3d_blocks.py", line 1278, in forward
    hidden_states = motion_module(
  File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1844, in _call_impl
    return inner()
  File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1803, in inner
    hook_result = hook(self, args, result)
  File "/home/dreamyou070/Prun/tests/sy.py", line 245, in hook_fn_student
    inputs_student.append(input.detach())  # Student 모델의 입력
AttributeError: 'tuple' object has no attribute 'detach'
Traceback (most recent call last):
  File "/home/dreamyou070/Prun/tests/sy.py", line 530, in <module>
    main(args)
  File "/home/dreamyou070/Prun/tests/sy.py", line 417, in main
    student_output = student_unet(noisy_model_input.to(dtype=student_unet.dtype),
  File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/accelerate/utils/operations.py", line 823, in forward
    return model_forward(*args, **kwargs)
  File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/accelerate/utils/operations.py", line 811, in __call__
    return convert_to_fp32(self.model_forward(*args, **kwargs))
  File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/torch/amp/autocast_mode.py", line 44, in decorate_autocast
    return func(*args, **kwargs)
  File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home/dreamyou070/Prun/src/prun/third_party/diffusers/src/diffusers/models/unets/unet_motion_model.py", line 1089, in forward
    sample, res_samples = downsample_block(
  File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/dreamyou070/Prun/src/prun/third_party/diffusers/src/diffusers/models/unets/unet_3d_blocks.py", line 1278, in forward
    hidden_states = motion_module(
  File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1844, in _call_impl
    return inner()
  File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1803, in inner
    hook_result = hook(self, args, result)
  File "/home/dreamyou070/Prun/tests/sy.py", line 245, in hook_fn_student
    inputs_student.append(input.detach())  # Student 모델의 입력
AttributeError: 'tuple' object has no attribute 'detach'
