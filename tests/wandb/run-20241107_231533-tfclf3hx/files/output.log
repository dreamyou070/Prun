 step 3. weight and device

 step 4. noise scheduler and solver

 step 5. model and pipe
 (1) teacher pipe
Loading pipeline components...:  83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                    | 5/6 [00:02<00:00,  1.54it/s]/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/transformers/models/clip/feature_extraction_clip.py:28: FutureWarning: The class CLIPFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use CLIPImageProcessor instead.
  warnings.warn(
Loading pipeline components...: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:02<00:00,  2.43it/s]
 (2) student pipe
Loading pipeline components...: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:02<00:00,  2.88it/s]
final_name = down_blocks_2_motion_modules_1 in skip_layers
setting simple attention
final_name = down_blocks_3_motion_modules_0 in skip_layers
setting simple attention
final_name = down_blocks_3_motion_modules_1 in skip_layers
setting simple attention
final_name = up_blocks_0_motion_modules_0 in skip_layers
setting simple attention
final_name = up_blocks_0_motion_modules_1 in skip_layers
setting simple attention
final_name = up_blocks_0_motion_modules_2 in skip_layers
setting simple attention
final_name = up_blocks_1_motion_modules_0 in skip_layers
setting simple attention
final_name = up_blocks_2_motion_modules_0 in skip_layers
setting simple attention
final_name = up_blocks_3_motion_modules_1 in skip_layers
setting simple attention
final_name = up_blocks_3_motion_modules_2 in skip_layers
setting simple attention
final_name = mid_block_motion_modules_0 in skip_layers
setting simple attention
 (3) sub models

 step 4. optimizer
 step 5. make dataloader
loading annotations from /scratch2/dreamyou070/MyData/video/openvid_1M_sample.csv ...
 step 7. accelerator prepare
 ***** student_unet gradient checkpointing *****
 step 8. train
  0%|                                                                                                                                                                                                                                                               | 0/50000 [00:00<?, ?it/s]/home/dreamyou070/Prun/tests/distill_with_simple_only_transformer_cal.py:457: UserWarning: Using a target size (torch.Size([16, 1280, 16, 16])) that is different to the input size (torch.Size([16, 1280, 8, 8])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
window_x shape: torch.Size([256, 8, 1280])
window_x shape: torch.Size([256, 8, 1280])
window_x shape: torch.Size([64, 4, 1280])
window_x shape: torch.Size([64, 4, 1280])
window_x shape: torch.Size([64, 4, 1280])
window_x shape: torch.Size([64, 4, 1280])
window_x shape: torch.Size([64, 4, 1280])
window_x shape: torch.Size([64, 4, 1280])
window_x shape: torch.Size([64, 4, 1280])
window_x shape: torch.Size([64, 4, 1280])
window_x shape: torch.Size([64, 4, 1280])
window_x shape: torch.Size([64, 4, 1280])
window_x shape: torch.Size([64, 4, 1280])
window_x shape: torch.Size([64, 4, 1280])
window_x shape: torch.Size([64, 4, 1280])
window_x shape: torch.Size([64, 4, 1280])
window_x shape: torch.Size([64, 4, 1280])
window_x shape: torch.Size([64, 4, 1280])
window_x shape: torch.Size([64, 4, 1280])
window_x shape: torch.Size([64, 4, 1280])
window_x shape: torch.Size([64, 4, 1280])
window_x shape: torch.Size([64, 4, 1280])
window_x shape: torch.Size([64, 4, 1280])
window_x shape: torch.Size([64, 4, 1280])
window_x shape: torch.Size([64, 4, 1280])
window_x shape: torch.Size([64, 4, 1280])
window_x shape: torch.Size([256, 8, 1280])
window_x shape: torch.Size([256, 8, 1280])
window_x shape: torch.Size([1024, 16, 640])
window_x shape: torch.Size([4096, 16, 320])
window_x shape: torch.Size([4096, 16, 320])
  feature_loss += F.mse_loss(teacher_value.float(), student_value.float()).mean()  # MSE 손실 계산
Traceback (most recent call last):
  File "/home/dreamyou070/Prun/tests/distill_with_simple_only_transformer_cal.py", line 584, in <module>
    main(args)
  File "/home/dreamyou070/Prun/tests/distill_with_simple_only_transformer_cal.py", line 457, in main
    feature_loss += F.mse_loss(teacher_value.float(), student_value.float()).mean()  # MSE 손실 계산
  File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/torch/nn/functional.py", line 3791, in mse_loss
    expanded_input, expanded_target = torch.broadcast_tensors(input, target)
  File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/torch/functional.py", line 76, in broadcast_tensors
    return _VF.broadcast_tensors(tensors)  # type: ignore[attr-defined]
RuntimeError: The size of tensor a (8) must match the size of tensor b (16) at non-singleton dimension 3
[rank0]: Traceback (most recent call last):
[rank0]:   File "/home/dreamyou070/Prun/tests/distill_with_simple_only_transformer_cal.py", line 584, in <module>
[rank0]:     main(args)
[rank0]:   File "/home/dreamyou070/Prun/tests/distill_with_simple_only_transformer_cal.py", line 457, in main
[rank0]:     feature_loss += F.mse_loss(teacher_value.float(), student_value.float()).mean()  # MSE 손실 계산
[rank0]:   File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/torch/nn/functional.py", line 3791, in mse_loss
[rank0]:     expanded_input, expanded_target = torch.broadcast_tensors(input, target)
[rank0]:   File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/torch/functional.py", line 76, in broadcast_tensors
[rank0]:     return _VF.broadcast_tensors(tensors)  # type: ignore[attr-defined]
[rank0]: RuntimeError: The size of tensor a (8) must match the size of tensor b (16) at non-singleton dimension 3
