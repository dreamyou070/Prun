
 step 2. noise scheduler and solver
 (1) teacher pipe
Loading pipeline components...:  33%|███████████████████████████████████████▎                                                                              | 2/6 [00:00<00:00,  4.30it/s]/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/transformers/models/clip/feature_extraction_clip.py:28: FutureWarning: The class CLIPFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use CLIPImageProcessor instead.
  warnings.warn(
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:01<00:00,  4.27it/s]
 (2) student pipe
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:01<00:00,  5.10it/s]
 (3.2) student model
 (3.3) sub models

 step 3. optimizer
It seems like you have activated model offloading by calling `enable_model_cpu_offload`, but are now manually moving the pipeline to GPU. It is strongly recommended against doing so as memory gains from offloading are likely to be lost. Offloading automatically takes care of moving the individual components vae, text_encoder, tokenizer, unet, motion_adapter, scheduler, feature_extractor, image_encoder to GPU when needed. To make sure offloading works as expected, you should consider moving the pipeline back to CPU: `pipeline.to('cpu')` or removing the move altogether if you use offloading.

 step 4. target unet
 step 5. weight and device
 final weight_dtype : torch.float16
 step 6. move to device
 step 7. Enable optimizations
loading annotations from /scratch2/dreamyou070/MyData/video/panda/test_sample_trimmed/sample.csv ...
/home/dreamyou070/Prun/tests/distill.py:408: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()
Traceback (most recent call last):
  File "/home/dreamyou070/Prun/tests/distill.py", line 585, in <module>
    main(args)
  File "/home/dreamyou070/Prun/tests/distill.py", line 487, in main
    accelerator.clip_grad_norm_(trainable_params, args.max_grad_norm)
  File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/accelerate/accelerator.py", line 2391, in clip_grad_norm_
    self.unscale_gradients()
  File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/accelerate/accelerator.py", line 2335, in unscale_gradients
    self.scaler.unscale_(opt)
  File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/torch/amp/grad_scaler.py", line 322, in unscale_
    self._check_scale_growth_tracker("unscale_")
  File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/torch/amp/grad_scaler.py", line 158, in _check_scale_growth_tracker
    assert self._scale is not None, (
AssertionError: Attempted unscale_ but _scale is None.  This may indicate your script did not use scaler.scale(loss or outputs) earlier in the iteration.
[rank0]: Traceback (most recent call last):
[rank0]:   File "/home/dreamyou070/Prun/tests/distill.py", line 585, in <module>
[rank0]:     main(args)
[rank0]:   File "/home/dreamyou070/Prun/tests/distill.py", line 487, in main
[rank0]:     accelerator.clip_grad_norm_(trainable_params, args.max_grad_norm)
[rank0]:   File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/accelerate/accelerator.py", line 2391, in clip_grad_norm_
[rank0]:     self.unscale_gradients()
[rank0]:   File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/accelerate/accelerator.py", line 2335, in unscale_gradients
[rank0]:     self.scaler.unscale_(opt)
[rank0]:   File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/torch/amp/grad_scaler.py", line 322, in unscale_
[rank0]:     self._check_scale_growth_tracker("unscale_")
[rank0]:   File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/torch/amp/grad_scaler.py", line 158, in _check_scale_growth_tracker
[rank0]:     assert self._scale is not None, (
[rank0]: AssertionError: Attempted unscale_ but _scale is None.  This may indicate your script did not use scaler.scale(loss or outputs) earlier in the iteration.
