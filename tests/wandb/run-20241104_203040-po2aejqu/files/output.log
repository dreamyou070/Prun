
 step 2. noise scheduler and solver
 (1) teacher pipe
Loading pipeline components...:  33%|█████████████████████████████████████████████████████████████████████████▎                                                                                                                                                  | 2/6 [00:00<00:01,  3.49it/s]/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/transformers/models/clip/feature_extraction_clip.py:28: FutureWarning: The class CLIPFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use CLIPImageProcessor instead.
  warnings.warn(
Loading pipeline components...: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:03<00:00,  1.69it/s]
 (2) student pipe
Loading pipeline components...: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:02<00:00,  2.46it/s]
 (3.2) student model
 (3.3) sub models

 step 3. optimizer
It seems like you have activated model offloading by calling `enable_model_cpu_offload`, but are now manually moving the pipeline to GPU. It is strongly recommended against doing so as memory gains from offloading are likely to be lost. Offloading automatically takes care of moving the individual components vae, text_encoder, tokenizer, unet, motion_adapter, scheduler, feature_extractor, image_encoder to GPU when needed. To make sure offloading works as expected, you should consider moving the pipeline back to CPU: `pipeline.to('cpu')` or removing the move altogether if you use offloading.

 step 4. target unet
 step 5. weight and device
 final weight_dtype : torch.float32
 step 6. move to device
 step 7. Enable optimizations
loading annotations from /scratch2/dreamyou070/MyData/video/openvid_1M/sample.csv ...
/home/dreamyou070/Prun/tests/distill.py:408: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()
Steps:   0%|                                                                                                                                                                                                                                                         | 0/50000 [00:00<?, ?it/s]Traceback (most recent call last):
  File "/home/dreamyou070/Prun/tests/distill.py", line 608, in <module>
    main(args)
  File "/home/dreamyou070/Prun/tests/distill.py", line 417, in main
    for step, batch in enumerate(train_dataloader):
  File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/accelerate/data_loader.py", line 552, in __iter__
    current_batch = next(dataloader_iter)
  File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
    data = self._next_data()
  File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1448, in _next_data
    idx, data = self._get_data()
  File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1412, in _get_data
    success, data = self._try_get_data()
  File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1243, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
  File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/multiprocessing/connection.py", line 424, in _poll
    r = wait([self], timeout)
  File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
KeyboardInterrupt
[rank0]: Traceback (most recent call last):
[rank0]:   File "/home/dreamyou070/Prun/tests/distill.py", line 608, in <module>
[rank0]:     main(args)
[rank0]:   File "/home/dreamyou070/Prun/tests/distill.py", line 417, in main
[rank0]:     for step, batch in enumerate(train_dataloader):
[rank0]:   File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/accelerate/data_loader.py", line 552, in __iter__
[rank0]:     current_batch = next(dataloader_iter)
[rank0]:   File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
[rank0]:     data = self._next_data()
[rank0]:   File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1448, in _next_data
[rank0]:     idx, data = self._get_data()
[rank0]:   File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1412, in _get_data
[rank0]:     success, data = self._try_get_data()
[rank0]:   File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1243, in _try_get_data
[rank0]:     data = self._data_queue.get(timeout=timeout)
[rank0]:   File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/multiprocessing/queues.py", line 113, in get
[rank0]:     if not self._poll(timeout):
[rank0]:   File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/multiprocessing/connection.py", line 257, in poll
[rank0]:     return self._poll(timeout)
[rank0]:   File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/multiprocessing/connection.py", line 424, in _poll
[rank0]:     r = wait([self], timeout)
[rank0]:   File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/multiprocessing/connection.py", line 931, in wait
[rank0]:     ready = selector.select(timeout)
[rank0]:   File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/selectors.py", line 416, in select
[rank0]:     fd_event_list = self._selector.poll(timeout)
[rank0]: KeyboardInterrupt
