
 step 2. noise scheduler and solver
 (1) teacher pipe
Loading pipeline components...:  17%|████████████████████████████████████▋                                                                                                                                                                                       | 1/6 [00:00<00:02,  2.28it/s]/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/transformers/models/clip/feature_extraction_clip.py:28: FutureWarning: The class CLIPFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use CLIPImageProcessor instead.
  warnings.warn(
Loading pipeline components...: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:02<00:00,  2.58it/s]
 (2) student pipe
Loading pipeline components...: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:01<00:00,  3.40it/s]
skip_layers : ['down_blocks_2_motion_modules_1', 'down_blocks_3_motion_modules_1', 'mid_block_motion_modules_0', 'up_blocks_0_motion_modules_0', 'up_blocks_0_motion_modules_1', 'up_blocks_0_motion_modules_2', 'up_blocks_1_motion_modules_0', 'up_blocks_1_motion_modules_1', 'up_blocks_2_motion_modules_2', 'up_blocks_3_motion_modules_0', 'up_blocks_3_motion_modules_1']
final_name = down_blocks_2_motion_modules_1 in skip_layers
setting simple attention
final_name = down_blocks_3_motion_modules_1 in skip_layers
setting simple attention
final_name = up_blocks_0_motion_modules_0 in skip_layers
setting simple attention
final_name = up_blocks_0_motion_modules_1 in skip_layers
setting simple attention
final_name = up_blocks_0_motion_modules_2 in skip_layers
setting simple attention
final_name = up_blocks_1_motion_modules_0 in skip_layers
setting simple attention
final_name = up_blocks_1_motion_modules_1 in skip_layers
setting simple attention
final_name = up_blocks_2_motion_modules_2 in skip_layers
setting simple attention
final_name = up_blocks_3_motion_modules_0 in skip_layers
setting simple attention
final_name = up_blocks_3_motion_modules_1 in skip_layers
setting simple attention
final_name = mid_block_motion_modules_0 in skip_layers
setting simple attention
 (3.2) student model
 (3.3) sub models

 step 3. optimizer
It seems like you have activated model offloading by calling `enable_model_cpu_offload`, but are now manually moving the pipeline to GPU. It is strongly recommended against doing so as memory gains from offloading are likely to be lost. Offloading automatically takes care of moving the individual components vae, text_encoder, tokenizer, unet, motion_adapter, scheduler, feature_extractor, image_encoder to GPU when needed. To make sure offloading works as expected, you should consider moving the pipeline back to CPU: `pipeline.to('cpu')` or removing the move altogether if you use offloading.

 step 4. target unet
 step 5. weight and device
 final weight_dtype : torch.float32
 step 6. move to device
 step 7. Enable optimizations
loading annotations from /scratch2/dreamyou070/MyData/video/panda/test_sample_trimmed/sample.csv ...
/home/dreamyou070/Prun/tests/distill.py:408: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()
Steps:   0%|                                                                                                                                                                                                                                                         | 0/50000 [00:00<?, ?it/s]/home/dreamyou070/Prun/tests/distill.py:482: UserWarning: Using a target size (torch.Size([16, 1280, 8, 8])) that is different to the input size (torch.Size([16, 1280, 16, 16])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  feature_loss += F.mse_loss(teacher_value, student_value).mean()  # MSE 손실 계산
Traceback (most recent call last):
  File "/home/dreamyou070/Prun/tests/distill.py", line 639, in <module>
    main(args)
  File "/home/dreamyou070/Prun/tests/distill.py", line 482, in main
    feature_loss += F.mse_loss(teacher_value, student_value).mean()  # MSE 손실 계산
  File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/torch/nn/functional.py", line 3791, in mse_loss
    expanded_input, expanded_target = torch.broadcast_tensors(input, target)
  File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/torch/functional.py", line 76, in broadcast_tensors
    return _VF.broadcast_tensors(tensors)  # type: ignore[attr-defined]
RuntimeError: The size of tensor a (16) must match the size of tensor b (8) at non-singleton dimension 3
[rank0]: Traceback (most recent call last):
[rank0]:   File "/home/dreamyou070/Prun/tests/distill.py", line 639, in <module>
[rank0]:     main(args)
[rank0]:   File "/home/dreamyou070/Prun/tests/distill.py", line 482, in main
[rank0]:     feature_loss += F.mse_loss(teacher_value, student_value).mean()  # MSE 손실 계산
[rank0]:   File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/torch/nn/functional.py", line 3791, in mse_loss
[rank0]:     expanded_input, expanded_target = torch.broadcast_tensors(input, target)
[rank0]:   File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/torch/functional.py", line 76, in broadcast_tensors
[rank0]:     return _VF.broadcast_tensors(tensors)  # type: ignore[attr-defined]
[rank0]: RuntimeError: The size of tensor a (16) must match the size of tensor b (8) at non-singleton dimension 3
