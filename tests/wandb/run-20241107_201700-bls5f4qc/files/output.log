 step 3. weight and device

 step 4. noise scheduler and solver

 step 5. model and pipe
 (1) teacher pipe
Loading pipeline components...:  33%|███▎      | 2/6 [00:02<00:05,  1.30s/it]/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/transformers/models/clip/feature_extraction_clip.py:28: FutureWarning: The class CLIPFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use CLIPImageProcessor instead.
  warnings.warn(
Loading pipeline components...: 100%|██████████| 6/6 [00:03<00:00,  1.86it/s]
 (2) student pipe
Loading pipeline components...: 100%|██████████| 6/6 [00:02<00:00,  2.18it/s]
final_name = down_blocks_2_motion_modules_1 in skip_layers
setting simple attention
final_name = down_blocks_3_motion_modules_0 in skip_layers
setting simple attention
final_name = down_blocks_3_motion_modules_1 in skip_layers
setting simple attention
final_name = up_blocks_0_motion_modules_0 in skip_layers
setting simple attention
final_name = up_blocks_0_motion_modules_1 in skip_layers
setting simple attention
final_name = up_blocks_0_motion_modules_2 in skip_layers
setting simple attention
final_name = up_blocks_1_motion_modules_0 in skip_layers
setting simple attention
final_name = up_blocks_2_motion_modules_0 in skip_layers
setting simple attention
final_name = up_blocks_3_motion_modules_1 in skip_layers
setting simple attention
final_name = up_blocks_3_motion_modules_2 in skip_layers
setting simple attention
final_name = mid_block_motion_modules_0 in skip_layers
setting simple attention
 (3) sub models

 step 4. optimizer
 step 5. make dataloader
loading annotations from /scratch2/dreamyou070/MyData/video/openvid_1M_sample.csv ...
 step 7. accelerator prepare
 ***** student_unet gradient checkpointing *****
 step 8. train
  0%|          | 1/50000 [00:06<89:37:11,  6.45s/it]wandb: WARNING Tried to log to step -1 that is less than the current step 0. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
 [main process] total_loss = 2.476613998413086 device = cuda:0
 main process, lr step
[2024-11-07 20:17:39,008] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Warning: The cache directory for DeepSpeed Triton autotune, /home/dreamyou070/.triton/autotune, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
 -- trained model save --
100%|██████████| 6/6 [00:05<00:00,  1.12it/s]
100%|██████████| 6/6 [00:07<00:00,  1.17s/it]
100%|██████████| 6/6 [00:06<00:00,  1.13s/it]
100%|██████████| 6/6 [00:08<00:00,  1.41s/it]
100%|██████████| 6/6 [00:06<00:00,  1.06s/it]
 17%|█▋        | 1/6 [00:03<00:15,  3.00s/it]
Traceback (most recent call last):  2.45s/it]
  File "/home/dreamyou070/Prun/tests/distill_with_simple_transformer.py", line 519, in <module>
    main(args)
  File "/home/dreamyou070/Prun/tests/distill_with_simple_transformer.py", line 441, in main
    evaluation(prompt,
  File "/home/dreamyou070/Prun/tests/distill_with_simple_transformer.py", line 140, in evaluation
    output = evaluation_pipe(prompt=prompt,
  File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/dreamyou070/Prun/src/prun/third_party/diffusers/src/diffusers/pipelines/animatediff/pipeline_animatediff.py", line 807, in __call__
    noise_pred = self.unet(latent_model_input,
  File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/home/dreamyou070/Prun/src/prun/third_party/diffusers/src/diffusers/models/unets/unet_motion_model.py", line 1150, in forward
    sample = upsample_block(
  File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/dreamyou070/Prun/src/prun/third_party/diffusers/src/diffusers/models/unets/unet_3d_blocks.py", line 1485, in forward
    hidden_states = attn(
  File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/dreamyou070/Prun/src/prun/third_party/diffusers/src/diffusers/models/transformers/transformer_2d.py", line 442, in forward
    hidden_states = block(
  File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/dreamyou070/Prun/src/prun/third_party/diffusers/src/diffusers/models/attention.py", line 519, in forward
    ff_output = self.ff(norm_hidden_states)
  File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/dreamyou070/Prun/src/prun/third_party/diffusers/src/diffusers/models/attention.py", line 840, in forward
    hidden_states = module(hidden_states)
  File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/dreamyou070/Prun/src/prun/third_party/diffusers/src/diffusers/models/activations.py", line 117, in forward
    hidden_states = self.proj(hidden_states)
  File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/peft/tuners/lora/layer.py", line 584, in forward
    result = result + lora_B(lora_A(dropout(x))) * scaling
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 640.00 MiB. GPU 0 has a total capacity of 79.26 GiB of which 523.62 MiB is free. Process 1937784 has 5.43 GiB memory in use. Process 1937783 has 17.49 GiB memory in use. Including non-PyTorch memory, this process has 55.81 GiB memory in use. Of the allocated memory 54.54 GiB is allocated by PyTorch, and 775.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]: Traceback (most recent call last):
[rank0]:   File "/home/dreamyou070/Prun/tests/distill_with_simple_transformer.py", line 519, in <module>
[rank0]:     main(args)
[rank0]:   File "/home/dreamyou070/Prun/tests/distill_with_simple_transformer.py", line 441, in main
[rank0]:     evaluation(prompt,
[rank0]:   File "/home/dreamyou070/Prun/tests/distill_with_simple_transformer.py", line 140, in evaluation
[rank0]:     output = evaluation_pipe(prompt=prompt,
[rank0]:   File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank0]:     return func(*args, **kwargs)
[rank0]:   File "/home/dreamyou070/Prun/src/prun/third_party/diffusers/src/diffusers/pipelines/animatediff/pipeline_animatediff.py", line 807, in __call__
[rank0]:     noise_pred = self.unet(latent_model_input,
[rank0]:   File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
[rank0]:     output = module._old_forward(*args, **kwargs)
[rank0]:   File "/home/dreamyou070/Prun/src/prun/third_party/diffusers/src/diffusers/models/unets/unet_motion_model.py", line 1150, in forward
[rank0]:     sample = upsample_block(
[rank0]:   File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/dreamyou070/Prun/src/prun/third_party/diffusers/src/diffusers/models/unets/unet_3d_blocks.py", line 1485, in forward
[rank0]:     hidden_states = attn(
[rank0]:   File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/dreamyou070/Prun/src/prun/third_party/diffusers/src/diffusers/models/transformers/transformer_2d.py", line 442, in forward
[rank0]:     hidden_states = block(
[rank0]:   File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/dreamyou070/Prun/src/prun/third_party/diffusers/src/diffusers/models/attention.py", line 519, in forward
[rank0]:     ff_output = self.ff(norm_hidden_states)
[rank0]:   File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/dreamyou070/Prun/src/prun/third_party/diffusers/src/diffusers/models/attention.py", line 840, in forward
[rank0]:     hidden_states = module(hidden_states)
[rank0]:   File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/dreamyou070/Prun/src/prun/third_party/diffusers/src/diffusers/models/activations.py", line 117, in forward
[rank0]:     hidden_states = self.proj(hidden_states)
[rank0]:   File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/peft/tuners/lora/layer.py", line 584, in forward
[rank0]:     result = result + lora_B(lora_A(dropout(x))) * scaling
[rank0]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 640.00 MiB. GPU 0 has a total capacity of 79.26 GiB of which 523.62 MiB is free. Process 1937784 has 5.43 GiB memory in use. Process 1937783 has 17.49 GiB memory in use. Including non-PyTorch memory, this process has 55.81 GiB memory in use. Of the allocated memory 54.54 GiB is allocated by PyTorch, and 775.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
