
 step 2. noise scheduler and solver
 (1) teacher pipe
Loading pipeline components...:  33%|███████████████████████████████████████▎                                                                              | 2/6 [00:01<00:02,  1.56it/s]/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/transformers/models/clip/feature_extraction_clip.py:28: FutureWarning: The class CLIPFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use CLIPImageProcessor instead.
  warnings.warn(
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:01<00:00,  4.25it/s]
 (2) student pipe
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:01<00:00,  5.17it/s]
 (3.2) student model
 (3.3) sub models

 step 3. optimizer
It seems like you have activated model offloading by calling `enable_model_cpu_offload`, but are now manually moving the pipeline to GPU. It is strongly recommended against doing so as memory gains from offloading are likely to be lost. Offloading automatically takes care of moving the individual components vae, text_encoder, tokenizer, unet, motion_adapter, scheduler, feature_extractor, image_encoder to GPU when needed. To make sure offloading works as expected, you should consider moving the pipeline back to CPU: `pipeline.to('cpu')` or removing the move altogether if you use offloading.

 step 4. target unet
 step 5. weight and device
 final weight_dtype : torch.float16
 step 6. move to device
 step 7. Enable optimizations
loading annotations from /scratch2/dreamyou070/MyData/video/panda/test_sample_trimmed/sample.csv ...
/home/dreamyou070/Prun/tests/distill.py:408: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()
Gradient for Parameter containing:
tensor([0.6958, 0.6626, 0.6704,  ..., 0.7412, 0.7520, 0.7886], device='cuda:0',
       dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([ 0.0920,  0.1202, -0.1490,  ...,  0.0035, -0.0049,  0.1212],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[-0.0016, -0.0071, -0.0156,  ..., -0.0398,  0.0123,  0.0569],
        [ 0.0257, -0.0325, -0.0538,  ...,  0.0185,  0.0255,  0.0263],
        [ 0.0166, -0.0056, -0.0025,  ..., -0.0393,  0.0453,  0.0328],
        ...,
        [-0.0337, -0.0521, -0.0282,  ..., -0.0160,  0.0328, -0.0385],
        [ 0.0137,  0.0163, -0.0170,  ..., -0.0835, -0.0092, -0.0188],
        [ 0.0095, -0.0164, -0.0154,  ..., -0.0090,  0.0452, -0.0449]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([ 0.0256,  0.0413,  0.0437,  ..., -0.0114,  0.0887, -0.0172],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([0.3618, 0.3743, 0.3894,  ..., 0.7896, 0.5161, 0.8291], device='cuda:0',
       dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([-0.2566, -0.2798, -0.2502,  ..., -0.2432, -0.2629, -0.2505],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[-0.0037,  0.0143, -0.0380,  ...,  0.0169,  0.0349,  0.0205],
        [ 0.0685,  0.0385, -0.0077,  ..., -0.0470, -0.0190,  0.0293],
        [ 0.0280, -0.0180,  0.0523,  ..., -0.0169,  0.0158,  0.0106],
        ...,
        [-0.0176, -0.0140,  0.0112,  ..., -0.0255, -0.0293, -0.0491],
        [-0.0329, -0.0193, -0.0068,  ..., -0.0370,  0.0206,  0.0052],
        [ 0.0009, -0.0264, -0.0103,  ...,  0.0401,  0.0110,  0.0020]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[-0.0102,  0.0201, -0.0361,  ..., -0.0124,  0.0084, -0.0012],
        [-0.0222,  0.0058, -0.0294,  ..., -0.0370, -0.0164,  0.0225],
        [-0.0625, -0.0085, -0.0036,  ...,  0.0046,  0.0066, -0.0141],
        ...,
        [-0.0111, -0.0147,  0.0438,  ...,  0.0300,  0.0238,  0.0070],
        [ 0.0194,  0.0404,  0.0264,  ...,  0.0162, -0.0237, -0.0180],
        [ 0.0147, -0.0130,  0.0293,  ...,  0.0049, -0.0263, -0.0247]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[-0.0393,  0.0529, -0.0068,  ...,  0.0361, -0.0186, -0.0159],
        [-0.0075,  0.0002,  0.0057,  ..., -0.0093, -0.0128, -0.0046],
        [ 0.0319,  0.0185, -0.0291,  ..., -0.0253, -0.0191, -0.0167],
        ...,
        [-0.0599, -0.0143, -0.0289,  ..., -0.0147, -0.0067,  0.0506],
        [-0.0338,  0.0217, -0.0183,  ..., -0.0036, -0.0067,  0.0754],
        [-0.0273,  0.0190, -0.0051,  ..., -0.0472,  0.0092,  0.0331]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[ 0.0316, -0.0361,  0.0068,  ...,  0.0544,  0.0240,  0.0271],
        [-0.0057, -0.0580,  0.0064,  ..., -0.0101, -0.0284, -0.0069],
        [ 0.0048, -0.0089,  0.0424,  ...,  0.0155,  0.0116,  0.0416],
        ...,
        [ 0.0003, -0.0326,  0.0240,  ..., -0.0079, -0.0296,  0.0128],
        [ 0.0477, -0.0119,  0.0200,  ...,  0.0067,  0.0525,  0.0133],
        [-0.0401,  0.0064, -0.0451,  ..., -0.0584, -0.0500, -0.0483]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([-0.0179,  0.0001,  0.0344,  ...,  0.0142,  0.0523,  0.0080],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([0.4348, 0.4587, 0.5151,  ..., 0.8750, 0.5664, 0.8501], device='cuda:0',
       dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([-0.2661, -0.2981, -0.2776,  ..., -0.2218, -0.2891, -0.2532],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[ 0.0086,  0.0031, -0.0046,  ...,  0.0230,  0.0263, -0.1085],
        [ 0.0452, -0.0340,  0.0245,  ..., -0.0707, -0.0217,  0.0112],
        [ 0.0329, -0.0483,  0.0406,  ..., -0.0281, -0.0024, -0.0024],
        ...,
        [-0.0218, -0.0315, -0.0076,  ..., -0.0224, -0.0823, -0.0032],
        [ 0.0370, -0.0442,  0.0566,  ..., -0.0069, -0.0157, -0.0072],
        [-0.0083,  0.0005, -0.0200,  ...,  0.0045, -0.0122,  0.0071]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[-0.0193,  0.0195,  0.0397,  ..., -0.0270,  0.0147, -0.0187],
        [-0.0215,  0.0765, -0.0463,  ..., -0.0127,  0.0668, -0.0011],
        [-0.0558, -0.0048,  0.0137,  ..., -0.0302, -0.0156,  0.0370],
        ...,
        [ 0.0128, -0.0229, -0.0196,  ..., -0.0165, -0.0403,  0.0207],
        [ 0.0374,  0.0050,  0.0060,  ..., -0.0077,  0.0725,  0.0367],
        [ 0.0013, -0.0081, -0.0240,  ...,  0.0014, -0.0037, -0.0247]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[-0.0330, -0.0013, -0.0278,  ...,  0.0558, -0.0037,  0.0409],
        [-0.0385,  0.0214,  0.0075,  ..., -0.0085,  0.0463, -0.0045],
        [-0.0187,  0.0220,  0.0484,  ...,  0.0442,  0.0021, -0.0004],
        ...,
        [ 0.0192, -0.0112, -0.0191,  ...,  0.0125, -0.0373, -0.0142],
        [ 0.0269, -0.0338,  0.0119,  ..., -0.0075,  0.0088, -0.0074],
        [ 0.0372,  0.0121, -0.0405,  ..., -0.0237, -0.0199,  0.0315]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[ 0.0081,  0.0195,  0.0111,  ..., -0.0335, -0.0742, -0.0360],
        [ 0.0293, -0.0102, -0.0076,  ...,  0.0322,  0.0332,  0.0049],
        [ 0.0043, -0.0494,  0.0139,  ..., -0.0517, -0.0126,  0.0168],
        ...,
        [-0.0307, -0.0553, -0.0385,  ..., -0.0278,  0.0139, -0.0159],
        [-0.0146, -0.0248, -0.0546,  ...,  0.0396,  0.0083,  0.0030],
        [ 0.0325,  0.0167,  0.0036,  ...,  0.0268,  0.0266,  0.0024]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([-0.0276, -0.0272, -0.0019,  ...,  0.0354,  0.0195,  0.0614],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([0.5688, 0.5288, 0.5601,  ..., 0.5918, 0.5254, 0.5728], device='cuda:0',
       dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([ 0.0045, -0.0703, -0.0696,  ...,  0.0474, -0.0820,  0.0263],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[ 0.0569,  0.0068,  0.0234,  ..., -0.0362, -0.0162, -0.0370],
        [ 0.0039, -0.0214, -0.0109,  ...,  0.0023, -0.0142, -0.0517],
        [-0.0343,  0.0207, -0.0079,  ..., -0.0519, -0.0434, -0.0020],
        ...,
        [ 0.0075,  0.0173,  0.0188,  ...,  0.0360, -0.0063, -0.0378],
        [-0.0532, -0.0094,  0.0085,  ..., -0.0058, -0.0038, -0.0266],
        [ 0.0185,  0.0019,  0.0133,  ...,  0.0066,  0.0110, -0.0236]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([ 0.0288, -0.0138,  0.0326,  ..., -0.0010, -0.0342, -0.0219],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[-0.0177,  0.0055, -0.0031,  ...,  0.0098,  0.0052,  0.0022],
        [-0.0048,  0.0117, -0.0185,  ..., -0.0087, -0.0276,  0.0104],
        [-0.0076, -0.0049, -0.0278,  ..., -0.0233,  0.0384, -0.0182],
        ...,
        [-0.0197, -0.0019,  0.0218,  ..., -0.0069, -0.0086, -0.0112],
        [ 0.0243,  0.0316, -0.0429,  ...,  0.0181, -0.0473, -0.0373],
        [-0.0604, -0.0207, -0.0133,  ...,  0.0058, -0.0141,  0.0175]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([-0.0155, -0.0077,  0.0274,  ...,  0.0560, -0.0479,  0.0432],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[ 0.0202, -0.0300,  0.0122,  ...,  0.0085,  0.0034,  0.0135],
        [-0.0180, -0.0029, -0.0417,  ..., -0.0009,  0.0223, -0.0013],
        [-0.0033, -0.0018, -0.0250,  ...,  0.0209,  0.0339, -0.0008],
        ...,
        [-0.0191, -0.0437, -0.0007,  ...,  0.0316,  0.0396, -0.0416],
        [-0.0100,  0.0206, -0.0109,  ...,  0.0127,  0.0056, -0.0155],
        [ 0.0105, -0.0100, -0.0491,  ..., -0.0006,  0.0057, -0.0091]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([-0.0190,  0.0250, -0.0192,  ...,  0.0453,  0.0126, -0.0269],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([0.8906, 0.8105, 0.8130,  ..., 0.7686, 0.7500, 0.8491], device='cuda:0',
       dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([ 0.0175, -0.0174, -0.0239,  ...,  0.0314, -0.0247,  0.0003],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[-0.0540, -0.0048,  0.0104,  ...,  0.0077,  0.0171, -0.0242],
        [-0.0091, -0.0095, -0.0312,  ..., -0.0077,  0.0415, -0.0246],
        [-0.0311, -0.0225,  0.0110,  ..., -0.0467, -0.0009, -0.0131],
        ...,
        [ 0.0086,  0.0089,  0.0029,  ..., -0.0146, -0.0047,  0.0229],
        [-0.0253,  0.0433,  0.0297,  ...,  0.0102,  0.0012,  0.0184],
        [ 0.0428,  0.0004, -0.0100,  ...,  0.0304, -0.0072, -0.0045]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([ 0.0134,  0.0369,  0.0271,  ..., -0.0284,  0.0109, -0.0331],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([0.7393, 0.6763, 0.6802,  ..., 0.8696, 0.7051, 0.8721], device='cuda:0',
       dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([-0.1368, -0.1562, -0.1483,  ..., -0.1919, -0.1505, -0.1860],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[ 0.0091,  0.0172,  0.0143,  ...,  0.0166,  0.0052, -0.0121],
        [ 0.0095,  0.0214, -0.0034,  ...,  0.0161, -0.0024, -0.0296],
        [ 0.0043, -0.0036, -0.0066,  ..., -0.0137,  0.0261,  0.0163],
        ...,
        [ 0.0080, -0.0185, -0.0217,  ..., -0.0099,  0.0031,  0.0189],
        [-0.0205,  0.0112,  0.0215,  ..., -0.0122,  0.0196,  0.0207],
        [ 0.0052, -0.0215,  0.0291,  ..., -0.0053, -0.0100, -0.0035]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[ 0.0037, -0.0175,  0.0077,  ..., -0.0023, -0.0026, -0.0042],
        [-0.0334, -0.0048,  0.0321,  ...,  0.0100,  0.0077, -0.0006],
        [-0.0128, -0.0024, -0.0211,  ..., -0.0189, -0.0316,  0.0037],
        ...,
        [ 0.0109, -0.0002, -0.0099,  ..., -0.0091, -0.0047, -0.0091],
        [ 0.0035,  0.0125,  0.0215,  ..., -0.0034,  0.0222,  0.0192],
        [ 0.0421, -0.0069, -0.0189,  ..., -0.0052,  0.0071,  0.0272]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[ 0.0180,  0.0061,  0.0101,  ..., -0.0090,  0.0177, -0.0110],
        [ 0.0102,  0.0045, -0.0044,  ...,  0.0053, -0.0167,  0.0154],
        [ 0.0405, -0.0163,  0.0080,  ...,  0.0242, -0.0336, -0.0031],
        ...,
        [-0.0025,  0.0119,  0.0278,  ..., -0.0233, -0.0098, -0.0147],
        [ 0.0167, -0.0230,  0.0157,  ..., -0.0079, -0.0332,  0.0071],
        [ 0.0155, -0.0074, -0.0044,  ..., -0.0089,  0.0220, -0.0034]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[ 0.0032, -0.0211, -0.0284,  ...,  0.0039,  0.0112, -0.0077],
        [ 0.0256,  0.0160,  0.0164,  ..., -0.0184, -0.0038, -0.0044],
        [-0.0160,  0.0115, -0.0216,  ..., -0.0117, -0.0386,  0.0056],
        ...,
        [ 0.0103, -0.0083, -0.0312,  ...,  0.0217,  0.0082, -0.0104],
        [-0.0232, -0.0189, -0.0091,  ...,  0.0051, -0.0208, -0.0026],
        [-0.0034,  0.0044, -0.0157,  ...,  0.0134,  0.0087, -0.0301]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([-0.0007, -0.0035,  0.0112,  ..., -0.0231, -0.0147, -0.0037],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([0.7476, 0.7065, 0.7354,  ..., 0.8564, 0.7212, 0.8789], device='cuda:0',
       dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([-0.1218, -0.1368, -0.1509,  ..., -0.1885, -0.1155, -0.1989],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[ 0.0103,  0.0112,  0.0101,  ...,  0.0135,  0.0188,  0.0287],
        [-0.0063, -0.0150,  0.0018,  ..., -0.0078, -0.0250, -0.0014],
        [ 0.0049,  0.0014,  0.0036,  ...,  0.0096,  0.0104, -0.0061],
        ...,
        [-0.0147,  0.0203, -0.0252,  ..., -0.0061, -0.0213,  0.0319],
        [-0.0037, -0.0089,  0.0268,  ...,  0.0189, -0.0197,  0.0048],
        [-0.0042,  0.0146,  0.0043,  ...,  0.0160, -0.0044, -0.0030]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[-0.0455,  0.0222,  0.0012,  ...,  0.0141, -0.0063,  0.0102],
        [ 0.0042, -0.0067,  0.0086,  ..., -0.0033,  0.0156,  0.0044],
        [-0.0023, -0.0308, -0.0152,  ...,  0.0134, -0.0164, -0.0066],
        ...,
        [ 0.0165,  0.0152,  0.0095,  ...,  0.0128,  0.0122,  0.0112],
        [ 0.0205,  0.0088, -0.0246,  ...,  0.0185, -0.0130, -0.0057],
        [-0.0185, -0.0002,  0.0109,  ..., -0.0034,  0.0006,  0.0080]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[ 0.0194,  0.0376,  0.0085,  ..., -0.0289,  0.0267,  0.0315],
        [-0.0164,  0.0091,  0.0179,  ...,  0.0032,  0.0392,  0.0048],
        [-0.0070,  0.0031,  0.0043,  ...,  0.0028,  0.0003,  0.0020],
        ...,
        [-0.0067,  0.0408,  0.0002,  ...,  0.0273, -0.0123,  0.0064],
        [ 0.0040,  0.0079,  0.0291,  ..., -0.0018,  0.0192,  0.0133],
        [ 0.0166, -0.0029,  0.0114,  ..., -0.0065, -0.0138, -0.0043]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[-0.0062, -0.0305,  0.0117,  ..., -0.0146,  0.0050, -0.0063],
        [-0.0007, -0.0099,  0.0138,  ..., -0.0137, -0.0215,  0.0163],
        [ 0.0114, -0.0221,  0.0086,  ...,  0.0135, -0.0308, -0.0122],
        ...,
        [ 0.0151,  0.0078,  0.0264,  ..., -0.0132,  0.0150, -0.0105],
        [-0.0092, -0.0094, -0.0073,  ..., -0.0075,  0.0180,  0.0324],
        [-0.0174, -0.0223,  0.0110,  ...,  0.0117,  0.0308, -0.0004]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([-0.0191, -0.0244, -0.0020,  ...,  0.0104, -0.0543,  0.0293],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([0.8960, 0.8916, 0.8779,  ..., 0.8721, 0.8818, 0.8813], device='cuda:0',
       dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([-0.0246, -0.0529, -0.0158,  ...,  0.0538, -0.0399,  0.0289],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[-0.0332,  0.0223,  0.0120,  ..., -0.0316, -0.0228, -0.0341],
        [ 0.0206,  0.0249,  0.0193,  ...,  0.0309, -0.0032, -0.0137],
        [-0.0393, -0.0177,  0.0271,  ..., -0.0074, -0.0097,  0.0085],
        ...,
        [ 0.0121, -0.0037,  0.0359,  ...,  0.0122,  0.0269,  0.0265],
        [-0.0384, -0.0229,  0.0098,  ...,  0.0264, -0.0133,  0.0198],
        [-0.0037,  0.0227, -0.0163,  ...,  0.0197, -0.0090,  0.0116]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([ 0.0148,  0.0192, -0.0316,  ...,  0.0108, -0.0071, -0.0144],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[-0.0092, -0.0123,  0.0020,  ...,  0.0034,  0.0132, -0.0145],
        [ 0.0300,  0.0030, -0.0201,  ..., -0.0066,  0.0092, -0.0123],
        [ 0.0117, -0.0093, -0.0041,  ..., -0.0043,  0.0152,  0.0088],
        ...,
        [-0.0031,  0.0087, -0.0136,  ...,  0.0151,  0.0085,  0.0078],
        [-0.0038, -0.0035, -0.0150,  ...,  0.0005,  0.0247,  0.0061],
        [ 0.0158, -0.0302, -0.0021,  ...,  0.0187, -0.0202, -0.0041]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([ 0.0183,  0.0173,  0.0008,  ..., -0.0043,  0.0160,  0.0023],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[ 3.4058e-02, -2.2858e-02,  4.4342e-02,  ...,  3.8727e-02,
          5.7602e-03, -1.9165e-02],
        [ 1.7136e-02, -9.4452e-03, -3.0994e-03,  ..., -4.3845e-04,
         -8.4534e-03, -7.1793e-03],
        [ 2.1194e-02,  1.0475e-02, -5.2185e-02,  ..., -1.8066e-02,
         -4.6295e-02,  2.5467e-02],
        ...,
        [ 3.7327e-03, -1.0429e-02, -7.2336e-04,  ..., -1.7776e-03,
         -4.9412e-05,  4.7417e-03],
        [-5.3986e-02,  4.5228e-04,  1.0063e-02,  ...,  4.8332e-03,
         -1.7395e-02, -2.6665e-03],
        [-1.8890e-02,  3.8239e-02, -1.1658e-02,  ..., -1.5137e-02,
         -5.2605e-03, -1.9196e-02]], device='cuda:0', dtype=torch.float16,
       requires_grad=True) is not None
Gradient for Parameter containing:
tensor([ 0.0556,  0.1014, -0.0253,  ...,  0.0542,  0.0042,  0.0538],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([0.9360, 0.8477, 0.8384,  ..., 0.9258, 0.8999, 0.8711], device='cuda:0',
       dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([ 0.0058,  0.0144, -0.0185,  ...,  0.0268, -0.0146, -0.0119],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[ 0.0269,  0.0320, -0.0175,  ...,  0.0147,  0.0050, -0.0157],
        [-0.0219, -0.0291, -0.0179,  ..., -0.0307, -0.0399, -0.0311],
        [ 0.0235, -0.0064, -0.0166,  ...,  0.0261,  0.0130,  0.0061],
        ...,
        [ 0.0241,  0.0495,  0.0433,  ...,  0.0200,  0.0245, -0.0518],
        [ 0.0268, -0.0154, -0.0059,  ...,  0.0034, -0.0218,  0.0144],
        [-0.0111, -0.0093,  0.0056,  ...,  0.0357, -0.0322,  0.0594]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([ 0.0714,  0.0068,  0.0042,  ..., -0.0255,  0.0174, -0.0258],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([0.7300, 0.7217, 0.7070,  ..., 0.8809, 0.7271, 0.8550], device='cuda:0',
       dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([-0.1440, -0.1459, -0.1501,  ..., -0.1908, -0.1235, -0.1962],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[ 0.0146, -0.0217,  0.0010,  ...,  0.0127, -0.0038,  0.0038],
        [-0.0176, -0.0187, -0.0055,  ...,  0.0309, -0.0100, -0.0123],
        [ 0.0080, -0.0044,  0.0155,  ...,  0.0031,  0.0170,  0.0285],
        ...,
        [ 0.0161,  0.0145, -0.0113,  ...,  0.0105, -0.0178, -0.0024],
        [-0.0307, -0.0043, -0.0151,  ...,  0.0334,  0.0175, -0.0199],
        [ 0.0101,  0.0215, -0.0056,  ..., -0.0019,  0.0048,  0.0280]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[-0.0209, -0.0307, -0.0178,  ..., -0.0172, -0.0075,  0.0104],
        [ 0.0198,  0.0124,  0.0121,  ..., -0.0052,  0.0026, -0.0051],
        [ 0.0010,  0.0096, -0.0047,  ..., -0.0041, -0.0088,  0.0030],
        ...,
        [ 0.0072, -0.0194,  0.0033,  ..., -0.0007,  0.0140,  0.0088],
        [-0.0193, -0.0221, -0.0184,  ..., -0.0277,  0.0042,  0.0075],
        [ 0.0100,  0.0143,  0.0021,  ...,  0.0035, -0.0077,  0.0239]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[-0.0003,  0.0178,  0.0033,  ...,  0.0218, -0.0122,  0.0133],
        [ 0.0019,  0.0262,  0.0178,  ..., -0.0046,  0.0162, -0.0090],
        [-0.0377, -0.0104,  0.0066,  ..., -0.0219,  0.0052, -0.0260],
        ...,
        [ 0.0413, -0.0155,  0.0243,  ...,  0.0135, -0.0004,  0.0195],
        [-0.0063, -0.0300,  0.0338,  ..., -0.0202,  0.0007, -0.0036],
        [ 0.0215,  0.0036, -0.0426,  ...,  0.0204, -0.0199,  0.0131]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[-0.0110, -0.0120,  0.0052,  ..., -0.0009, -0.0089, -0.0027],
        [-0.0091, -0.0094, -0.0102,  ..., -0.0041, -0.0284, -0.0316],
        [-0.0313,  0.0061, -0.0233,  ..., -0.0009, -0.0179,  0.0152],
        ...,
        [ 0.0260, -0.0184,  0.0070,  ...,  0.0008,  0.0140,  0.0112],
        [ 0.0162,  0.0029, -0.0075,  ...,  0.0005, -0.0107, -0.0105],
        [ 0.0139, -0.0072, -0.0210,  ..., -0.0200,  0.0229,  0.0144]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([ 0.0060, -0.0151,  0.0031,  ...,  0.0371,  0.0145, -0.0187],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([0.7485, 0.7217, 0.7275,  ..., 0.8569, 0.7319, 0.8901], device='cuda:0',
       dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([-0.1271, -0.1074, -0.1149,  ..., -0.1833, -0.0886, -0.1398],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[ 0.0115, -0.0001,  0.0320,  ..., -0.0117,  0.0162,  0.0161],
        [-0.0073,  0.0091,  0.0122,  ..., -0.0056, -0.0007,  0.0120],
        [-0.0071,  0.0158,  0.0128,  ...,  0.0019, -0.0192, -0.0098],
        ...,
        [ 0.0033, -0.0071, -0.0043,  ..., -0.0173, -0.0209, -0.0077],
        [-0.0069,  0.0030, -0.0033,  ..., -0.0147, -0.0011, -0.0085],
        [-0.0174,  0.0096,  0.0181,  ...,  0.0081, -0.0047,  0.0112]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[ 0.0201,  0.0124, -0.0038,  ..., -0.0272,  0.0120,  0.0020],
        [ 0.0415, -0.0102, -0.0025,  ...,  0.0310,  0.0034,  0.0155],
        [-0.0295, -0.0252, -0.0293,  ...,  0.0168,  0.0076, -0.0179],
        ...,
        [ 0.0296,  0.0130, -0.0009,  ...,  0.0094, -0.0091,  0.0250],
        [ 0.0024, -0.0078, -0.0138,  ..., -0.0110, -0.0174,  0.0055],
        [ 0.0170,  0.0096,  0.0176,  ..., -0.0084, -0.0091, -0.0081]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[ 0.0062, -0.0063, -0.0176,  ...,  0.0221, -0.0059, -0.0099],
        [ 0.0131, -0.0184, -0.0294,  ...,  0.0044,  0.0043, -0.0050],
        [ 0.0082,  0.0156,  0.0127,  ..., -0.0393,  0.0040,  0.0316],
        ...,
        [-0.0348, -0.0027,  0.0033,  ..., -0.0025, -0.0285, -0.0181],
        [ 0.0352, -0.0145, -0.0037,  ..., -0.0213,  0.0043, -0.0058],
        [-0.0165, -0.0031,  0.0108,  ..., -0.0120,  0.0160, -0.0147]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[ 0.0136, -0.0215, -0.0043,  ...,  0.0032, -0.0043, -0.0280],
        [ 0.0228,  0.0041, -0.0245,  ..., -0.0155,  0.0345,  0.0132],
        [ 0.0021, -0.0103, -0.0137,  ..., -0.0126, -0.0128, -0.0185],
        ...,
        [-0.0031,  0.0207,  0.0017,  ..., -0.0022, -0.0123, -0.0210],
        [-0.0156, -0.0213, -0.0039,  ...,  0.0036, -0.0091, -0.0060],
        [ 0.0105,  0.0163,  0.0092,  ..., -0.0106, -0.0139,  0.0356]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([ 0.0109, -0.0100,  0.0034,  ...,  0.0634, -0.0383,  0.0213],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([0.9419, 0.9624, 0.9648,  ..., 0.9790, 0.9614, 0.9717], device='cuda:0',
       dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([ 0.0019, -0.0368,  0.0347,  ...,  0.0452, -0.0432,  0.0491],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[ 0.0087,  0.0122, -0.0064,  ...,  0.0471, -0.0034, -0.0084],
        [-0.0088, -0.0020, -0.0109,  ..., -0.0086,  0.0055,  0.0025],
        [-0.0218, -0.0238,  0.0117,  ...,  0.0015, -0.0084,  0.0123],
        ...,
        [-0.0088,  0.0125,  0.0087,  ...,  0.0059,  0.0360, -0.0304],
        [ 0.0212, -0.0106, -0.0075,  ..., -0.0028,  0.0087,  0.0057],
        [ 0.0026,  0.0008, -0.0079,  ..., -0.0101, -0.0159, -0.0144]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([ 0.0071,  0.0120, -0.0106,  ..., -0.0236, -0.0245,  0.0037],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[ 0.0188, -0.0071, -0.0164,  ...,  0.0229, -0.0450,  0.0203],
        [-0.0233, -0.0092,  0.0126,  ...,  0.0109, -0.0087,  0.0058],
        [-0.0146, -0.0133,  0.0005,  ...,  0.0099,  0.0190,  0.0269],
        ...,
        [ 0.0109,  0.0018, -0.0250,  ...,  0.0294, -0.0317, -0.0156],
        [-0.0110, -0.0207,  0.0189,  ...,  0.0321,  0.0152,  0.0094],
        [-0.0015,  0.0015,  0.0020,  ..., -0.0149,  0.0189,  0.0021]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([-0.0280, -0.0153,  0.0074,  ..., -0.0044,  0.0110,  0.0040],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[-7.2975e-03,  2.0187e-02, -1.7624e-02,  ..., -1.7456e-02,
          4.9782e-03,  3.2074e-02],
        [-6.4636e-02,  2.4673e-02,  1.2329e-02,  ..., -7.0007e-02,
          5.9875e-02,  4.4632e-03],
        [ 1.9522e-03, -5.5199e-03, -1.6617e-02,  ...,  3.3447e-02,
         -7.1228e-05, -3.9215e-02],
        ...,
        [ 3.5004e-02,  8.4763e-03,  2.7962e-03,  ...,  4.4405e-05,
          1.3680e-02,  3.4393e-02],
        [ 4.1962e-02,  2.5909e-02,  9.7809e-03,  ...,  1.0201e-02,
         -1.0735e-02,  1.3542e-02],
        [ 3.2623e-02,  7.0839e-03, -3.7842e-02,  ...,  3.8544e-02,
          2.6062e-02, -4.6417e-02]], device='cuda:0', dtype=torch.float16,
       requires_grad=True) is not None
Gradient for Parameter containing:
tensor([-0.0411, -0.0207, -0.0211,  ...,  0.0155,  0.0153,  0.0499],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([0.8516, 0.8623, 0.8740,  ..., 0.8384, 0.8311, 0.8560], device='cuda:0',
       dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([-0.0240,  0.0522,  0.0174,  ..., -0.0164, -0.0038,  0.0209],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[-2.3560e-02, -2.8885e-02,  3.5286e-03,  ...,  6.1188e-03,
         -1.3294e-03,  5.1178e-02],
        [-3.1219e-02,  1.5350e-02, -7.2327e-02,  ...,  4.4769e-02,
         -3.0167e-02, -3.3295e-02],
        [ 2.3300e-02, -2.0508e-02, -1.7334e-02,  ...,  1.3092e-02,
         -8.5297e-03, -3.1109e-03],
        ...,
        [-1.4687e-02, -3.7689e-02,  2.6993e-02,  ...,  3.7903e-02,
         -1.3382e-02, -4.0070e-02],
        [-2.3651e-03,  4.3793e-02,  9.5062e-03,  ..., -1.2474e-02,
          1.4915e-02, -7.7019e-03],
        [ 2.1912e-02, -1.8775e-05,  7.7858e-03,  ...,  3.0502e-02,
         -5.9357e-02, -4.6600e-02]], device='cuda:0', dtype=torch.float16,
       requires_grad=True) is not None
Gradient for Parameter containing:
tensor([ 0.0275, -0.0040,  0.0580,  ..., -0.0614,  0.0171,  0.0029],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([0.6821, 0.6792, 0.6768,  ..., 0.8560, 0.6738, 0.8794], device='cuda:0',
       dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([-0.1599, -0.1649, -0.1735,  ..., -0.1908, -0.1737, -0.1978],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[ 0.0069,  0.0052,  0.0113,  ..., -0.0131, -0.0286, -0.0186],
        [ 0.0124,  0.0111,  0.0035,  ..., -0.0215, -0.0075,  0.0231],
        [ 0.0283, -0.0060,  0.0246,  ..., -0.0256, -0.0302,  0.0161],
        ...,
        [-0.0454,  0.0037, -0.0429,  ...,  0.0296,  0.0010,  0.0051],
        [-0.0100, -0.0320, -0.0144,  ..., -0.0161,  0.0300,  0.0126],
        [ 0.0052,  0.0545,  0.0080,  ..., -0.0030, -0.0212,  0.0177]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[-0.0216,  0.0117,  0.0291,  ..., -0.0036,  0.0150,  0.0104],
        [ 0.0093, -0.0133, -0.0047,  ...,  0.0266,  0.0158, -0.0058],
        [-0.0119, -0.0047, -0.0139,  ...,  0.0002,  0.0150, -0.0056],
        ...,
        [ 0.0323,  0.0663,  0.0204,  ...,  0.0003, -0.0158, -0.0044],
        [ 0.0046,  0.0195, -0.0119,  ..., -0.0171,  0.0124, -0.0097],
        [ 0.0006, -0.0206,  0.0182,  ..., -0.0088, -0.0296, -0.0260]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[-0.0099, -0.0383,  0.0092,  ...,  0.0449, -0.0144, -0.0385],
        [-0.0041,  0.0113, -0.0111,  ...,  0.0099, -0.0241,  0.0213],
        [ 0.0013, -0.0053,  0.0147,  ..., -0.0007,  0.0210, -0.0327],
        ...,
        [ 0.0200,  0.0287, -0.0260,  ...,  0.0042,  0.0053, -0.0129],
        [ 0.0286, -0.0195,  0.0088,  ...,  0.0143,  0.0102, -0.0136],
        [ 0.0085, -0.0044,  0.0175,  ...,  0.0010, -0.0220,  0.0214]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[ 0.0099,  0.0097, -0.0130,  ..., -0.0420, -0.0289, -0.0144],
        [ 0.0107, -0.0171,  0.0079,  ..., -0.0189,  0.0016, -0.0050],
        [-0.0174, -0.0035,  0.0024,  ..., -0.0003,  0.0259, -0.0242],
        ...,
        [-0.0101, -0.0039, -0.0125,  ...,  0.0020,  0.0136,  0.0039],
        [-0.0144, -0.0150, -0.0026,  ...,  0.0396,  0.0011,  0.0133],
        [-0.0069, -0.0107,  0.0352,  ..., -0.0405, -0.0042, -0.0532]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([-0.0219,  0.0033,  0.0189,  ..., -0.0253,  0.0018,  0.0434],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([0.6230, 0.6587, 0.6484,  ..., 0.8960, 0.7241, 0.8896], device='cuda:0',
       dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([-0.1449, -0.1102, -0.1490,  ..., -0.1753, -0.1390, -0.2203],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[-0.0022, -0.0005,  0.0110,  ..., -0.0039,  0.0048,  0.0139],
        [-0.0042,  0.0296, -0.0145,  ..., -0.0211,  0.0051,  0.0004],
        [-0.0141, -0.0113, -0.0143,  ..., -0.0044,  0.0138, -0.0126],
        ...,
        [-0.0100, -0.0097, -0.0522,  ..., -0.0007, -0.0204,  0.0107],
        [ 0.0208, -0.0261, -0.0017,  ..., -0.0253, -0.0260, -0.0493],
        [-0.0087, -0.0179, -0.0259,  ..., -0.0094,  0.0309, -0.0362]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[ 0.0204,  0.0159,  0.0179,  ..., -0.0104, -0.0016,  0.0265],
        [ 0.0199, -0.0073, -0.0083,  ..., -0.0080,  0.0364,  0.0038],
        [-0.0185,  0.0063,  0.0137,  ..., -0.0293,  0.0131, -0.0218],
        ...,
        [ 0.0157,  0.0014,  0.0218,  ..., -0.0064, -0.0331,  0.0149],
        [-0.0208, -0.0001, -0.0232,  ..., -0.0231,  0.0318, -0.0221],
        [-0.0047, -0.0004,  0.0011,  ..., -0.0176,  0.0003,  0.0221]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[ 0.0265,  0.0059, -0.0065,  ..., -0.0171, -0.0058, -0.0109],
        [ 0.0220,  0.0181, -0.0313,  ..., -0.0194,  0.0286, -0.0267],
        [-0.0040,  0.0225, -0.0242,  ..., -0.0542, -0.0447,  0.0311],
        ...,
        [ 0.0150,  0.0152,  0.0396,  ...,  0.0082, -0.0375,  0.0185],
        [ 0.0138,  0.0373, -0.0213,  ...,  0.0230,  0.0085,  0.0230],
        [-0.0300,  0.0075, -0.0518,  ..., -0.0273,  0.0269,  0.0070]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[-0.0154,  0.0063, -0.0156,  ...,  0.0076, -0.0253,  0.0184],
        [ 0.0287, -0.0282,  0.0048,  ...,  0.0133, -0.0147, -0.0047],
        [ 0.0484,  0.0190,  0.0388,  ..., -0.0142,  0.0259, -0.0028],
        ...,
        [ 0.0327,  0.0066,  0.0013,  ..., -0.0256, -0.0007,  0.0172],
        [-0.0093, -0.0117,  0.0133,  ...,  0.0309,  0.0134, -0.0043],
        [ 0.0390, -0.0065,  0.0045,  ..., -0.0230, -0.0188, -0.0086]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([-0.0149, -0.0241,  0.0204,  ...,  0.0441, -0.0453,  0.0735],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([0.9146, 0.8979, 0.8623,  ..., 0.8594, 0.8799, 0.8760], device='cuda:0',
       dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([ 0.0407, -0.0325, -0.0674,  ...,  0.0833,  0.0114,  0.0450],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[-0.0232, -0.0119, -0.0050,  ..., -0.0102,  0.0216,  0.0053],
        [ 0.0030,  0.0069, -0.0148,  ...,  0.0170,  0.0351, -0.0080],
        [ 0.0211, -0.0227, -0.0099,  ...,  0.0283,  0.0181, -0.0132],
        ...,
        [-0.0160,  0.0072, -0.0294,  ...,  0.0036,  0.0159, -0.0324],
        [-0.0138, -0.0010, -0.0253,  ...,  0.0127, -0.0057, -0.0196],
        [-0.0144, -0.0246, -0.0057,  ...,  0.0279,  0.0043, -0.0079]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([-0.0212,  0.0028, -0.0179,  ..., -0.0018,  0.0105, -0.0488],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[ 0.0360,  0.0047, -0.0080,  ...,  0.0291, -0.0088,  0.0201],
        [-0.0381,  0.0151, -0.0100,  ..., -0.0111, -0.0102,  0.0381],
        [ 0.0001, -0.0292,  0.0297,  ...,  0.0023,  0.0325, -0.0209],
        ...,
        [ 0.0169, -0.0035, -0.0074,  ...,  0.0183, -0.0249,  0.0125],
        [-0.0034, -0.0149, -0.0198,  ..., -0.0132,  0.0042,  0.0381],
        [-0.0104,  0.0110,  0.0125,  ...,  0.0048, -0.0229, -0.0071]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([-0.0169,  0.0276,  0.0196,  ...,  0.0296,  0.0084, -0.0137],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[-0.0040, -0.0188,  0.0109,  ..., -0.0114, -0.0345,  0.0437],
        [ 0.0187, -0.0190, -0.0244,  ...,  0.0044, -0.0152, -0.0013],
        [ 0.0016,  0.0072, -0.0180,  ..., -0.0347,  0.0323, -0.0350],
        ...,
        [-0.0407,  0.0038, -0.0188,  ..., -0.0204,  0.0461, -0.0319],
        [ 0.0361,  0.0048, -0.0312,  ..., -0.0439,  0.0468,  0.0003],
        [-0.0125, -0.0043, -0.0010,  ...,  0.0331, -0.0032,  0.0143]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([ 0.0043,  0.0175,  0.0452,  ...,  0.0317, -0.0259, -0.0017],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([0.7568, 0.8325, 0.7173,  ..., 0.7939, 0.8467, 0.7173], device='cuda:0',
       dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([ 0.0595,  0.0003,  0.0482,  ..., -0.0299, -0.0008,  0.0822],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[-0.0302, -0.0328,  0.0348,  ..., -0.0276, -0.0226,  0.0457],
        [ 0.0350, -0.0363, -0.0170,  ...,  0.0087,  0.0099,  0.0298],
        [ 0.0061,  0.0115,  0.0074,  ..., -0.0941, -0.0095, -0.0430],
        ...,
        [ 0.0286,  0.0025,  0.0371,  ..., -0.0170,  0.0244, -0.0458],
        [ 0.0456,  0.0214,  0.0312,  ..., -0.0693,  0.0257, -0.0265],
        [-0.0284, -0.0015, -0.0277,  ..., -0.0010, -0.0215, -0.0004]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([ 0.0237,  0.0900,  0.0445,  ..., -0.0121,  0.0497, -0.0373],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([0.5928, 0.5732, 0.6274,  ..., 0.8311, 0.6333, 0.8325], device='cuda:0',
       dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([-0.2001, -0.2325, -0.1727,  ..., -0.2269, -0.2236, -0.2262],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[-1.8784e-02, -2.9694e-02, -1.7899e-02,  ..., -3.6133e-02,
         -6.0501e-03,  3.5645e-02],
        [-3.3951e-03, -1.5945e-02,  1.1635e-02,  ...,  5.8174e-03,
         -1.6083e-02,  3.5725e-03],
        [ 2.2415e-02,  1.4656e-02,  2.1343e-03,  ...,  2.3529e-02,
         -4.4823e-03, -3.9406e-03],
        ...,
        [ 1.7838e-02, -7.3776e-03,  1.1780e-02,  ...,  2.1530e-02,
         -2.1149e-02,  9.8825e-05],
        [ 1.9255e-03, -2.3636e-02,  1.9806e-02,  ...,  3.0731e-02,
         -1.1185e-02,  2.6855e-02],
        [ 8.4839e-03, -6.8283e-03,  1.9970e-03,  ..., -2.6794e-02,
          9.6588e-03, -1.3931e-02]], device='cuda:0', dtype=torch.float16,
       requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[ 0.0090,  0.0159, -0.0070,  ...,  0.0471, -0.0394,  0.0266],
        [-0.0027, -0.0495, -0.0229,  ..., -0.0009,  0.0463,  0.0096],
        [-0.0003, -0.0077,  0.0058,  ...,  0.0075,  0.0066,  0.0016],
        ...,
        [-0.0182, -0.0112,  0.0085,  ..., -0.0013, -0.0092, -0.0296],
        [ 0.0038,  0.0312,  0.0290,  ..., -0.0007, -0.0189,  0.0047],
        [-0.0335, -0.0204,  0.0103,  ...,  0.0026, -0.0225, -0.0266]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[ 3.1143e-02,  7.6180e-03,  1.0857e-02,  ..., -8.2159e-04,
          9.4452e-03,  1.3557e-02],
        [-4.2648e-03,  7.5836e-03,  4.2694e-02,  ...,  2.3880e-02,
         -7.5035e-03, -6.7234e-04],
        [-3.4485e-03, -3.0548e-02, -3.0884e-02,  ..., -2.4185e-02,
          1.2787e-02,  7.1030e-03],
        ...,
        [-2.6993e-02,  3.0930e-02, -4.5898e-02,  ...,  1.9287e-02,
         -4.1626e-02,  3.6106e-03],
        [-1.6647e-02,  2.6398e-03,  2.4033e-03,  ...,  3.2684e-02,
         -1.7319e-02, -2.3590e-02],
        [ 7.1526e-07, -2.1866e-02,  3.2013e-02,  ..., -1.0445e-02,
          1.5373e-03,  2.8580e-02]], device='cuda:0', dtype=torch.float16,
       requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[-0.0032,  0.0095, -0.0215,  ..., -0.0097,  0.0262,  0.0438],
        [ 0.0139,  0.0398,  0.0235,  ..., -0.0183, -0.0353,  0.0047],
        [ 0.0028,  0.0098,  0.0081,  ...,  0.0108, -0.0038,  0.0260],
        ...,
        [ 0.0187, -0.0420, -0.0088,  ..., -0.0096, -0.0190, -0.0257],
        [ 0.0066,  0.0286,  0.0010,  ..., -0.0032, -0.0165,  0.0185],
        [-0.0086, -0.0013, -0.0137,  ...,  0.0354, -0.0108, -0.0114]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([-7.8440e-05,  6.4621e-03,  4.6478e-02,  ...,  2.6810e-02,
         1.1930e-03, -6.8169e-03], device='cuda:0', dtype=torch.float16,
       requires_grad=True) is not None
Gradient for Parameter containing:
tensor([0.6411, 0.5771, 0.6597,  ..., 0.8608, 0.6514, 0.8613], device='cuda:0',
       dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([-0.2242, -0.2332, -0.2037,  ..., -0.2429, -0.1689, -0.2338],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[ 0.0203, -0.0238, -0.0126,  ...,  0.0042, -0.0228,  0.0271],
        [ 0.0020, -0.0047, -0.0043,  ..., -0.0125,  0.0054,  0.0188],
        [ 0.0220, -0.0233, -0.0012,  ..., -0.0224,  0.0053,  0.0120],
        ...,
        [-0.0120,  0.0035, -0.0244,  ...,  0.0143, -0.0155, -0.0079],
        [ 0.0067, -0.0361, -0.0093,  ..., -0.0404, -0.0055,  0.0349],
        [ 0.0125,  0.0181,  0.0033,  ...,  0.0122,  0.0022,  0.0222]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[ 0.0308,  0.0104, -0.0033,  ...,  0.0187, -0.0066, -0.0298],
        [ 0.0289,  0.0137,  0.0201,  ..., -0.0194, -0.0310, -0.0173],
        [-0.0195, -0.0032,  0.0027,  ..., -0.0166, -0.0257, -0.0005],
        ...,
        [ 0.0142, -0.0159,  0.0088,  ...,  0.0028, -0.0177,  0.0263],
        [ 0.0070,  0.0231, -0.0284,  ..., -0.0075, -0.0019,  0.0031],
        [ 0.0209,  0.0192,  0.0224,  ...,  0.0351,  0.0176,  0.0025]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[-0.0258, -0.0010,  0.0150,  ..., -0.0354, -0.0080,  0.0110],
        [ 0.0030,  0.0256,  0.0268,  ..., -0.0054,  0.0302,  0.0198],
        [-0.0040, -0.0319,  0.0019,  ...,  0.0116,  0.0004,  0.0340],
        ...,
        [ 0.0109,  0.0345,  0.0076,  ...,  0.0155,  0.0091,  0.0182],
        [-0.0068, -0.0029, -0.0426,  ...,  0.0389, -0.0356, -0.0403],
        [ 0.0220, -0.0214,  0.0033,  ...,  0.0219, -0.0290,  0.0271]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[-0.0003,  0.0263,  0.0213,  ..., -0.0143,  0.0074,  0.0042],
        [-0.0028,  0.0036, -0.0123,  ...,  0.0025,  0.0317,  0.0117],
        [-0.0268, -0.0255, -0.0002,  ..., -0.0134,  0.0173,  0.0037],
        ...,
        [ 0.0323,  0.0018, -0.0434,  ..., -0.0338, -0.0577, -0.0155],
        [ 0.0010, -0.0077,  0.0056,  ..., -0.0240,  0.0159,  0.0156],
        [-0.0023, -0.0283,  0.0101,  ...,  0.0051, -0.0018, -0.0096]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([-0.0418, -0.0122, -0.0027,  ...,  0.0618, -0.0513,  0.0383],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([0.8203, 0.7949, 0.8320,  ..., 0.8262, 0.7852, 0.8374], device='cuda:0',
       dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([-0.0781, -0.0284, -0.1506,  ...,  0.1263, -0.0322,  0.0459],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[-0.0250, -0.0299,  0.0192,  ..., -0.0273,  0.0389,  0.0101],
        [ 0.0002, -0.0215, -0.0051,  ..., -0.0405,  0.0079, -0.0092],
        [-0.0414, -0.0403, -0.0096,  ..., -0.0094,  0.0036,  0.0024],
        ...,
        [ 0.0051,  0.0044,  0.0066,  ..., -0.0086, -0.0075, -0.0156],
        [ 0.0151,  0.0197, -0.0195,  ..., -0.0085,  0.0403, -0.0209],
        [-0.0378,  0.0033,  0.0135,  ..., -0.0167, -0.0269,  0.0200]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([ 0.0033, -0.0131,  0.0197,  ...,  0.0089,  0.0004,  0.0083],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[-0.0037,  0.0180, -0.0161,  ..., -0.0052, -0.0227, -0.0074],
        [ 0.0141,  0.0296, -0.0222,  ...,  0.0003,  0.0202, -0.0636],
        [ 0.0389, -0.0184,  0.0312,  ...,  0.0154,  0.0027,  0.0471],
        ...,
        [ 0.0461, -0.0286,  0.0051,  ..., -0.0280, -0.0099,  0.0484],
        [ 0.0312, -0.0057, -0.0102,  ...,  0.0016,  0.0047,  0.0040],
        [-0.0322, -0.0148, -0.0106,  ...,  0.0253,  0.0164, -0.0119]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([-0.0041, -0.0392, -0.0343,  ...,  0.0099,  0.0149,  0.0112],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[ 0.0206, -0.0031, -0.0029,  ...,  0.0492,  0.0192, -0.0417],
        [-0.0082, -0.0126, -0.0120,  ..., -0.0395,  0.0585, -0.0085],
        [-0.0157,  0.0100,  0.0026,  ..., -0.0050,  0.0015,  0.0316],
        ...,
        [ 0.0127, -0.0057,  0.0017,  ...,  0.0400,  0.0484,  0.0198],
        [ 0.0074, -0.0008,  0.0754,  ...,  0.0271,  0.0152, -0.0030],
        [ 0.0439,  0.0279,  0.0224,  ...,  0.0016,  0.0031, -0.0142]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([-0.0526, -0.0303,  0.0134,  ...,  0.0403,  0.0065, -0.0436],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([0.7935, 0.8213, 0.7764,  ..., 0.8164, 0.8501, 0.7646], device='cuda:0',
       dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([-0.0271, -0.1211,  0.0065,  ...,  0.0175,  0.0073,  0.0093],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[ 0.0695, -0.0292,  0.0021,  ..., -0.0170, -0.0143, -0.0345],
        [-0.0342,  0.0911, -0.0555,  ..., -0.0323,  0.0527,  0.0174],
        [-0.0446,  0.0144,  0.0068,  ...,  0.0362,  0.0514, -0.0280],
        ...,
        [-0.0484,  0.0885,  0.0596,  ..., -0.0480, -0.0015,  0.0531],
        [-0.0026, -0.0599,  0.0080,  ..., -0.0152,  0.0090,  0.0018],
        [-0.0044, -0.0023,  0.0213,  ...,  0.0388,  0.0026,  0.0275]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([-0.0009,  0.0482,  0.0473,  ..., -0.0854,  0.0551, -0.0771],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([0.6021, 0.5327, 0.6104,  ..., 0.8652, 0.6299, 0.9058], device='cuda:0',
       dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([-0.2263, -0.2408, -0.2136,  ..., -0.3257, -0.2411, -0.3118],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[-0.0017, -0.0128,  0.0695,  ...,  0.0317,  0.0126,  0.0348],
        [-0.0146, -0.0184, -0.0195,  ...,  0.0277, -0.0282,  0.0315],
        [-0.0111, -0.0075,  0.0380,  ..., -0.0023,  0.0077, -0.0191],
        ...,
        [ 0.0162,  0.0163,  0.0463,  ..., -0.0022, -0.0197,  0.0496],
        [-0.0118,  0.0492, -0.0063,  ..., -0.0228, -0.0020, -0.0185],
        [ 0.0569,  0.0090,  0.0397,  ..., -0.0224,  0.0004,  0.0130]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[-0.0317,  0.0132, -0.0106,  ..., -0.0286,  0.0250, -0.0071],
        [-0.0024, -0.0185,  0.0141,  ...,  0.0055,  0.0224, -0.0090],
        [-0.0307,  0.0119, -0.0449,  ..., -0.0156,  0.0197,  0.0251],
        ...,
        [-0.0111,  0.0337,  0.0053,  ...,  0.0012, -0.0282, -0.0015],
        [-0.0174, -0.0515, -0.0170,  ...,  0.0118, -0.0094,  0.0328],
        [ 0.0182, -0.0084,  0.0123,  ...,  0.0323, -0.0291, -0.0007]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[ 0.0413, -0.0116, -0.0221,  ..., -0.0157, -0.0642, -0.0069],
        [ 0.0275,  0.0251, -0.0097,  ..., -0.0157, -0.0281, -0.0156],
        [-0.0334, -0.0291, -0.0063,  ..., -0.0443,  0.0246,  0.0554],
        ...,
        [ 0.0741,  0.0073,  0.0069,  ..., -0.0045, -0.0178, -0.0270],
        [ 0.0300, -0.0292, -0.0231,  ..., -0.0216, -0.0108,  0.0304],
        [ 0.0034, -0.0482, -0.0135,  ..., -0.0141, -0.0405,  0.0110]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[ 0.0395, -0.0356, -0.0060,  ..., -0.0034, -0.0149, -0.0352],
        [ 0.0585,  0.0475, -0.0089,  ..., -0.0538, -0.0161,  0.0193],
        [ 0.0586,  0.0350,  0.0288,  ...,  0.0084,  0.0191, -0.0496],
        ...,
        [ 0.0349,  0.0124,  0.0431,  ...,  0.0285,  0.0052,  0.0100],
        [-0.0184,  0.0222, -0.0164,  ..., -0.0504, -0.0257,  0.0351],
        [-0.0126, -0.0193, -0.0367,  ...,  0.0566, -0.0491, -0.0151]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([-0.0150,  0.0010, -0.0182,  ..., -0.0364,  0.0250, -0.0129],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([0.6362, 0.5859, 0.6606,  ..., 0.8696, 0.6470, 0.9639], device='cuda:0',
       dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([-0.2059, -0.2396, -0.2251,  ..., -0.3364, -0.2255, -0.2910],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[ 0.0239,  0.0079, -0.0082,  ...,  0.0144, -0.0099,  0.0245],
        [ 0.0283,  0.0031, -0.0345,  ..., -0.0023,  0.0008, -0.0112],
        [-0.0457,  0.0057, -0.0039,  ..., -0.0064,  0.0074,  0.0555],
        ...,
        [ 0.0700,  0.1052,  0.1122,  ...,  0.0148, -0.0076,  0.0285],
        [ 0.0434, -0.0116,  0.0253,  ...,  0.0007, -0.0027,  0.0278],
        [ 0.0602,  0.0429,  0.0709,  ...,  0.0057,  0.0025,  0.0142]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[-1.8797e-03,  5.4054e-03, -5.1758e-02,  ...,  4.5836e-05,
         -2.2568e-02,  4.4861e-02],
        [ 1.4534e-02, -8.4457e-03, -2.1713e-02,  ..., -3.2959e-02,
         -2.7514e-04, -3.5980e-02],
        [-1.2039e-02, -1.0086e-02,  2.7252e-02,  ..., -9.1629e-03,
          1.7273e-02, -1.6037e-02],
        ...,
        [-5.1483e-02, -5.6122e-02, -5.7007e-02,  ...,  2.1362e-03,
          4.5128e-03,  2.4048e-02],
        [ 4.0680e-02,  2.1469e-02, -1.9852e-02,  ..., -1.9379e-02,
          2.5986e-02, -3.8452e-02],
        [-1.2215e-02, -2.6398e-02, -9.9487e-03,  ..., -4.4128e-02,
          2.1534e-03,  3.5828e-02]], device='cuda:0', dtype=torch.float16,
       requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[-0.0561,  0.0047, -0.0613,  ..., -0.0674,  0.0046,  0.0094],
        [-0.0122,  0.0246, -0.0151,  ...,  0.0420, -0.0536,  0.0391],
        [-0.0217,  0.0485,  0.0066,  ...,  0.0005, -0.0075, -0.0178],
        ...,
        [ 0.0208,  0.0386,  0.0314,  ...,  0.0020,  0.0165,  0.0165],
        [-0.0021, -0.0144,  0.0515,  ...,  0.0035,  0.0193, -0.0302],
        [ 0.0144,  0.0032, -0.0120,  ...,  0.0288, -0.0168,  0.0050]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[ 0.0440, -0.0027, -0.0516,  ..., -0.0113, -0.0186, -0.0007],
        [ 0.0225, -0.0396, -0.0325,  ...,  0.0283, -0.0150,  0.0010],
        [-0.0060,  0.0404,  0.0235,  ...,  0.0104, -0.0036, -0.0063],
        ...,
        [ 0.0072, -0.0496, -0.0202,  ...,  0.0014,  0.0121,  0.0075],
        [ 0.0379,  0.0356, -0.0173,  ...,  0.0101, -0.0111, -0.0266],
        [-0.0333,  0.0143,  0.0210,  ..., -0.0107, -0.0009, -0.0020]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([-0.0334, -0.0150, -0.0041,  ...,  0.0161, -0.0248,  0.0336],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([0.8276, 0.7979, 0.8267,  ..., 0.8657, 0.8208, 0.8330], device='cuda:0',
       dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([-0.0082, -0.0307, -0.0257,  ...,  0.0725, -0.0468,  0.0512],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[-0.0189, -0.0304, -0.0154,  ..., -0.0121, -0.0309,  0.0022],
        [ 0.0297,  0.0344, -0.0048,  ..., -0.0026, -0.0310,  0.0541],
        [ 0.0227,  0.0537, -0.0079,  ..., -0.0090,  0.0357,  0.0273],
        ...,
        [-0.0624,  0.0275, -0.0106,  ...,  0.0512, -0.0642,  0.0234],
        [-0.0163,  0.0138, -0.0461,  ..., -0.0452,  0.0147, -0.0089],
        [ 0.0108, -0.0348, -0.0426,  ...,  0.0462,  0.0099, -0.0081]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([-0.0266, -0.0030, -0.0225,  ..., -0.0320, -0.0090,  0.0127],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[-0.0009, -0.0106,  0.0504,  ..., -0.0085,  0.0206, -0.0065],
        [ 0.0118,  0.0581, -0.0028,  ..., -0.0097, -0.0112,  0.0576],
        [-0.0238, -0.0045,  0.0095,  ...,  0.0309,  0.0135, -0.0233],
        ...,
        [-0.0185, -0.0319,  0.0027,  ..., -0.0149,  0.0276,  0.0360],
        [ 0.0800, -0.0397, -0.0251,  ...,  0.0195, -0.0096, -0.0244],
        [ 0.0008,  0.0450, -0.0149,  ...,  0.0429, -0.0115, -0.0169]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([ 0.0251, -0.0251, -0.0119,  ...,  0.0144, -0.0483, -0.0034],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[-0.0213,  0.0136, -0.0521,  ...,  0.0243,  0.0559, -0.0267],
        [ 0.0225,  0.0181,  0.0393,  ...,  0.0062, -0.0093, -0.0395],
        [ 0.0315, -0.0290,  0.0308,  ...,  0.0077,  0.0342,  0.0327],
        ...,
        [-0.0194,  0.0043, -0.0284,  ...,  0.0108,  0.0095, -0.0035],
        [ 0.0278,  0.0003,  0.0118,  ..., -0.0355,  0.0182,  0.0006],
        [-0.0184, -0.0014,  0.0074,  ..., -0.0037, -0.0577,  0.0124]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([ 0.0328, -0.0901, -0.0087,  ..., -0.0026, -0.0240, -0.0347],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([0.8491, 0.8521, 0.8652,  ..., 0.8608, 0.8350, 0.8794], device='cuda:0',
       dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([-0.0478, -0.0474,  0.0325,  ..., -0.1036, -0.0800, -0.0736],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[-2.1636e-04,  8.3313e-03, -3.3035e-03,  ..., -4.7302e-02,
         -3.1189e-02,  1.6565e-03],
        [ 3.1067e-02, -1.6602e-02,  1.1024e-02,  ...,  3.6926e-02,
          1.4557e-02, -4.1992e-02],
        [ 5.6946e-02,  3.4393e-02,  2.3026e-02,  ..., -4.4098e-02,
          2.8763e-02,  7.6416e-02],
        ...,
        [-4.5013e-02,  6.1829e-02, -4.5868e-02,  ...,  5.7007e-02,
          1.2245e-02,  7.6172e-02],
        [ 8.1406e-03, -5.5756e-02, -2.6817e-03,  ..., -4.9057e-03,
         -7.0190e-02, -7.7271e-02],
        [-4.2023e-02,  3.2684e-02,  3.4302e-02,  ...,  2.7716e-05,
          2.1515e-02, -1.5556e-02]], device='cuda:0', dtype=torch.float16,
       requires_grad=True) is not None
Gradient for Parameter containing:
tensor([ 0.0248,  0.0092,  0.0341,  ..., -0.0629,  0.1136, -0.0693],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([0.5356, 0.4958, 0.5454,  ..., 0.8242, 0.5996, 0.9146], device='cuda:0',
       dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([-0.2084, -0.2517, -0.2289,  ..., -0.3142, -0.2625, -0.2747],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[ 0.0098,  0.0254,  0.0335,  ..., -0.0475,  0.0088, -0.0037],
        [ 0.0023,  0.0393,  0.0297,  ..., -0.0114, -0.0242, -0.0080],
        [-0.0081,  0.0202,  0.0517,  ...,  0.0247,  0.0367,  0.0211],
        ...,
        [-0.0093,  0.0181,  0.0119,  ..., -0.0141, -0.0012,  0.0091],
        [-0.0027, -0.0181, -0.0570,  ...,  0.0068,  0.0369,  0.0461],
        [-0.0615, -0.0049, -0.0161,  ...,  0.0005,  0.0303,  0.0166]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[-1.8280e-02, -1.7044e-02, -3.0457e-02,  ...,  7.0877e-03,
         -3.5248e-02,  6.3721e-02],
        [-8.0109e-03, -5.1361e-02, -1.9974e-02,  ...,  5.3070e-02,
          4.7180e-02,  2.4094e-02],
        [-2.2812e-03,  1.4168e-02,  7.0877e-03,  ...,  1.1230e-02,
          1.7349e-02,  9.1705e-03],
        ...,
        [ 3.3081e-02,  2.8427e-02,  3.7460e-03,  ...,  2.5421e-02,
          3.1281e-02, -1.9989e-02],
        [-8.6665e-05, -1.3969e-02,  3.8757e-02,  ...,  1.7548e-02,
         -2.4338e-02, -3.4302e-02],
        [-2.7466e-02, -9.4080e-04, -7.6599e-03,  ..., -2.8824e-02,
          2.3823e-03,  3.0334e-02]], device='cuda:0', dtype=torch.float16,
       requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[-0.0309,  0.0046,  0.0079,  ..., -0.0385,  0.0019, -0.0338],
        [-0.0082, -0.0301,  0.0013,  ...,  0.0386, -0.0008,  0.0374],
        [ 0.0025,  0.0246, -0.0011,  ..., -0.0171, -0.0349, -0.0459],
        ...,
        [-0.0080,  0.0517, -0.0057,  ...,  0.0314, -0.0028, -0.0141],
        [ 0.0580,  0.0322,  0.0300,  ...,  0.0083, -0.0193, -0.0157],
        [ 0.0064,  0.0107,  0.0406,  ..., -0.0068, -0.0080,  0.0097]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[ 0.0050, -0.0367, -0.0137,  ...,  0.0148, -0.0079, -0.0016],
        [ 0.0246,  0.0270, -0.0190,  ...,  0.0535,  0.0461, -0.0435],
        [-0.0421,  0.0003, -0.0064,  ...,  0.0076, -0.0263, -0.0024],
        ...,
        [ 0.0068,  0.0106,  0.0072,  ..., -0.0506, -0.0392, -0.0058],
        [-0.0322,  0.0033,  0.0639,  ..., -0.0050, -0.0076, -0.0083],
        [ 0.0563,  0.0006,  0.0527,  ...,  0.0208,  0.0338,  0.0364]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([-0.0379, -0.0368,  0.0043,  ...,  0.0113,  0.0742, -0.0289],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([0.7461, 0.6030, 0.7266,  ..., 0.9629, 0.6484, 0.9927], device='cuda:0',
       dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([-0.2097, -0.2590, -0.2238,  ..., -0.2466, -0.2520, -0.2600],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[ 0.0690, -0.0974,  0.0743,  ...,  0.0013,  0.0509,  0.0159],
        [ 0.0040,  0.0037, -0.0221,  ..., -0.0150, -0.0301, -0.0305],
        [ 0.0372,  0.0253,  0.0331,  ...,  0.0042,  0.0215, -0.0549],
        ...,
        [-0.0204,  0.0257,  0.0079,  ..., -0.0466, -0.0242,  0.0620],
        [-0.0061,  0.0192,  0.0045,  ..., -0.0529,  0.0133, -0.0029],
        [-0.0816,  0.0594, -0.0222,  ...,  0.0104,  0.0322,  0.0113]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[-0.0300,  0.0125,  0.0048,  ..., -0.0172,  0.0379,  0.0082],
        [-0.0165, -0.0112, -0.0533,  ..., -0.0416, -0.0120, -0.0086],
        [ 0.0057,  0.0328,  0.0176,  ..., -0.0609,  0.0316,  0.0114],
        ...,
        [-0.0562,  0.0042, -0.0287,  ...,  0.0079, -0.0186,  0.0442],
        [ 0.0398, -0.0125, -0.0366,  ...,  0.0064,  0.0170,  0.0147],
        [ 0.0713,  0.0031,  0.0043,  ..., -0.0092,  0.0240, -0.0321]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[-0.0079,  0.0271,  0.0211,  ..., -0.0318, -0.0252,  0.0398],
        [-0.0188,  0.0122,  0.0927,  ..., -0.0081, -0.0459,  0.0046],
        [-0.0074,  0.0116, -0.0417,  ...,  0.0054,  0.0327,  0.0248],
        ...,
        [-0.0155, -0.0107, -0.0976,  ...,  0.0089,  0.0174, -0.0128],
        [ 0.0032,  0.0111, -0.0082,  ..., -0.0767, -0.0199,  0.0321],
        [ 0.0207, -0.0132,  0.0976,  ..., -0.0034, -0.0145, -0.0312]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[-0.0093,  0.0092,  0.0477,  ..., -0.0220,  0.0138, -0.0039],
        [-0.0419, -0.0195, -0.0170,  ...,  0.0329, -0.0034, -0.0046],
        [-0.0458, -0.0417, -0.0253,  ...,  0.0172,  0.0057, -0.0627],
        ...,
        [ 0.0442, -0.0017,  0.0072,  ...,  0.0121, -0.0229, -0.0091],
        [-0.0092,  0.0696, -0.0058,  ...,  0.0113,  0.0696,  0.0321],
        [ 0.0211, -0.0114, -0.0233,  ...,  0.0163, -0.0588,  0.0252]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([-0.0159, -0.0780, -0.0213,  ...,  0.0313, -0.0050,  0.0408],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([0.8193, 0.8467, 0.8345,  ..., 0.8521, 0.7349, 0.8843], device='cuda:0',
       dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([-0.0061,  0.0041, -0.0170,  ...,  0.0069, -0.0804,  0.0724],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[-0.0344, -0.0248, -0.0845,  ..., -0.0529,  0.0037,  0.0147],
        [-0.0028, -0.0027, -0.0018,  ..., -0.0180, -0.0591,  0.0474],
        [-0.0548,  0.0304, -0.0574,  ...,  0.0386,  0.0004, -0.0003],
        ...,
        [-0.0100,  0.0395,  0.0140,  ...,  0.0663,  0.0067, -0.0197],
        [-0.0421,  0.0293, -0.0040,  ..., -0.0085, -0.0425,  0.0055],
        [-0.0251,  0.0319,  0.0005,  ..., -0.0248, -0.0491,  0.0094]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([ 0.0128, -0.0006, -0.0095,  ..., -0.0281,  0.0155,  0.0345],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[ 0.0377, -0.0099,  0.0458,  ..., -0.0335,  0.0310, -0.0336],
        [-0.0015, -0.0247, -0.0225,  ...,  0.0154,  0.0028,  0.0270],
        [ 0.0279, -0.0397,  0.0179,  ...,  0.0141, -0.0320, -0.0033],
        ...,
        [ 0.0524, -0.0127, -0.0135,  ...,  0.0260,  0.0355,  0.0143],
        [ 0.0400,  0.0127,  0.0460,  ...,  0.0224,  0.0098, -0.0044],
        [ 0.0078, -0.0091, -0.0120,  ...,  0.0189,  0.0612, -0.0240]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([-0.0011,  0.0167,  0.0144,  ..., -0.0389, -0.0359,  0.0063],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[ 0.0529,  0.0511, -0.0666,  ..., -0.0070,  0.0066, -0.0339],
        [ 0.0237,  0.0129, -0.0284,  ..., -0.0489,  0.0218, -0.0209],
        [ 0.0287,  0.0053,  0.0035,  ...,  0.0298,  0.0036, -0.0433],
        ...,
        [ 0.0074, -0.0071,  0.0011,  ..., -0.0271, -0.0182, -0.0099],
        [ 0.0212, -0.0169,  0.0127,  ..., -0.0014,  0.0158, -0.0173],
        [ 0.0388, -0.0209,  0.0059,  ..., -0.0451, -0.0197, -0.0524]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([ 0.0150, -0.0277,  0.0303,  ...,  0.0344,  0.0143, -0.0066],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([0.7524, 0.7515, 0.7812, 0.7856, 0.6836, 0.7739, 0.7451, 0.7524, 0.6987,
        0.7339, 0.7061, 0.6919, 0.7837, 0.7144, 0.7319, 0.7666, 0.7334, 0.7798,
        0.7588, 0.6807, 0.6841, 0.7827, 0.7202, 0.7686, 0.7407, 0.7930, 0.7573,
        0.7310, 0.7031, 0.6938, 0.7319, 0.7134, 0.7559, 0.6748, 0.7686, 0.7603,
        0.7720, 0.8091, 0.7461, 0.6968, 0.6934, 0.6860, 0.7231, 0.5850, 0.7085,
        0.6519, 0.6963, 0.6626, 0.6431, 0.6792, 0.6631, 0.6826, 0.6519, 0.7192,
        0.6660, 0.6763, 0.6982, 0.7471, 0.6816, 0.6660, 0.7002, 0.6465, 0.6860,
        0.6904, 0.6812, 0.6694, 0.7183, 0.7485, 0.7510, 0.7212, 0.6313, 0.6733,
        0.6733, 0.6284, 0.6890, 0.7363, 0.6963, 0.6812, 0.6484, 0.6543, 0.7407,
        0.7676, 0.7036, 0.6748, 0.7056, 0.7334, 0.7485, 0.6562, 0.7021, 0.6758,
        0.7031, 0.6768, 0.6934, 0.6865, 0.6309, 0.7729, 0.6548, 0.7417, 0.7041,
        0.7124, 0.7432, 0.7700, 0.7393, 0.6602, 0.7349, 0.7852, 0.6890, 0.7373,
        0.6724, 0.7520, 0.7227, 0.7407, 0.7358, 0.7104, 0.7129, 0.7622, 0.7393,
        0.7373, 0.7339, 0.6870, 0.7402, 0.7891, 0.7617, 0.7837, 0.7764, 0.7920,
        0.8110, 0.7988, 0.8223, 0.7588, 0.7524, 0.8223, 0.7524, 0.7700, 0.7734,
        0.7896, 0.7461, 0.7593, 0.7954, 0.7466, 0.7285, 0.7402, 0.7148, 0.7559,
        0.7349, 0.7378, 0.7793, 0.6528, 0.7363, 0.7344, 0.7578, 0.7734, 0.7231,
        0.7446, 0.7417, 0.7241, 0.7437, 0.7808, 0.7520, 0.7363, 0.7002, 0.7500,
        0.6362, 0.6230, 0.6699, 0.6118, 0.6436, 0.7207, 0.6274, 0.6509, 0.6680,
        0.6895, 0.6553, 0.6719, 0.6411, 0.6431, 0.6821, 0.6826, 0.6865, 0.6143,
        0.7144, 0.6479, 0.7852, 0.7812, 0.7339, 0.7397, 0.7485, 0.7305, 0.7520,
        0.7729, 0.6826, 0.7251, 0.7090, 0.7344, 0.7427, 0.7217, 0.7212, 0.7563,
        0.7476, 0.7886, 0.6543, 0.6982, 0.7373, 0.6772, 0.6680, 0.7451, 0.6709,
        0.7134, 0.6758, 0.7256, 0.7642, 0.6455, 0.7217, 0.6514, 0.7114, 0.7192,
        0.6519, 0.7246, 0.7285, 0.7080, 0.8022, 0.7734, 0.7686, 0.7339, 0.8237,
        0.8096, 0.7358, 0.7109, 0.7622, 0.8105, 0.7852, 0.7358, 0.7734, 0.7939,
        0.7881, 0.8003, 0.7300, 0.8188, 0.7520, 0.7354, 0.6421, 0.6904, 0.6895,
        0.6797, 0.6787, 0.7197, 0.7588, 0.7275, 0.7402, 0.7021, 0.6641, 0.7349,
        0.7783, 0.6777, 0.6934, 0.7222, 0.7051, 0.7021, 0.7729, 0.7656, 0.7559,
        0.6685, 0.6987, 0.6997, 0.6724, 0.6890, 0.6982, 0.6626, 0.7524, 0.7358,
        0.6855, 0.7202, 0.7090, 0.6997, 0.7246, 0.6924, 0.6963, 0.7471, 0.6758,
        0.7505, 0.7656, 0.7397, 0.7378, 0.7725, 0.7314, 0.7310, 0.6709, 0.7666,
        0.7837, 0.7773, 0.6768, 0.7583, 0.7583, 0.7021, 0.7666, 0.7583, 0.7651,
        0.7632, 0.7822, 0.7622, 0.7461, 0.6694, 0.7515, 0.7036, 0.7656, 0.7510,
        0.6714, 0.6851, 0.6592, 0.7617, 0.7593, 0.7036, 0.7793, 0.7227, 0.7134,
        0.7070, 0.6836, 0.6973, 0.7466, 0.7446, 0.7544, 0.7744, 0.7676, 0.7690,
        0.7505, 0.7661, 0.7158, 0.7969, 0.7690, 0.8213, 0.7627, 0.7627, 0.8052,
        0.8091, 0.7466, 0.8057, 0.7700, 0.7734, 0.7124, 0.7212, 0.7603, 0.7397,
        0.7568, 0.7583, 0.7793, 0.7256, 0.7720, 0.7632, 0.7817, 0.7583, 0.7754,
        0.7881, 0.7148, 0.7622, 0.7227, 0.6743, 0.7559, 0.7241, 0.7686, 0.7061,
        0.6748, 0.7056, 0.7051, 0.7339, 0.6533, 0.7622, 0.6758, 0.7314, 0.6924,
        0.6948, 0.7495, 0.6758, 0.6748, 0.6797, 0.7178, 0.7129, 0.6855, 0.6792,
        0.7222, 0.6665, 0.8394, 0.8198, 0.8643, 0.8638, 0.8579, 0.8237, 0.8506,
        0.8169, 0.8301, 0.8662, 0.8633, 0.7944, 0.8179, 0.7769, 0.8213, 0.8115,
        0.8052, 0.8350, 0.8115, 0.8516, 0.6812, 0.7349, 0.7485, 0.6826, 0.6797,
        0.6870, 0.6899, 0.7529, 0.7178, 0.7441, 0.6680, 0.7529, 0.6465, 0.7598,
        0.6880, 0.7612, 0.7656, 0.7007, 0.7334, 0.7705, 0.7881, 0.8032, 0.7896,
        0.7939, 0.8149, 0.8179, 0.8677, 0.8242, 0.8359, 0.8359, 0.7466, 0.8364,
        0.7656, 0.8247, 0.8267, 0.8145, 0.8281, 0.7891, 0.8022, 0.7480, 0.6528,
        0.7451, 0.6680, 0.7710, 0.6636, 0.7520, 0.7295, 0.6924, 0.7769, 0.7612,
        0.7778, 0.6670, 0.6611, 0.7065, 0.7163, 0.7632, 0.7388, 0.6753, 0.7671,
        0.7197, 0.7617, 0.7329, 0.7173, 0.6743, 0.7681, 0.7275, 0.6260, 0.7266,
        0.6348, 0.7056, 0.6499, 0.7158, 0.7183, 0.6665, 0.7275, 0.7666, 0.6851,
        0.6875, 0.7153, 0.6929, 0.7163, 0.7446, 0.6772, 0.7021, 0.6948, 0.7505,
        0.7573, 0.6885, 0.7241, 0.7285, 0.7466, 0.7583, 0.7207, 0.7808, 0.7236,
        0.6543, 0.6982, 0.6963, 0.6738, 0.6777, 0.7734, 0.8003, 0.8267, 0.7671,
        0.8081, 0.7251, 0.8203, 0.8604, 0.8086, 0.8154, 0.7930, 0.7725, 0.8101,
        0.7573, 0.8057, 0.7510, 0.7144, 0.8164, 0.7866, 0.8486, 0.7314, 0.7393,
        0.7798, 0.7383, 0.6255, 0.6826, 0.6846, 0.7041, 0.7373, 0.7148, 0.6968,
        0.6758, 0.6597, 0.7100, 0.6851, 0.7368, 0.7324, 0.7393, 0.7549, 0.7134,
        0.7666, 0.7280, 0.7002, 0.7207, 0.6743, 0.8130, 0.7700, 0.7671, 0.7637,
        0.7676, 0.7266, 0.6982, 0.7471, 0.6660, 0.7109, 0.7578, 0.6997, 0.7861,
        0.7812, 0.6592, 0.7568, 0.7764, 0.7935, 0.8174, 0.7573, 0.8335, 0.7729,
        0.8008, 0.8032, 0.7891, 0.7456, 0.8154, 0.7710, 0.7554, 0.7534, 0.7944,
        0.7822, 0.8237, 0.8237, 0.7495, 0.7305, 0.7300, 0.7227, 0.7476, 0.7383,
        0.7305, 0.6714, 0.6738, 0.7432, 0.7310, 0.7603, 0.7231, 0.7275, 0.7500,
        0.6543, 0.7222, 0.7236, 0.7368, 0.7466, 0.6924, 0.7715, 0.7812, 0.8027,
        0.7700, 0.8135, 0.7832, 0.8486, 0.8384, 0.7241, 0.8486, 0.8486, 0.7988,
        0.8193, 0.7822, 0.7642, 0.8325, 0.8340, 0.7827, 0.7974, 0.7959, 0.7271,
        0.7085, 0.7529, 0.7202, 0.7148, 0.6685, 0.7100, 0.6553, 0.7324, 0.6934,
        0.7437, 0.7012, 0.6914, 0.6987, 0.7461, 0.6860, 0.7363, 0.7612, 0.7095,
        0.7144], device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([ 2.0554e-02, -2.0584e-02,  2.9404e-02,  1.4145e-02, -4.5288e-02,
        -6.1111e-03,  5.5008e-03,  2.2469e-03,  3.7720e-02, -1.3268e-02,
        -1.4503e-02, -3.6438e-02,  5.5275e-03, -6.7444e-02,  1.1749e-02,
         3.6850e-03, -8.1360e-02, -2.0813e-02,  1.8997e-02, -2.2774e-03,
        -4.2755e-02,  1.5366e-02, -7.7576e-02, -2.3026e-02,  4.8096e-02,
        -6.8741e-03,  5.7404e-02,  1.1383e-01,  5.6505e-04,  3.3600e-02,
         8.7891e-02,  2.6569e-03, -1.0455e-01,  1.3037e-01, -8.2886e-02,
        -3.7720e-02, -2.1076e-03, -7.0374e-02,  1.7519e-03,  5.4535e-02,
         1.7807e-02, -3.2745e-02,  1.9455e-02, -1.0425e-01, -3.2501e-02,
         1.0724e-01, -5.8380e-02,  5.5267e-02, -2.3895e-02,  4.1656e-02,
        -6.1371e-02, -1.2079e-01, -2.0187e-02,  1.7432e-01,  7.3608e-02,
        -7.3364e-02, -9.1248e-03, -4.7913e-02, -1.4320e-02,  1.1407e-01,
         3.8719e-03,  1.5332e-01,  4.4861e-02,  5.9814e-03,  6.5125e-02,
        -7.2746e-03, -7.4524e-02, -2.8086e-04, -3.9429e-02, -1.0506e-02,
         1.8646e-02, -9.6497e-02, -3.4485e-02, -9.7122e-03, -4.9316e-02,
        -9.3613e-03, -1.2383e-02,  7.6538e-02, -9.9243e-02, -3.6438e-02,
         2.1896e-02,  5.6671e-02,  1.0663e-01,  9.2346e-02,  3.1708e-02,
         3.9398e-02, -8.3008e-03, -5.0011e-03, -5.9753e-02, -7.0374e-02,
        -5.8899e-02,  4.6997e-02, -1.2764e-02, -4.5013e-02, -6.6956e-02,
        -8.2932e-03, -9.7351e-02, -5.7312e-02,  2.4246e-02,  2.7573e-02,
         8.4412e-02,  2.1271e-02, -6.0120e-02,  3.0579e-02,  1.1597e-02,
        -2.7802e-02, -4.4785e-03, -5.0110e-02, -1.3818e-01,  7.9041e-02,
        -1.5991e-02,  8.0444e-02,  5.6122e-02,  5.9906e-02,  1.7410e-02,
        -2.2873e-02, -1.6037e-02, -1.7990e-02,  1.1192e-02, -6.5651e-03,
        -5.6641e-02, -3.1311e-02, -4.7119e-02,  3.1036e-02,  3.0746e-02,
        -2.7649e-02, -1.8997e-02, -8.8348e-03,  3.2837e-02, -1.2642e-02,
        -4.3427e-02,  2.9510e-02,  3.5553e-02,  1.5625e-01, -5.8746e-04,
         4.9171e-03, -3.4698e-02,  5.5420e-02, -2.7752e-04,  6.2286e-02,
         1.6617e-02,  2.9236e-02,  1.5701e-02, -7.1869e-03, -3.7445e-02,
        -9.3994e-02, -4.5013e-03,  4.1016e-02,  1.3718e-02, -1.7853e-02,
        -1.1890e-01,  7.6256e-03,  4.0161e-02, -2.3926e-02,  4.1080e-04,
         1.5808e-02, -5.0476e-02,  1.1414e-02,  1.1604e-02,  3.5172e-03,
         2.3056e-02, -1.6155e-03, -1.4661e-01,  1.0840e-01,  5.8632e-03,
        -3.1681e-03,  4.4670e-03,  7.0312e-02, -5.0262e-02,  2.8610e-02,
        -1.4076e-02,  2.7145e-02, -4.5502e-02,  1.8506e-01,  9.2651e-02,
        -9.4223e-03, -2.0615e-02, -1.0529e-01, -7.0068e-02,  2.2774e-03,
         1.4687e-03,  6.4575e-02, -7.9529e-02,  9.7504e-03, -3.1738e-02,
         2.2995e-02,  9.6313e-02, -3.4973e-02,  5.6305e-02,  2.4109e-02,
         1.1090e-01,  2.5208e-02,  5.4108e-02,  6.4087e-02, -4.2908e-02,
         4.9866e-02, -7.5623e-02,  6.5063e-02, -1.2109e-01,  1.1263e-03,
         6.6406e-02, -3.3169e-03, -5.4077e-02, -6.6101e-02, -1.1353e-01,
        -1.1301e-03, -1.9293e-03, -8.4925e-04, -2.2339e-02,  4.6936e-02,
         3.4210e-02,  1.7188e-01,  6.1722e-03, -2.8870e-02, -7.0229e-03,
        -3.8696e-02,  1.0388e-01, -3.9520e-02, -2.0962e-03, -3.4847e-03,
        -9.2773e-03,  4.3213e-02, -6.9153e-02, -9.6741e-02, -6.8665e-02,
        -4.8447e-03,  1.0272e-01,  4.5074e-02,  6.0577e-02,  1.6937e-02,
        -2.4384e-02, -3.6011e-02, -1.4380e-01,  1.3504e-02, -2.9160e-02,
         6.2103e-03, -1.5945e-02,  2.4826e-02, -7.5989e-02, -9.1064e-02,
        -1.1902e-02, -9.2224e-02,  1.1121e-01, -1.4575e-01, -8.7097e-02,
         1.0962e-01,  1.4091e-02,  3.6072e-02, -7.7087e-02, -1.7258e-02,
         1.7798e-01,  6.1096e-02,  3.0991e-02,  5.1384e-03,  7.5073e-03,
        -6.0547e-02, -1.4404e-02,  4.4312e-02, -3.7354e-02, -8.8196e-02,
        -2.9068e-02,  6.1829e-02,  2.6779e-03,  2.9480e-02, -1.2493e-03,
        -8.0490e-03,  9.5032e-02, -3.9856e-02, -8.0919e-04,  4.9927e-02,
         2.2186e-02, -8.4351e-02, -1.0162e-02, -1.1230e-02, -2.6367e-02,
        -2.2751e-02,  6.4819e-02, -2.9697e-03, -8.0933e-02, -7.4402e-02,
         6.3477e-03,  2.4918e-02,  5.3558e-02,  1.0841e-02,  5.6030e-02,
        -1.9897e-02, -4.6112e-02, -1.3649e-02, -2.1164e-02, -2.3987e-02,
        -8.1299e-02, -3.7174e-03,  1.9970e-03,  2.1500e-02, -5.3680e-02,
         1.4259e-02,  4.2694e-02, -1.6586e-02,  2.3865e-02, -1.6830e-02,
         3.2867e-02, -4.8523e-03, -2.7847e-02,  7.0068e-02,  7.8247e-02,
        -4.7211e-02, -2.8870e-02, -2.8976e-02,  2.7252e-02, -3.4698e-02,
         7.7454e-02,  5.8784e-03, -2.2171e-02,  1.4534e-03,  7.0618e-02,
         2.4338e-02, -1.5854e-02, -1.2006e-01,  4.3030e-02, -4.6204e-02,
        -2.8839e-02,  2.6733e-02,  5.2368e-02, -6.7017e-02, -4.7394e-02,
         1.7273e-02,  1.2238e-01, -3.8696e-02, -1.2024e-02,  1.2787e-02,
         2.5009e-02, -2.7908e-02, -1.8402e-02, -8.4229e-03,  4.4800e-02,
        -1.0620e-01, -1.5640e-02,  1.1096e-01,  1.2657e-02,  2.7981e-03,
         4.7028e-02, -4.5685e-02, -2.0401e-02, -4.3732e-02,  1.3330e-01,
         5.3894e-02,  4.1084e-03,  4.7913e-02, -5.8105e-02,  1.2711e-02,
        -5.1544e-02,  4.5357e-03,  2.0599e-02,  6.0501e-03, -3.2257e-02,
        -2.4629e-04, -5.0598e-02, -2.9053e-02, -1.4057e-03, -1.9592e-02,
        -1.6647e-02,  8.6548e-02,  7.0496e-02, -2.2934e-02,  1.1299e-02,
        -7.4348e-03, -3.6194e-02, -5.6519e-02,  4.8462e-02,  1.7462e-03,
         5.1689e-03,  3.4733e-03,  6.1264e-03, -2.7817e-02, -1.7883e-02,
         3.2166e-02,  2.4216e-02, -1.3107e-02,  8.0109e-03,  4.8492e-02,
         1.0706e-01, -4.6387e-02, -6.2744e-02,  1.4862e-02,  2.7237e-02,
        -3.7262e-02, -6.6162e-02,  2.9160e-02, -3.1067e-02,  2.0462e-02,
         3.0716e-02, -2.9926e-03, -7.0007e-02,  6.8016e-03, -4.8706e-02,
        -3.1555e-02, -9.3994e-02,  5.8258e-02, -1.3443e-02, -3.8818e-02,
         3.2715e-02,  4.1687e-02, -1.2177e-02,  1.3721e-01, -6.0669e-02,
        -3.5950e-02, -1.8494e-02,  5.8716e-02, -4.8737e-02,  2.0920e-02,
        -8.5602e-03,  1.5068e-02,  8.3923e-02,  1.0815e-01,  2.8076e-02,
        -1.1032e-02,  3.7842e-02, -1.0974e-01,  6.3782e-02,  2.7252e-02,
         3.5725e-03, -4.1389e-03,  8.4839e-03, -5.3497e-02,  2.1687e-03,
         2.1912e-02, -5.7678e-02, -3.8910e-02, -6.6467e-02, -6.0486e-02,
        -1.5186e-01, -2.4551e-02,  7.3303e-02, -9.4986e-03,  8.4686e-03,
         6.6650e-02,  2.5696e-02, -4.4922e-02,  2.6779e-02,  1.4046e-02,
         6.8604e-02,  5.0201e-02,  8.7219e-02, -1.9913e-02, -1.4990e-01,
         9.3994e-02, -1.6418e-02,  1.8054e-01, -2.7817e-02,  7.5607e-03,
        -1.5628e-04, -6.9885e-02,  6.6101e-02,  1.7349e-02,  1.2848e-02,
         7.2632e-02, -1.5854e-02, -8.6914e-02, -2.1759e-02,  2.9282e-02,
        -6.2828e-03, -4.2236e-02,  6.1981e-02,  7.0068e-02,  8.7708e-02,
         1.4258e-01, -6.2225e-02, -6.4026e-02,  1.5762e-02,  7.0984e-02,
        -3.8483e-02, -8.4152e-03,  8.7524e-02,  1.5190e-02,  5.1086e-02,
        -4.6509e-02,  3.1372e-02,  9.4604e-02,  2.6031e-02, -4.3884e-02,
        -1.2665e-03, -3.9101e-03,  3.9856e-02,  3.3356e-02,  1.4236e-02,
        -2.4948e-02, -5.5206e-02,  1.0849e-02,  5.9296e-02,  2.8305e-02,
        -5.7650e-04, -1.3367e-02, -4.3488e-02,  1.3008e-02,  2.3880e-03,
        -3.5553e-02, -7.6103e-04, -7.5722e-03, -5.9204e-02, -3.6499e-02,
         5.5054e-02, -6.0539e-03,  6.8604e-02, -3.7785e-03,  5.6305e-02,
         1.1078e-01,  3.9917e-02,  4.8065e-02,  1.3496e-02,  1.2769e-01,
        -8.7341e-02,  4.6661e-02,  6.2599e-03,  1.2825e-02, -2.7069e-02,
        -1.4758e-01, -5.8075e-02, -2.1240e-02, -1.3092e-02, -1.7893e-04,
         6.5796e-02, -4.2938e-02,  2.2583e-02,  7.1594e-02,  3.1403e-02,
         6.9702e-02,  2.9266e-02, -1.7033e-03, -3.6987e-02, -3.5156e-02,
        -4.2969e-02, -9.3140e-02, -1.0779e-01,  1.9547e-02,  9.1675e-02,
        -2.1179e-02, -8.6288e-03,  5.1605e-02, -6.3782e-02,  5.8472e-02,
        -5.2673e-02, -7.0496e-02,  4.6661e-02, -8.0505e-02,  1.1139e-01,
        -5.2643e-02,  1.3924e-02,  1.5320e-02,  7.1594e-02, -3.1708e-02,
        -1.2866e-01, -6.3721e-02, -3.7994e-03,  3.8055e-02, -1.1658e-02,
         1.4856e-01, -1.1304e-01,  6.6833e-03,  2.7573e-02,  1.1176e-01,
         6.7200e-02, -7.6752e-03, -1.3660e-01,  8.1406e-03,  3.2120e-03,
         1.0205e-01, -3.2074e-02, -1.2627e-02,  1.1725e-01, -8.2336e-02,
         6.0654e-03, -1.6556e-02, -6.8726e-02, -6.7993e-02,  1.6565e-01,
         6.3721e-02,  4.0588e-02,  1.1917e-02,  3.0766e-03, -1.1673e-02,
        -9.1187e-02,  7.8918e-02, -1.7624e-02,  1.2077e-02, -1.4641e-02,
         2.4689e-02, -1.6739e-02, -1.5625e-01, -6.1310e-02,  7.8552e-02,
         3.9215e-02, -1.1121e-01, -1.2335e-01,  4.9927e-02, -2.6764e-02,
        -6.4026e-02,  7.9712e-02, -3.7689e-02,  4.6356e-02, -9.7473e-02,
         5.1392e-02,  2.1729e-02, -4.0161e-02,  5.8746e-02, -5.9938e-04,
         6.2927e-02, -5.3673e-03,  5.6091e-02, -1.8204e-02, -1.4221e-02,
        -9.5825e-02, -7.9529e-02, -3.3508e-02,  5.3368e-03,  5.4901e-02,
        -2.1500e-02,  1.3367e-02, -4.6478e-02,  6.2332e-03,  3.3569e-02,
        -3.7567e-02,  5.4535e-02,  5.9296e-02, -5.1178e-02, -9.6985e-02,
        -6.1462e-02,  2.0050e-02, -7.4036e-02,  1.0553e-01,  3.2623e-02,
         1.3611e-02,  3.3447e-02,  7.0618e-02, -2.1805e-02,  8.0505e-02,
        -4.2542e-02, -8.7036e-02, -2.5833e-02,  1.4351e-02,  3.8666e-02],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[-0.0249, -0.0165, -0.0001,  ..., -0.0257,  0.0233, -0.0490],
        [ 0.0374,  0.0126,  0.0433,  ..., -0.0554,  0.0349,  0.0185],
        [ 0.0010,  0.0214, -0.0167,  ..., -0.0015, -0.0180,  0.0206],
        ...,
        [ 0.0217,  0.0153, -0.0330,  ..., -0.0202, -0.0318, -0.0172],
        [ 0.0252,  0.0077,  0.0079,  ..., -0.0082, -0.0523,  0.0023],
        [-0.0388, -0.0302,  0.0331,  ..., -0.0053,  0.0127, -0.0055]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([ 0.0140,  0.0825,  0.0055, -0.0186,  0.0721, -0.0184,  0.0814, -0.0233,
         0.0032,  0.0440,  0.0255, -0.0016, -0.0282,  0.0374,  0.0344,  0.0576,
        -0.0270, -0.0005, -0.0310,  0.0191,  0.0507,  0.1149, -0.0194,  0.0522,
         0.0569,  0.0159, -0.0162,  0.0243, -0.0266,  0.0432,  0.0782,  0.1217,
        -0.0444, -0.0383,  0.0448,  0.0029, -0.0187,  0.0150,  0.0864,  0.0289,
        -0.0130,  0.1042,  0.0062,  0.0196,  0.0595, -0.0195,  0.0023,  0.0778,
        -0.0462,  0.0161, -0.0110, -0.0265,  0.0490, -0.0328, -0.0115,  0.0074,
        -0.0357,  0.0174,  0.0119, -0.0362, -0.0106, -0.0155,  0.0196, -0.0539,
         0.0510,  0.0722,  0.0422,  0.0757, -0.0156,  0.0335,  0.0340, -0.0447,
         0.0286,  0.0667,  0.0112,  0.0516,  0.0698,  0.0620, -0.0370,  0.1394,
        -0.0111,  0.0638,  0.0709,  0.0375,  0.0812,  0.0356,  0.0429,  0.0815,
         0.0812,  0.1163,  0.0478, -0.0008,  0.0034,  0.0440, -0.0241,  0.0787,
         0.0189,  0.0579, -0.0031,  0.0848, -0.0148, -0.0617, -0.0364, -0.0186,
        -0.0318,  0.0206,  0.0221,  0.0242, -0.0637,  0.0025,  0.0457,  0.0623,
        -0.0223, -0.0026, -0.0121, -0.0313,  0.0091,  0.0634, -0.0433, -0.0104,
        -0.1235, -0.0358,  0.0607,  0.0060, -0.0189,  0.0200, -0.0152,  0.0213,
        -0.0416,  0.0550,  0.0094,  0.1075, -0.0449,  0.0537, -0.0518, -0.0077,
         0.0322, -0.0149, -0.0425, -0.0056, -0.0228, -0.0421,  0.0210, -0.0096,
         0.0243, -0.0243, -0.0003, -0.0231,  0.0244,  0.0477, -0.0943, -0.0282,
         0.0432,  0.0194,  0.0002, -0.0045,  0.0258, -0.0686, -0.0057, -0.0617,
        -0.0186,  0.0476, -0.0289, -0.0433, -0.0157, -0.0501,  0.0286,  0.0766,
         0.0106, -0.0875,  0.0073,  0.0435,  0.0127, -0.0114,  0.0680, -0.0583,
         0.0441, -0.0676,  0.0886, -0.0212,  0.0140, -0.0072,  0.0038, -0.0386,
        -0.0040,  0.0610,  0.0301, -0.1047, -0.0323, -0.0484,  0.0256, -0.0528,
         0.0031, -0.0471,  0.0306, -0.0867,  0.0050, -0.1073, -0.0764, -0.0224,
        -0.1208, -0.1426,  0.0043,  0.0262, -0.1576, -0.0490,  0.0593,  0.0371,
        -0.1059, -0.0862, -0.0024, -0.0820, -0.0379, -0.0348, -0.0723, -0.0675,
        -0.0562,  0.0356, -0.0245, -0.0778, -0.0194, -0.0359, -0.0742,  0.0275,
        -0.0357, -0.0638,  0.0485, -0.0886, -0.0668, -0.0078,  0.0814, -0.0680,
        -0.0018, -0.0513,  0.0867, -0.0170,  0.0349,  0.0576, -0.0568, -0.0166,
         0.0474, -0.0826,  0.0093, -0.0918,  0.0108, -0.0450, -0.0161,  0.0264,
         0.0381, -0.1437, -0.0545,  0.0269,  0.0434, -0.0261, -0.0299, -0.1144,
         0.2314, -0.0767,  0.0356, -0.0059,  0.1060, -0.0510,  0.0124, -0.0017,
        -0.0196, -0.0998,  0.0233, -0.1707,  0.0135,  0.0214, -0.0446, -0.0977,
        -0.0536, -0.0889,  0.0253, -0.0587, -0.0147, -0.0072, -0.0448, -0.0222,
         0.0222, -0.0778,  0.0357, -0.0360, -0.0062, -0.0564,  0.0903,  0.0119,
         0.0144, -0.0137,  0.0395, -0.0498, -0.0193, -0.0910,  0.1093, -0.0354,
         0.0090, -0.0818, -0.0399, -0.0793,  0.0395,  0.0216,  0.0891, -0.1614,
         0.0560,  0.0003, -0.0330, -0.1362,  0.0598, -0.1244,  0.0741,  0.0037,
        -0.0306, -0.0689,  0.0992, -0.0306, -0.0301, -0.0946,  0.0562, -0.0204,
         0.0172, -0.0561, -0.0182, -0.0254,  0.0226,  0.0356,  0.0141, -0.0704,
         0.0578, -0.0862,  0.1097, -0.1606, -0.0364, -0.1135, -0.0565,  0.0233,
         0.0027, -0.0534, -0.0057, -0.0025,  0.0371, -0.0006,  0.0109, -0.0496,
         0.0915, -0.0550,  0.0347,  0.0064, -0.0156,  0.0288,  0.1069, -0.1179,
         0.0995, -0.0841,  0.0193, -0.0353,  0.0415, -0.1196, -0.0038, -0.0331,
         0.0709, -0.1069, -0.0304, -0.0385,  0.0485, -0.1257,  0.1059, -0.0251,
        -0.0031, -0.0092,  0.0447,  0.0160,  0.0702, -0.0908, -0.0345, -0.0281,
         0.0109, -0.0694,  0.0948, -0.1339, -0.0094, -0.0659, -0.0054, -0.0451,
         0.0949, -0.0191,  0.0216, -0.0821,  0.0221, -0.1792,  0.0470, -0.0059,
        -0.0867,  0.0201,  0.0136,  0.0399,  0.0857, -0.0601,  0.0443,  0.0166,
         0.0779, -0.0779,  0.0382, -0.0498,  0.0070,  0.0026,  0.1103, -0.0974,
         0.0393, -0.2145,  0.0955, -0.1294,  0.1011, -0.0380,  0.0609, -0.1370,
         0.0217, -0.0461,  0.0523, -0.0055,  0.1285, -0.0635,  0.0411, -0.0739,
         0.0746, -0.1646,  0.0628,  0.0396, -0.0184, -0.0552,  0.0081, -0.0605,
         0.1067, -0.0428,  0.0447, -0.0947,  0.0840, -0.0713,  0.0177, -0.1238,
         0.0386, -0.0271,  0.0195, -0.0037,  0.0587, -0.0677,  0.0514, -0.0913,
         0.0941,  0.0006,  0.0081,  0.0259,  0.0361, -0.0320,  0.0683,  0.0038,
        -0.0163, -0.0275,  0.0384, -0.0352,  0.1225, -0.0817,  0.1036, -0.0948,
        -0.0093,  0.0673,  0.0367, -0.0606,  0.0764,  0.0742,  0.0971,  0.0029,
        -0.0105, -0.0749,  0.0409, -0.1051,  0.1019,  0.0078,  0.0745,  0.0185,
         0.0251, -0.0594,  0.0649,  0.0638, -0.0160,  0.0105,  0.0378,  0.0118,
         0.0662, -0.0325,  0.1442, -0.0192, -0.0866,  0.0496,  0.1583, -0.1005,
         0.0348, -0.0320,  0.1101, -0.0202,  0.0056, -0.0064,  0.0245,  0.0199,
         0.0373, -0.0413, -0.0208, -0.0350,  0.0475,  0.0464, -0.0278, -0.0952,
         0.0216, -0.0756,  0.0393, -0.0797,  0.0628, -0.0446, -0.0014,  0.0308,
        -0.0475, -0.0061,  0.0800, -0.0956,  0.0557, -0.1385,  0.0293,  0.0344,
         0.0118,  0.0634,  0.0296, -0.0944,  0.0709, -0.0409, -0.0295, -0.0756,
         0.0514, -0.1440,  0.0410, -0.0034,  0.0519, -0.0217, -0.0136, -0.0789,
         0.0665,  0.0746,  0.0261,  0.0243,  0.0694, -0.0558,  0.0207, -0.0158,
         0.0367, -0.0006, -0.0563, -0.0798,  0.0204, -0.0713,  0.0782, -0.0019,
         0.1648,  0.0843,  0.0193, -0.1310,  0.0228, -0.1255,  0.0161, -0.1138,
         0.0693, -0.1138,  0.0792, -0.1074,  0.1730, -0.0799, -0.0486, -0.0695,
        -0.0920, -0.0223,  0.0384, -0.1010,  0.0503, -0.0594,  0.0391, -0.0641,
         0.0446,  0.0013, -0.0574, -0.0255, -0.0007, -0.0719,  0.0431,  0.0715,
        -0.0161, -0.0286, -0.0014,  0.0282,  0.0994, -0.1519,  0.0956, -0.0101,
         0.0855, -0.1010,  0.0653, -0.1043, -0.0089, -0.0569,  0.0690, -0.0385,
         0.1030, -0.0289,  0.0401, -0.0439,  0.0044, -0.0486,  0.0187,  0.0459,
         0.0724,  0.0505,  0.0047,  0.0070,  0.0729, -0.0338,  0.0117, -0.0100,
        -0.0095,  0.0093,  0.0328,  0.0125,  0.1086, -0.0159, -0.0091, -0.0402,
         0.0095, -0.0483, -0.0239, -0.1483,  0.0688, -0.0762,  0.0238,  0.0006],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([0.7271, 0.7705, 0.7671, 0.7871, 0.7988, 0.7534, 0.8564, 0.8135, 0.8296,
        0.7881, 0.8311, 0.8159, 0.7905, 0.7529, 0.7500, 0.7812, 0.7661, 0.8374,
        0.8496, 0.8540, 0.7935, 0.7915, 0.8804, 0.7837, 0.7900, 0.7939, 0.8340,
        0.7656, 0.8203, 0.7847, 0.8403, 0.8149, 0.8076, 0.8306, 0.8086, 0.8608,
        0.7939, 0.7573, 0.8071, 0.7432, 0.9111, 0.8013, 0.7622, 0.8667, 0.8018,
        0.8271, 0.8120, 0.7632, 0.8169, 0.8506, 0.8477, 0.8247, 0.8521, 0.8335,
        0.8252, 0.8940, 0.8804, 0.8564, 0.8193, 0.7866, 0.8721, 0.7759, 0.8252,
        0.7959, 0.8042, 0.8735, 0.8413, 0.7104, 0.7988, 0.8208, 0.8037, 0.8394,
        0.7515, 0.8120, 0.7559, 0.8081, 0.8076, 0.7617, 0.7959, 0.7759, 0.8257,
        0.8521, 0.8149, 0.8589, 0.8452, 0.7588, 0.7920, 0.8125, 0.8291, 0.8047,
        0.7061, 0.8267, 0.8555, 0.8442, 0.8188, 0.7070, 0.7744, 0.7710, 0.9053,
        0.7739, 0.9272, 0.8223, 0.8867, 0.8384, 0.9116, 0.8091, 0.8472, 0.7119,
        0.8750, 0.8652, 0.8623, 0.7925, 0.9126, 0.8301, 0.7783, 0.8232, 0.9126,
        0.8164, 0.9194, 0.7715, 0.9346, 0.7534, 0.9224, 0.8364, 0.9590, 0.8179,
        0.9116, 0.8931, 0.9111, 0.7480, 0.7451, 0.8521, 0.8794, 0.8330, 0.8774,
        0.8906, 0.8325, 0.8555, 0.7681, 0.8491, 0.9043, 0.9023, 0.8730, 0.8257,
        0.9434, 0.8496, 0.8848, 0.9102, 0.8516, 0.8789, 0.9009, 0.9673, 0.9507,
        0.8550, 0.9434, 0.9023, 0.8560, 0.8940, 0.8921, 0.8970, 0.8052, 0.8882,
        0.7949, 0.9551, 0.8608, 0.9243, 0.8652, 0.6958, 0.8696, 0.9614, 0.8896,
        0.8965, 0.9067, 0.9360, 0.8462, 0.9209, 0.8120, 0.9683, 0.6797, 0.8174,
        0.9229, 0.8809, 0.8818, 1.0352, 0.9121, 0.9077, 0.7710, 0.8794, 0.8638,
        0.9160, 0.7383, 0.9141, 0.8115, 0.8950, 0.7271, 0.9253, 0.8521, 0.8643,
        0.8462, 0.9087, 0.8779, 0.8940, 0.7495, 0.9497, 0.8516, 0.9189, 0.8496,
        0.8574, 0.8462, 0.9443, 0.8613, 0.8921, 0.8955, 0.9175, 0.8901, 0.9395,
        0.8940, 0.8354, 0.9155, 0.9531, 0.8433, 0.9556, 0.8584, 0.8164, 0.9146,
        0.9033, 0.8096, 0.9468, 0.8257, 0.9375, 0.9058, 0.9277, 0.8608, 0.9204,
        0.7383, 0.8672, 0.8096, 0.9614, 0.8667, 0.9028, 0.8584, 0.9507, 0.8286,
        0.9243, 0.7505, 0.9492, 0.8027, 0.9106, 0.8555, 0.8906, 0.8354, 0.6455,
        0.8203, 0.9033, 0.8989, 0.9473, 0.6157, 0.9326, 0.8901, 0.9004, 0.8188,
        0.8945, 0.8130, 0.9224, 0.8555, 0.9785, 0.8281, 0.9609, 0.8623, 0.9761,
        0.8257, 0.8892, 0.8311, 0.8809, 0.8247, 0.9082, 0.7720, 0.9155, 0.8726,
        0.9575, 0.8345, 0.8809, 0.7646, 0.9072, 0.8232, 0.8882, 0.8096, 0.8232,
        0.7891, 0.9185, 0.8198, 0.9214, 0.8564, 0.9331, 0.8076, 0.9033, 0.8550,
        0.8843, 0.7891, 0.9541, 0.8579, 0.9438, 0.8218, 0.8403, 0.7456, 0.9189,
        0.8555, 0.9497, 0.7905, 0.9668, 0.8057, 0.8374, 0.8350, 0.9082, 0.8618,
        0.8721, 0.8477, 0.9072, 0.7529, 0.8994, 0.8140, 0.9531, 0.7886, 0.9121,
        0.8398, 0.9043, 0.8667, 0.9336, 0.8584, 0.9707, 0.7773, 0.8979, 0.8794,
        0.9399, 0.8398, 0.7808, 0.8438, 0.8950, 0.8037, 0.9038, 0.8403, 0.9429,
        0.8237, 0.9429, 0.8032, 0.8999, 0.8682, 0.8779, 0.8350, 0.9297, 0.8184,
        0.9243, 0.7832, 0.9775, 0.8652, 0.9277, 0.8550, 0.8921, 0.8296, 0.8203,
        0.8115, 0.9243, 0.8081, 0.9097, 0.7646, 0.9395, 0.7441, 0.8706, 0.7905,
        0.8413, 0.8457, 0.9180, 0.8486, 0.9497, 0.7979, 0.9771, 0.8306, 0.8916,
        0.8364, 0.9565, 0.8950, 1.0049, 0.8052, 0.9307, 0.8042, 0.8574, 0.8179,
        0.8882, 0.8193, 0.8696, 0.8213, 0.8301, 0.8359, 0.8423, 0.8394, 0.8315,
        0.8218, 0.9087, 0.8140, 0.8301, 0.8032, 0.9473, 0.8105, 0.9312, 0.8452,
        0.8740, 0.8799, 0.9453, 0.8491, 0.9580, 0.8379, 0.9478, 0.7461, 0.8945,
        0.8984, 0.9248, 0.6821, 0.8779, 0.8062, 0.9355, 0.8740, 0.9170, 0.8115,
        0.8833, 0.8389, 0.9185, 0.8325, 0.7524, 0.8486, 0.8857, 0.8350, 0.9141,
        0.7227, 0.9062, 0.8032, 0.9424, 0.8325, 0.9390, 0.8252, 0.9604, 0.8022,
        0.9180, 0.8018, 0.8511, 0.8115, 0.8979, 0.7778, 0.8809, 0.7495, 0.9062,
        0.8384, 0.9282, 0.7798, 0.8125, 0.8862, 0.9326, 0.8403, 0.8892, 0.8931,
        0.8755, 0.7451, 0.8950, 0.7739, 0.9395, 0.8130, 0.9185, 0.7393, 0.9854,
        0.8750, 0.8262, 0.8091, 0.8999, 0.8335, 0.9219, 0.8809, 0.9238, 0.8511,
        0.8564, 0.8271, 0.9419, 0.7705, 0.9561, 0.7681, 0.9219, 0.7007, 0.9199,
        0.7959, 0.9253, 0.7954, 0.9497, 0.8433, 0.9141, 0.7246, 0.7412, 0.8081,
        0.9321, 0.7803, 0.9302, 0.8301, 0.8799, 0.7754, 0.8501, 0.8164, 0.8813,
        0.7979, 0.9058, 0.8247, 0.9121, 0.7114, 0.8789, 0.7949, 0.8682, 0.8003,
        0.9634, 0.8198, 0.9551, 0.8857, 0.8896, 0.8472, 0.8965, 0.7788, 0.9482,
        0.7979, 0.9092, 0.7461, 0.9834, 0.7905, 0.9360, 0.8423, 0.9404, 0.7339,
        0.9058, 0.8037, 0.8877, 0.8516, 0.9346, 0.8335, 0.9346, 0.7993, 0.9116,
        0.8140, 0.9146, 0.8223, 0.9126, 0.7764, 0.9478, 0.8164, 0.9282, 0.8774,
        0.8882, 0.7891, 0.9541, 0.7676, 0.8013, 0.8633, 0.9468, 0.8486, 0.9150,
        0.7910, 0.9058, 0.8325, 0.9199, 0.7881, 0.9683, 0.7935, 0.9824, 0.8521,
        0.9336, 0.7910, 0.9409, 0.8154, 0.9341, 0.6792, 0.8687, 0.8208, 0.9438,
        0.8794, 0.9395, 0.8662, 0.9121, 0.8188, 0.9131, 0.8145, 0.8789, 0.7915,
        0.9316, 0.8267, 0.9375, 0.8281, 0.9360, 0.8306, 0.9272, 0.8335, 0.8979,
        0.8208, 0.8994, 0.7710, 0.9253, 0.8325, 0.9282, 0.8281, 0.8857, 0.7666,
        0.9341, 0.7642, 0.8652, 0.8335, 0.9268, 0.8193, 0.9028, 0.8423, 0.9043,
        0.8271, 0.9224, 0.7803, 0.9712, 0.8813, 0.6187, 0.7373, 0.7988, 0.8364,
        0.9766, 0.8584, 0.9082, 0.8184, 0.8926, 0.7969, 0.8569, 0.8770, 0.9731,
        0.8086, 0.8823, 0.8105, 0.9292, 0.7495, 0.9766, 0.7754, 0.9258, 0.7812,
        0.8950], device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([-0.0833, -0.1333, -0.1037, -0.0952, -0.1188, -0.1088, -0.0881, -0.0984,
        -0.1041, -0.0958, -0.1092, -0.0738, -0.0935, -0.0897, -0.1078, -0.1100,
        -0.0707, -0.0776, -0.1086, -0.0775, -0.1287, -0.0432, -0.0607, -0.0665,
        -0.0969, -0.0747, -0.0634, -0.0801, -0.1038, -0.1121, -0.0820, -0.1177,
        -0.1051, -0.0714, -0.0544, -0.0646, -0.0990, -0.1335, -0.1071, -0.1471,
        -0.0494, -0.0868, -0.1281, -0.1006, -0.0992, -0.1271, -0.1050, -0.0938,
        -0.1022, -0.0717, -0.0989, -0.1122, -0.0668, -0.1044, -0.1020, -0.0623,
        -0.0811, -0.0799, -0.0812, -0.0940, -0.0848, -0.1082, -0.0614, -0.0971,
        -0.1013, -0.0854, -0.0950, -0.0811, -0.0753, -0.0584, -0.1011, -0.0659,
        -0.1089, -0.0807, -0.1356, -0.0778, -0.1000, -0.1040, -0.1096, -0.0627,
        -0.0753, -0.0556, -0.0607, -0.0950, -0.0865, -0.0538, -0.1495, -0.0697,
        -0.1289, -0.0632, -0.1595, -0.0911, -0.1141, -0.0580, -0.1153, -0.1534,
        -0.1210, -0.0725, -0.1432, -0.1118, -0.0558, -0.0900, -0.1396, -0.0715,
        -0.1129, -0.0605, -0.1824, -0.1183, -0.0780, -0.0775, -0.1013, -0.0952,
        -0.0984, -0.1237, -0.1802, -0.1036, -0.1116, -0.0942, -0.1137, -0.1054,
        -0.1337, -0.1069, -0.1135, -0.1245, -0.1108, -0.0837, -0.1841, -0.0407,
        -0.1693, -0.1780, -0.1292, -0.0738, -0.1375, -0.1248, -0.1331, -0.0828,
        -0.1749, -0.0665, -0.1663, -0.0889, -0.1016, -0.0890, -0.1023, -0.0611,
        -0.0944, -0.1028, -0.1460, -0.1041, -0.1733, -0.1345, -0.1677, -0.1130,
        -0.1592, -0.1060, -0.1191, -0.1484, -0.1820, -0.1023, -0.1610, -0.1272,
        -0.1771, -0.1134, -0.2092, -0.1127, -0.1571, -0.1002, -0.1451, -0.1656,
        -0.1247, -0.1090, -0.0984, -0.1360, -0.0837, -0.1797, -0.0993, -0.1377,
        -0.1558, -0.2000, -0.2189, -0.1133, -0.1581, -0.1115, -0.1610, -0.1794,
        -0.1469, -0.1953, -0.0908, -0.1293, -0.1158, -0.1635, -0.1552, -0.1282,
        -0.2053, -0.1046, -0.1533, -0.1527, -0.1261, -0.1315, -0.1603, -0.1151,
        -0.0903, -0.1287, -0.1362, -0.1405, -0.1318, -0.1501, -0.0582, -0.1512,
        -0.0959, -0.1110, -0.0652, -0.1046, -0.1037, -0.2140, -0.1277, -0.1157,
        -0.1194, -0.1090, -0.0958, -0.1015, -0.1042, -0.1235, -0.0931, -0.1530,
        -0.1068, -0.0987, -0.0698, -0.1416, -0.0760, -0.1550, -0.1057, -0.1214,
        -0.0972, -0.1428, -0.1106, -0.1823, -0.1307, -0.1385, -0.1075, -0.0878,
        -0.1404, -0.2520, -0.0323, -0.1059, -0.2177, -0.1361, -0.1298, -0.1266,
        -0.1146, -0.1045, -0.1375, -0.1498, -0.0406, -0.1260, -0.0952, -0.1761,
        -0.1918, -0.1584, -0.1301, -0.1162, -0.0738, -0.1049, -0.1050, -0.1256,
        -0.0938, -0.1797, -0.0877, -0.1520, -0.1140, -0.1700, -0.1060, -0.0826,
        -0.0723, -0.0739, -0.1043, -0.1420, -0.1555, -0.1305, -0.0771, -0.1528,
        -0.0819, -0.2047, -0.1175, -0.2142, -0.1071, -0.1348, -0.1676, -0.1259,
        -0.1270, -0.0682, -0.0903, -0.1625, -0.0829, -0.1339, -0.1054, -0.2369,
        -0.0643, -0.1221, -0.0977, -0.1332, -0.1360, -0.1852, -0.0893, -0.1925,
        -0.1030, -0.1515, -0.1238, -0.1159, -0.1081, -0.1482, -0.0958, -0.0745,
        -0.0930, -0.1652, -0.0630, -0.1104, -0.1766, -0.1337, -0.1532, -0.1190,
        -0.0787, -0.1781, -0.0927, -0.0999, -0.1033, -0.1525, -0.0826, -0.1163,
        -0.1113, -0.2258, -0.1216, -0.0862, -0.1042, -0.1991, -0.1394, -0.2452,
        -0.0794, -0.1221, -0.0668, -0.1455, -0.0810, -0.1882, -0.1226, -0.1167,
        -0.1389, -0.1096, -0.1020, -0.2019, -0.1082, -0.1230, -0.1305, -0.1257,
        -0.0908, -0.1530, -0.1011, -0.1453, -0.0804, -0.2235, -0.1346, -0.1376,
        -0.1152, -0.1379, -0.1169, -0.1685, -0.1427, -0.1268, -0.1145, -0.0534,
        -0.0720, -0.1250, -0.0933, -0.1318, -0.0721, -0.0948, -0.1137, -0.1482,
        -0.0673, -0.0790, -0.0781, -0.1545, -0.0823, -0.1779, -0.0645, -0.1635,
        -0.1357, -0.0916, -0.0986, -0.1052, -0.1572, -0.1342, -0.0747, -0.2629,
        -0.0827, -0.1504, -0.0930, -0.1732, -0.0970, -0.0990, -0.0979, -0.2164,
        -0.0899, -0.1392, -0.0982, -0.1194, -0.1353, -0.0870, -0.1050, -0.1401,
        -0.0649, -0.1049, -0.1102, -0.1128, -0.0818, -0.1223, -0.1004, -0.0839,
        -0.1302, -0.1061, -0.0660, -0.1118, -0.0718, -0.1284, -0.1026, -0.1019,
        -0.0867, -0.1483, -0.0978, -0.2070, -0.1299, -0.0991, -0.1588, -0.1169,
        -0.1716, -0.0858, -0.0911, -0.0925, -0.1266, -0.1256, -0.0717, -0.2089,
        -0.0782, -0.2133, -0.0907, -0.1040, -0.1099, -0.1031, -0.1094, -0.0970,
        -0.1538, -0.1709, -0.1068, -0.1714, -0.1281, -0.1904, -0.1204, -0.1339,
        -0.0881, -0.1644, -0.0584, -0.0911, -0.1649, -0.1041, -0.0912, -0.1759,
        -0.1097, -0.1384, -0.1160, -0.1426, -0.1075, -0.1412, -0.0808, -0.1515,
        -0.1399, -0.1481, -0.0925, -0.0919, -0.0690, -0.0742, -0.0811, -0.1426,
        -0.1290, -0.1544, -0.1617, -0.1033, -0.1907, -0.0979, -0.0829, -0.1445,
        -0.0919, -0.1345, -0.0536, -0.1718, -0.2085, -0.2361, -0.0964, -0.1326,
        -0.0958, -0.1733, -0.0977, -0.0930, -0.1304, -0.2200, -0.0706, -0.1067,
        -0.0594, -0.1798, -0.0875, -0.1129, -0.1747, -0.1929, -0.1024, -0.0637,
        -0.0994, -0.1166, -0.1221, -0.1517, -0.0898, -0.1436, -0.0939, -0.0950,
        -0.1191, -0.1445, -0.1272, -0.0923, -0.1390, -0.1787, -0.1220, -0.1274,
        -0.0876, -0.1163, -0.1095, -0.1139, -0.0877, -0.1364, -0.0465, -0.1669,
        -0.0487, -0.1425, -0.0785, -0.1449, -0.1356, -0.1109, -0.1138, -0.1172,
        -0.0795, -0.1809, -0.0950, -0.1421, -0.0596, -0.1365, -0.0741, -0.1681,
        -0.0828, -0.2374, -0.0614, -0.1619, -0.1172, -0.1445, -0.0838, -0.1512,
        -0.1376, -0.2109, -0.1501, -0.1620, -0.0860, -0.1459, -0.0558, -0.1564,
        -0.0419, -0.1027, -0.0989, -0.1273, -0.1837, -0.0662, -0.0779, -0.1713,
        -0.0828, -0.1439, -0.0462, -0.0888, -0.0978, -0.1401, -0.0910, -0.0896,
        -0.1039, -0.1151, -0.1136, -0.1434, -0.1060, -0.1301, -0.0939, -0.2289,
        -0.1206, -0.1332, -0.0734, -0.1270, -0.1121, -0.1074, -0.1444, -0.1106,
        -0.0912, -0.0757, -0.1038, -0.1458, -0.1231, -0.1313, -0.0916, -0.1334,
        -0.0807, -0.0967, -0.1099, -0.1005, -0.1061, -0.1857, -0.0981, -0.2096,
        -0.0723, -0.2573, -0.0856, -0.1124, -0.0939, -0.1420, -0.0685, -0.1381,
        -0.0902, -0.1412, -0.1071, -0.1132, -0.1375, -0.1542, -0.1255, -0.1530,
        -0.1061, -0.1036, -0.0943, -0.1459, -0.1058, -0.0964, -0.0923, -0.1537],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[ 0.1542, -0.0099,  0.0876,  ..., -0.0002,  0.0199,  0.0027],
        [ 0.1439, -0.0505,  0.0233,  ...,  0.0446,  0.0349, -0.0168],
        [ 0.0314,  0.0381,  0.0492,  ..., -0.0304, -0.0080,  0.0030],
        ...,
        [-0.0155, -0.0185,  0.0126,  ..., -0.0182,  0.0204,  0.0360],
        [-0.0004,  0.0420, -0.0066,  ..., -0.0117,  0.0069, -0.0486],
        [-0.0469,  0.0038, -0.0334,  ..., -0.0287,  0.0250, -0.0523]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[ 0.1829,  0.0580,  0.0845,  ...,  0.0183, -0.0244,  0.0551],
        [ 0.0972,  0.0700,  0.0616,  ..., -0.0026,  0.0211,  0.0162],
        [ 0.0388,  0.0034,  0.0331,  ..., -0.0195,  0.0410,  0.0015],
        ...,
        [ 0.0645, -0.0328, -0.0606,  ...,  0.0143,  0.0320, -0.0242],
        [ 0.0135,  0.0006,  0.0403,  ...,  0.0346,  0.0267,  0.0254],
        [ 0.0369,  0.0142, -0.0376,  ...,  0.0493, -0.0297, -0.0435]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[-3.0701e-02, -2.7435e-02, -5.3101e-03,  ...,  9.4376e-03,
          7.2241e-04,  2.1458e-05],
        [-1.2581e-02, -4.9316e-02, -5.6244e-02,  ...,  4.3823e-02,
         -1.1322e-02, -1.4210e-03],
        [-2.7130e-02, -1.3008e-02, -1.1719e-02,  ...,  1.5411e-02,
         -8.4991e-03, -1.4030e-02],
        ...,
        [-5.0781e-02, -8.6670e-03, -4.6326e-02,  ..., -8.7402e-02,
          1.5282e-02,  4.1771e-03],
        [ 5.5450e-02, -4.3823e-02, -1.4809e-02,  ..., -3.5980e-02,
         -4.7699e-02,  8.3008e-03],
        [ 5.6335e-02,  1.1978e-03,  4.5776e-03,  ..., -3.5675e-02,
         -2.6642e-02, -3.2990e-02]], device='cuda:0', dtype=torch.float16,
       requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[-0.0207, -0.0042,  0.0251,  ...,  0.0440,  0.0515, -0.0095],
        [ 0.0294,  0.0171, -0.0105,  ...,  0.0006,  0.0185, -0.0243],
        [-0.0152, -0.0357,  0.0155,  ..., -0.0273, -0.0801,  0.0114],
        ...,
        [ 0.0303,  0.0468,  0.0350,  ..., -0.0004,  0.0374, -0.0175],
        [ 0.0210, -0.0161, -0.0032,  ..., -0.0017,  0.0298,  0.0282],
        [ 0.0494,  0.0049,  0.0013,  ...,  0.0407, -0.0194, -0.0368]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([ 4.6539e-03, -1.2962e-02,  3.7708e-03, -1.7929e-02,  3.3478e-02,
        -8.1711e-03, -9.7580e-03, -2.3022e-03, -2.3270e-02, -1.2093e-02,
        -8.6441e-03,  1.4244e-02, -3.6835e-02, -1.4877e-02, -2.6260e-02,
        -6.7902e-03, -2.3407e-02,  8.3618e-03,  1.3588e-02, -8.8730e-03,
        -1.7181e-02,  2.5146e-02, -3.3360e-03,  1.7776e-02,  7.4120e-03,
        -1.0201e-02,  1.6037e-02, -2.7344e-02, -1.1246e-02,  8.6594e-03,
        -2.9106e-03, -5.9280e-03,  1.8606e-03, -9.7809e-03,  3.0991e-02,
         2.2278e-02, -2.3163e-02, -1.1803e-02,  1.3649e-02, -1.1208e-02,
         1.2827e-03,  2.8198e-02, -3.3081e-02,  3.6621e-02,  2.1835e-02,
        -2.2449e-03, -2.4048e-02,  4.8141e-03, -2.4521e-02, -2.5513e-02,
        -1.4275e-02, -5.1971e-02,  3.4119e-02, -3.0563e-02, -4.3457e-02,
        -1.6907e-02, -1.9394e-02,  1.4130e-02,  1.1803e-02, -4.7089e-02,
         1.1009e-02, -5.8746e-02,  3.7018e-02, -3.9978e-02,  8.6899e-03,
        -3.2959e-02,  8.4076e-03, -4.1321e-02,  2.4124e-02, -1.6724e-02,
        -1.2817e-02,  2.8610e-02,  2.5055e-02,  1.0193e-02, -2.5085e-02,
        -2.1805e-02,  1.5762e-02,  2.5192e-02, -1.6159e-02, -1.6632e-02,
        -6.1951e-03,  2.1988e-02,  1.1818e-02, -4.2915e-04,  3.6469e-02,
        -8.2855e-03, -1.1978e-02,  1.9989e-02, -6.7444e-02, -2.3758e-02,
        -6.3171e-02, -8.6746e-03, -2.9816e-02, -2.0695e-03, -1.4725e-02,
        -6.5491e-02, -4.0344e-02,  8.6498e-04,  1.2421e-02,  2.2781e-02,
         4.3671e-02, -2.9335e-03,  9.9945e-04,  2.7969e-02,  1.3664e-02,
         4.6875e-02,  9.1171e-03,  1.4862e-02, -1.7624e-02,  6.8436e-03,
         3.5797e-02, -7.4158e-03,  2.3468e-02,  2.4750e-02,  1.7365e-02,
        -1.6985e-03,  2.1530e-02,  9.6588e-03,  2.1484e-02,  7.0143e-04,
        -1.5533e-02, -3.6682e-02, -3.9635e-03,  1.0651e-02,  9.9106e-03,
        -1.4412e-02, -1.4008e-02, -5.2719e-03,  1.0948e-02, -1.9409e-02,
         5.7755e-03,  1.7914e-02,  2.4643e-02,  5.6267e-03,  1.9135e-02,
        -7.9956e-03, -1.4015e-02,  4.7150e-02, -6.6040e-02,  3.9558e-03,
         2.7542e-02,  1.3016e-02,  2.6894e-03, -5.0964e-03,  6.7329e-04,
         3.1952e-02,  9.3613e-03,  6.0005e-03, -1.4290e-02, -2.0065e-02,
        -3.5187e-02, -3.1174e-02, -3.1647e-02, -1.5320e-02,  2.7206e-02,
        -4.2610e-03,  1.2077e-02, -3.2837e-02,  1.9424e-02, -5.8868e-02,
        -4.8676e-02, -8.4839e-03, -2.8229e-02,  9.6130e-03,  1.4069e-02,
         1.5068e-02, -2.4826e-02,  5.0598e-02,  3.0762e-02,  3.9093e-02,
         1.3687e-02, -7.0724e-03, -2.3422e-02, -3.0685e-02,  1.7624e-02,
         4.5815e-03,  2.9037e-02, -5.8289e-02,  4.5357e-03, -5.1689e-03,
         4.9957e-02, -3.1082e-02,  2.5879e-02, -2.8824e-02,  2.5921e-03,
         3.4821e-02, -1.8875e-02, -3.8086e-02, -2.0309e-02,  2.6154e-02,
        -1.4481e-02, -8.3542e-04,  1.8721e-03, -1.4982e-03, -4.2542e-02,
         1.4214e-02,  2.6207e-03,  7.8125e-03,  1.3519e-02, -2.7981e-03,
         8.7204e-03, -1.7349e-02, -3.2990e-02,  1.7715e-02,  5.1832e-04,
        -1.6312e-02,  2.3117e-02, -4.5593e-02, -2.6718e-02,  2.7039e-02,
        -4.8141e-03, -1.8295e-02, -6.5308e-03,  1.9104e-02, -4.7624e-05,
        -7.1144e-03, -1.2108e-02,  5.5817e-02,  2.0587e-04,  7.4539e-03,
         3.2257e-02,  8.6746e-03, -1.5198e-02, -2.3651e-03, -2.0554e-02,
        -1.9083e-03,  3.3630e-02, -6.1646e-02,  2.1423e-02,  3.9978e-02,
         4.3488e-02, -7.9956e-03, -2.3239e-02,  3.3997e-02, -1.0391e-02,
         8.8425e-03, -2.0386e-02, -2.5894e-02,  1.1452e-02,  2.6962e-02,
        -1.6815e-02, -5.5267e-02,  3.9482e-03,  1.4740e-02, -2.3453e-02,
        -4.4098e-02,  4.4327e-03,  2.7725e-02, -3.4790e-02, -5.9509e-03,
        -1.4778e-02,  4.8706e-02,  5.2246e-02,  1.6891e-02, -6.0425e-03,
        -6.2042e-02,  1.2396e-01, -1.0544e-02, -2.7283e-02,  2.0428e-03,
         4.1199e-02, -4.8790e-03, -1.8402e-02,  1.2558e-02, -8.2855e-03,
        -1.7700e-02,  8.1329e-03, -9.8801e-03, -3.0533e-02, -1.5701e-02,
        -1.2619e-02,  1.1435e-03,  9.7427e-03,  4.1168e-02,  1.2115e-02,
        -3.7994e-02,  2.1851e-02,  1.7303e-02, -2.2829e-05, -1.4351e-02,
        -2.4796e-02, -1.3657e-02,  1.1368e-03, -3.6133e-02, -1.6754e-02,
        -4.0161e-02, -1.4122e-02,  4.7241e-02,  2.8397e-02,  5.8441e-02,
        -2.7802e-02, -9.7656e-03, -5.0583e-03,  1.1459e-02,  6.5269e-03,
        -1.0071e-02,  5.2765e-02,  3.5675e-02, -1.3138e-02, -2.8534e-02,
        -1.6663e-02, -4.7485e-02, -6.6900e-04, -7.9956e-02, -4.1565e-02,
        -1.8661e-02, -3.3905e-02, -5.7487e-03,  2.6703e-02, -1.6327e-02,
        -2.5955e-02,  2.1423e-02, -3.0701e-02,  2.4185e-03,  3.3630e-02,
         2.1423e-02, -4.0833e-02, -2.9160e-02, -2.3529e-02,  3.1006e-02,
         3.3203e-02, -1.8784e-02,  3.0228e-02, -1.5671e-02,  6.2370e-03,
        -1.2001e-02, -1.3382e-02,  2.6047e-02, -2.0889e-02, -5.7159e-02,
         4.0222e-02,  2.2644e-02,  1.7868e-02, -1.8402e-02, -5.0354e-02,
        -2.3785e-03,  8.6823e-03,  3.0624e-02,  8.0490e-04,  1.9145e-04,
        -1.5640e-02,  3.2196e-02, -1.0406e-02, -1.3695e-02, -6.0303e-02,
         3.5370e-02, -1.2573e-02, -2.5665e-02, -3.7506e-02, -2.1706e-03,
        -4.3716e-03,  1.1406e-02,  4.0070e-02, -1.0109e-02,  2.3422e-02,
        -2.4857e-02,  9.0561e-03, -6.7444e-02, -3.5645e-02,  1.7853e-02,
         1.6876e-02, -7.0953e-03,  6.9733e-03, -6.5842e-03, -4.9927e-02,
         8.7509e-03, -4.1351e-02,  5.9891e-03, -5.1727e-03,  1.7303e-02,
         2.8275e-02,  3.8666e-02,  3.2196e-02,  1.9562e-02, -2.7420e-02,
         2.8717e-02,  1.0513e-02,  1.3222e-02,  2.6169e-02, -1.7517e-02,
        -8.4991e-03, -4.5807e-02,  2.3636e-02,  2.7206e-02, -1.2306e-02,
         2.7008e-02,  1.8799e-02,  1.4816e-02, -3.2288e-02, -2.8564e-02,
        -2.2182e-03, -1.2550e-02,  1.6327e-02,  4.6196e-03, -3.4393e-02,
         1.5125e-03, -2.2469e-03,  3.4973e-02,  1.6281e-02, -2.7908e-02,
         2.4582e-02, -1.3138e-02, -6.8130e-03, -9.9640e-03,  2.5070e-02,
         4.9347e-02, -1.0887e-02,  2.0569e-02,  2.0523e-02, -1.3145e-02,
         2.2659e-02, -5.1788e-02,  2.5284e-02,  6.5727e-03, -4.9774e-02,
        -5.4896e-05,  1.4381e-02,  6.3820e-03,  6.8207e-03, -2.7985e-02,
         3.3844e-02,  3.5839e-03, -1.3374e-02,  8.4839e-03,  1.6800e-02,
        -1.1391e-02, -1.7197e-02, -3.3203e-02, -3.2349e-02,  3.1311e-02,
        -2.6276e-02, -2.6718e-02, -6.5674e-02,  1.5144e-02, -7.9269e-03,
         1.9501e-02,  1.2383e-02,  2.0767e-02, -2.7573e-02, -5.4230e-02,
         2.1729e-02,  6.6299e-03, -2.7180e-03, -1.8127e-02,  5.2738e-04,
        -1.5747e-02,  5.6953e-03, -3.5114e-03, -4.0253e-02,  4.2297e-02,
        -4.3762e-02,  6.0797e-06, -1.5358e-02,  1.4206e-02,  1.0216e-02,
         1.4702e-02,  1.7166e-02, -2.5681e-02,  1.0347e-03,  2.4643e-02,
        -4.1656e-02,  1.5640e-02,  5.2338e-03, -5.4810e-02, -1.4801e-02,
        -2.3560e-02, -2.4902e-02, -5.6190e-03,  1.7227e-02,  3.6144e-03,
        -5.3525e-05,  5.2071e-03, -6.8787e-02, -1.9653e-02,  3.8330e-02,
         2.4681e-03,  4.7874e-03,  1.6098e-02,  1.8448e-02,  2.8473e-02,
         1.9491e-05,  2.6138e-02,  4.4799e-04, -1.0101e-02, -6.2866e-02,
         3.0823e-03,  5.7144e-03, -1.3588e-02, -1.9806e-02, -2.8229e-02,
         5.5267e-02, -2.9434e-02, -1.2894e-02, -6.4125e-03,  2.9465e-02,
         1.4084e-02,  9.6893e-03,  1.3283e-02,  2.6718e-02, -3.4668e-02,
        -9.5520e-03, -8.0490e-03,  2.8839e-02,  3.8574e-02, -8.2626e-03,
         9.8190e-03,  4.7874e-04, -3.4218e-03,  5.2429e-02,  1.6754e-02,
         1.7929e-02,  4.0558e-02,  3.3813e-02,  4.0665e-03, -2.8133e-03,
        -1.1169e-02, -3.6926e-02,  1.0948e-02, -2.1088e-02, -9.4604e-03,
        -3.4271e-02,  2.7466e-02, -4.5349e-02, -2.6836e-03, -3.8574e-02,
        -1.0735e-02,  2.5681e-02, -1.5556e-02,  1.2306e-02,  3.6983e-03,
         4.2725e-03,  2.8793e-02,  1.1620e-02,  1.6388e-02,  4.6997e-02,
        -4.7394e-02,  2.6611e-02, -7.3509e-03,  3.6407e-02,  2.2827e-02,
        -3.4546e-02,  1.2398e-02, -2.1957e-02,  5.2856e-02,  2.9831e-02,
        -1.3838e-03,  7.5817e-04,  3.9276e-02,  4.4136e-03,  1.9836e-02,
         5.5756e-02, -3.4882e-02, -1.0559e-02, -1.5251e-02, -1.3550e-02,
        -1.7334e-02, -4.1656e-02,  1.9547e-02,  2.5192e-02, -7.1859e-04,
         1.8112e-02,  4.5074e-02,  1.1009e-02, -4.6387e-02, -6.8741e-03,
        -4.0398e-03,  2.3499e-02, -2.5986e-02,  1.7075e-02,  7.3738e-03,
        -2.4662e-03,  9.4147e-03,  1.0675e-01,  4.4861e-02,  5.2567e-03,
        -1.0887e-02, -1.1396e-03, -1.8816e-03,  3.8391e-02,  4.9957e-02,
        -1.2047e-02, -1.5419e-02,  2.1408e-02,  5.1483e-02,  3.2749e-03,
        -1.2169e-02, -2.5225e-04, -2.1530e-02, -6.5880e-03,  4.6936e-02,
         5.8441e-03, -4.4250e-02, -3.2776e-02,  4.9286e-02,  1.8448e-02,
         3.7872e-02, -2.9510e-02,  9.2773e-03,  4.6005e-03,  1.6220e-02,
         3.5248e-02, -3.2406e-03, -3.8879e-02, -8.6975e-03, -5.8929e-02,
        -1.6251e-02,  2.0355e-02, -9.3918e-03, -4.4670e-03,  3.5645e-02,
        -2.5803e-02, -1.7776e-02, -4.0161e-02, -4.9629e-03,  2.3499e-02,
        -1.8829e-02, -3.1067e-02,  2.6855e-02, -1.3794e-02, -6.4087e-03,
         2.1057e-02, -2.8744e-03, -4.1885e-03, -2.6123e-02, -1.5438e-04,
        -7.4997e-03, -3.5324e-03,  2.6886e-02, -1.6907e-02, -2.0477e-02,
        -2.6642e-02, -2.0050e-02, -1.1116e-02,  2.5909e-02, -9.7504e-03,
        -1.0345e-02, -3.2135e-02,  5.1422e-02, -1.2207e-02,  1.5965e-03],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([0.7388, 0.8018, 0.8037, 0.7495, 0.7935, 0.6934, 0.7988, 0.7642, 0.7910,
        0.8516, 0.8877, 0.8076, 0.8774, 0.6880, 0.8628, 0.8193, 0.8403, 0.8164,
        0.8901, 0.8267, 0.8232, 0.8335, 0.8862, 0.8242, 0.8159, 0.8433, 0.8745,
        0.8252, 0.8369, 0.8901, 0.8892, 0.9219, 0.8574, 0.9028, 0.8652, 0.9019,
        0.9102, 0.8496, 0.8647, 0.8574, 0.8643, 0.7788, 0.8745, 0.9165, 0.8262,
        0.8960, 0.8750, 0.8521, 0.8579, 0.8433, 0.9038, 0.8521, 0.9194, 0.8174,
        0.9434, 0.8242, 0.9150, 0.8853, 0.7900, 0.8638, 0.9087, 0.8521, 0.8765,
        0.8506, 0.9370, 0.8862, 0.8574, 0.7607, 0.8418, 0.8418, 0.8188, 0.8579,
        0.7725, 0.8359, 0.9316, 0.7861, 0.9028, 0.8242, 0.8584, 0.8232, 0.8813,
        0.8970, 0.8403, 0.8975, 0.8955, 0.8574, 0.8794, 0.8579, 0.8843, 0.8042,
        0.9399, 0.9072, 0.9502, 0.8784, 0.8760, 0.8931, 0.7979, 0.8652, 0.9863,
        0.8779, 0.9414, 0.8638, 0.9492, 0.9004, 0.9844, 0.8286, 0.9404, 0.7729,
        0.8750, 0.8496, 0.9634, 0.9458, 0.9385, 0.9365, 0.8315, 0.9238, 0.9849,
        0.8740, 0.9849, 0.8320, 0.9746, 0.9600, 0.9907, 0.9331, 0.9927, 0.9204,
        0.9878, 0.9697, 0.9707, 0.8745, 0.7236, 0.9888, 0.9707, 0.9673, 0.9678,
        1.0527, 0.9648, 0.9546, 0.9678, 0.9688, 0.9976, 1.0645, 0.9741, 0.9854,
        1.0479, 0.9927, 0.9932, 0.9644, 0.9536, 0.9224, 0.9517, 1.0010, 0.9683,
        0.9624, 1.0654, 0.9517, 0.9917, 1.0605, 1.0342, 0.9570, 1.0215, 0.8643,
        0.9233, 0.9868, 0.9570, 1.0000, 0.9800, 0.6079, 1.0518, 1.0303, 1.0078,
        0.9492, 0.9858, 0.9878, 0.9814, 0.9707, 0.8037, 1.0381, 0.7871, 0.8735,
        0.9087, 0.8994, 0.9141, 0.9780, 0.9302, 0.9175, 0.7988, 0.9429, 1.0156,
        1.0195, 0.9600, 1.0107, 0.8965, 0.9277, 0.8721, 1.0166, 0.8716, 0.9644,
        0.9214, 1.0146, 0.9561, 0.9771, 1.0107, 0.9980, 0.9565, 0.9604, 0.9346,
        0.9839, 1.0674, 1.0303, 1.0039, 1.0010, 0.8901, 0.8838, 0.9565, 1.0273,
        0.9150, 0.8945, 0.9551, 0.9878, 0.9409, 0.9941, 0.9741, 0.9521, 0.9824,
        0.9668, 1.0176, 0.9600, 0.9395, 0.9966, 0.8315, 1.0059, 0.9854, 0.9277,
        0.9502, 0.9487, 0.9580, 1.0781, 0.9683, 1.0059, 0.8950, 0.9863, 0.9409,
        1.0283, 0.8916, 1.0029, 0.8984, 1.0000, 0.9224, 0.9351, 0.8931, 0.7334,
        0.9600, 0.9873, 0.9819, 0.9458, 0.6807, 0.9272, 0.9683, 0.9922, 0.8628,
        1.0557, 0.9790, 0.9883, 0.9883, 0.9966, 0.9004, 0.9932, 1.0303, 1.0020,
        0.8608, 1.0254, 0.9243, 1.0166, 0.8994, 0.9458, 0.8525, 0.9268, 0.9321,
        1.0205, 0.9326, 0.9941, 0.9502, 0.9565, 0.9702, 1.0020, 0.9424, 0.8291,
        0.9419, 1.0830, 0.9067, 1.0342, 0.9102, 0.9214, 0.8901, 1.0820, 0.8652,
        0.9219, 0.8560, 1.0537, 0.9238, 0.9678, 0.8691, 0.7817, 0.8584, 0.9849,
        0.9790, 1.0156, 0.9180, 1.0127, 0.9458, 0.9731, 0.9551, 0.9595, 0.8047,
        0.9238, 0.9312, 0.8403, 0.8560, 0.9800, 0.7715, 0.9785, 0.7241, 0.9844,
        0.9155, 1.0176, 0.9048, 0.9902, 0.9580, 1.0127, 0.8730, 1.0303, 0.9180,
        1.0068, 0.9570, 0.9204, 0.8779, 0.9966, 0.9668, 1.0273, 0.9185, 0.9902,
        0.9634, 0.9800, 0.9287, 0.9814, 0.9692, 1.0293, 0.9263, 1.0166, 0.8579,
        0.9600, 0.9199, 1.0127, 0.9370, 0.9775, 0.9131, 0.9863, 0.9365, 0.9492,
        0.9312, 0.9683, 0.8843, 1.0078, 0.9858, 1.0566, 0.8369, 1.0322, 0.8853,
        0.8726, 0.9409, 0.9512, 0.8877, 0.9795, 0.9365, 1.0137, 0.9175, 0.9819,
        0.9121, 0.9414, 0.9629, 0.9678, 0.9546, 1.0098, 0.9238, 0.9531, 0.8477,
        0.9790, 0.9160, 0.9443, 0.8096, 0.9082, 0.8794, 0.8315, 0.9248, 0.7817,
        0.8398, 1.0586, 0.8979, 0.9297, 0.9185, 0.9937, 0.8833, 1.0146, 0.9448,
        1.0283, 0.8779, 0.9624, 0.9648, 0.9854, 0.9399, 0.9614, 0.7930, 0.9775,
        0.9565, 0.9756, 0.7495, 0.9990, 0.9224, 0.9810, 0.8833, 0.9727, 0.8530,
        1.0127, 0.8975, 0.9175, 0.9146, 0.9766, 0.8975, 1.0137, 0.9209, 0.9380,
        0.8550, 0.9478, 0.9536, 0.9956, 0.8906, 1.0918, 0.9258, 0.9419, 0.9067,
        0.9829, 0.8921, 0.8843, 0.9229, 0.9971, 0.8691, 0.9844, 0.9521, 0.8799,
        0.9478, 1.0244, 0.8735, 0.9565, 0.9199, 0.9775, 0.8867, 0.9702, 0.9414,
        1.0098, 0.8926, 1.0166, 0.8623, 1.0840, 0.9092, 0.8945, 0.8286, 0.9790,
        0.8979, 1.0566, 0.9434, 0.9600, 0.9868, 0.9121, 0.9795, 0.9321, 0.9316,
        0.9463, 0.8530, 0.9795, 0.8950, 1.0225, 0.8770, 0.9658, 0.9023, 0.9473,
        0.8931, 1.0264, 0.9448, 0.9448, 0.8706, 0.9927, 0.8809, 0.8281, 0.8818,
        0.9951, 0.8418, 1.0391, 0.8320, 1.0098, 0.8579, 1.0137, 0.8735, 0.9526,
        0.8887, 0.9917, 0.9326, 0.9897, 0.6812, 0.9805, 0.8428, 0.9502, 0.8452,
        1.0176, 0.8887, 1.0186, 1.0098, 0.9561, 0.9077, 1.0430, 0.9385, 1.0107,
        0.9116, 0.9907, 0.9097, 0.9688, 0.8564, 0.9683, 0.9565, 1.0000, 0.8818,
        1.0352, 0.8154, 0.9800, 0.9243, 0.9688, 0.9810, 1.0020, 0.9214, 0.9829,
        0.8628, 0.9717, 0.9292, 1.0186, 0.8223, 0.9756, 0.9082, 1.0283, 0.9478,
        0.9136, 0.9023, 0.9951, 0.7988, 0.9092, 0.8774, 0.9731, 0.9175, 0.9653,
        0.8965, 0.9165, 0.8950, 0.9165, 0.9263, 0.9507, 0.9463, 1.0547, 0.8906,
        0.9116, 0.8486, 0.9893, 0.8867, 0.9351, 0.6577, 1.0498, 0.8862, 0.9951,
        0.9541, 1.0166, 0.8506, 0.9971, 0.8442, 0.9771, 0.8667, 1.0049, 0.8452,
        1.0342, 0.9355, 0.9795, 1.0010, 0.9443, 0.8662, 1.0479, 0.9932, 0.9810,
        0.8550, 1.0186, 0.8872, 0.9575, 0.8525, 0.9585, 0.8696, 0.9575, 0.8882,
        0.9878, 0.9038, 0.9570, 0.9370, 0.9229, 0.8984, 1.0215, 0.8892, 1.0371,
        0.9971, 0.9282, 0.8774, 1.0039, 0.9219, 0.6885, 0.8926, 0.7534, 0.8574,
        1.0234, 0.9316, 0.9790, 0.8306, 1.0000, 0.8921, 0.9512, 0.9482, 0.9868,
        0.9185, 0.9927, 0.8506, 0.9814, 0.8818, 1.0244, 0.8618, 0.9238, 0.8921,
        0.9780], device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([-0.0779, -0.0775, -0.0524, -0.1004, -0.0652, -0.0594, -0.0527, -0.0702,
        -0.0698, -0.0737, -0.0862, -0.0765, -0.0893, -0.0568, -0.0880, -0.0890,
        -0.0759, -0.0763, -0.0548, -0.0508, -0.1000, -0.0779, -0.0859, -0.0608,
        -0.1000, -0.0583, -0.0667, -0.0789, -0.0629, -0.0676, -0.0794, -0.0632,
        -0.0522, -0.0729, -0.0889, -0.0977, -0.0853, -0.0778, -0.0839, -0.1399,
        -0.0734, -0.1076, -0.0732, -0.1096, -0.0894, -0.0816, -0.0662, -0.0636,
        -0.1054, -0.0637, -0.0708, -0.0848, -0.0917, -0.0742, -0.0862, -0.0658,
        -0.1249, -0.0837, -0.0718, -0.0750, -0.0703, -0.0673, -0.0646, -0.0703,
        -0.1102, -0.0594, -0.0911, -0.0494, -0.0781, -0.0536, -0.0524, -0.0696,
        -0.0806, -0.0695, -0.0830, -0.0840, -0.0810, -0.0731, -0.0981, -0.0887,
        -0.0963, -0.0801, -0.1111, -0.0555, -0.1209, -0.0854, -0.0542, -0.0665,
        -0.0908, -0.0555, -0.1079, -0.0696, -0.0907, -0.0617, -0.0784, -0.0465,
        -0.0895, -0.0547, -0.0928, -0.0726, -0.1335, -0.0656, -0.1426, -0.0502,
        -0.1207, -0.1083, -0.1348, -0.0615, -0.0997, -0.0896, -0.1049, -0.0594,
        -0.1311, -0.0948, -0.0789, -0.0693, -0.1079, -0.0845, -0.1503, -0.0869,
        -0.0735, -0.0504, -0.0882, -0.0880, -0.1379, -0.1302, -0.0979, -0.0833,
        -0.1600, -0.1311, -0.1368, -0.0823, -0.0734, -0.1019, -0.1108, -0.1058,
        -0.1183, -0.1285, -0.1171, -0.1167, -0.1379, -0.1100, -0.1191, -0.1218,
        -0.1193, -0.1614, -0.1782, -0.1081, -0.1354, -0.0687, -0.1061, -0.0822,
        -0.1323, -0.1185, -0.1482, -0.1265, -0.0948, -0.0778, -0.1060, -0.0799,
        -0.1276, -0.0987, -0.0903, -0.0916, -0.1443, -0.1140, -0.0926, -0.2114,
        -0.1026, -0.1013, -0.0945, -0.0684, -0.1036, -0.1008, -0.1136, -0.0770,
        -0.1541, -0.1105, -0.2340, -0.1005, -0.1414, -0.0929, -0.1724, -0.1143,
        -0.0937, -0.1504, -0.0416, -0.0610, -0.1167, -0.1475, -0.1060, -0.1440,
        -0.1256, -0.0862, -0.1219, -0.1134, -0.1515, -0.1001, -0.0976, -0.1148,
        -0.0838, -0.0879, -0.0854, -0.1243, -0.0946, -0.1179, -0.0780, -0.1191,
        -0.0731, -0.1101, -0.0862, -0.0949, -0.1439, -0.1252, -0.0941, -0.1511,
        -0.1024, -0.1232, -0.1052, -0.1057, -0.1096, -0.1218, -0.0619, -0.1104,
        -0.0948, -0.1041, -0.0953, -0.1295, -0.1003, -0.1608, -0.1122, -0.1399,
        -0.0950, -0.1137, -0.0855, -0.1006, -0.1077, -0.1528, -0.0795, -0.1328,
        -0.0951, -0.1250, -0.0709, -0.0835, -0.0783, -0.0988, -0.0931, -0.1417,
        -0.0836, -0.0668, -0.0643, -0.0685, -0.0938, -0.1210, -0.0541, -0.0894,
        -0.1214, -0.0818, -0.0912, -0.1174, -0.0997, -0.1437, -0.0739, -0.1475,
        -0.0648, -0.1288, -0.0693, -0.1040, -0.0818, -0.0960, -0.1125, -0.0946,
        -0.0664, -0.1248, -0.0826, -0.1232, -0.0685, -0.1032, -0.0739, -0.1492,
        -0.0551, -0.1747, -0.0532, -0.1387, -0.0885, -0.1104, -0.0706, -0.1115,
        -0.0958, -0.1188, -0.0795, -0.1479, -0.0691, -0.1521, -0.0683, -0.1779,
        -0.0938, -0.2122, -0.0840, -0.1559, -0.0956, -0.1458, -0.0953,  0.0343,
        -0.0922, -0.1317, -0.0576, -0.1074, -0.0723, -0.1460, -0.0836, -0.1017,
        -0.0704, -0.1345, -0.0866, -0.0892, -0.0617, -0.0596, -0.0996, -0.1153,
        -0.0929, -0.1245, -0.1050, -0.0694, -0.1069, -0.1593, -0.0988, -0.0912,
        -0.0432, -0.1475, -0.1080, -0.1345, -0.0628, -0.1482, -0.0757, -0.1497,
        -0.1183, -0.1218, -0.0715, -0.1481, -0.0615, -0.1490, -0.0766, -0.1284,
        -0.0956, -0.1375, -0.0698, -0.1425, -0.0635, -0.1382, -0.1045, -0.0792,
        -0.0973, -0.1840, -0.0919, -0.0787, -0.1049, -0.1331, -0.0875, -0.1035,
        -0.0605, -0.0964, -0.0644, -0.1492, -0.0766, -0.1252, -0.0909, -0.1318,
        -0.1200, -0.1207, -0.0795, -0.1152, -0.0819, -0.0978, -0.0776, -0.1348,
        -0.0690, -0.0883, -0.1014, -0.0849, -0.0889, -0.0961, -0.0770, -0.1170,
        -0.0843, -0.1044, -0.0823, -0.0823, -0.0764, -0.0935, -0.1125, -0.1057,
        -0.0870, -0.1078, -0.0762, -0.1205, -0.1029, -0.1375, -0.0872, -0.1061,
        -0.0760, -0.1072, -0.0645, -0.1220, -0.0437, -0.1260, -0.0738, -0.1188,
        -0.0610, -0.1066, -0.0899, -0.1179, -0.1000, -0.1331, -0.0851, -0.1313,
        -0.0717, -0.1246, -0.0980, -0.1083, -0.1364, -0.0887, -0.1041, -0.0912,
        -0.0800, -0.0897, -0.0656, -0.1151, -0.1125, -0.1160, -0.0757, -0.1060,
        -0.1166, -0.1067, -0.0673, -0.0918, -0.1096, -0.1499, -0.0884, -0.1323,
        -0.0858, -0.0875, -0.0739, -0.0764, -0.0886, -0.0905, -0.1064, -0.0877,
        -0.0815, -0.0909, -0.0759, -0.1226, -0.0731, -0.1404, -0.1133, -0.1141,
        -0.1080, -0.1210, -0.0778, -0.0954, -0.1111, -0.1353, -0.0684, -0.1420,
        -0.0677, -0.0748, -0.1021, -0.1080, -0.1309, -0.0897, -0.0888, -0.1395,
        -0.0490, -0.0634, -0.0634, -0.0848, -0.0960, -0.0963, -0.0953, -0.1755,
        -0.0847, -0.1504, -0.1018, -0.1348, -0.0692, -0.1277, -0.0820, -0.1499,
        -0.0771, -0.1013, -0.1333, -0.1832, -0.0936, -0.1431, -0.1124, -0.1442,
        -0.1024, -0.1023, -0.0903, -0.0812, -0.0867, -0.1538, -0.0740, -0.1252,
        -0.0954, -0.1586, -0.0847, -0.1470, -0.1854, -0.0997, -0.1429, -0.0898,
        -0.0685, -0.1243, -0.1076, -0.1311, -0.0536, -0.1230, -0.0713, -0.1436,
        -0.0649, -0.1444, -0.1036, -0.0931, -0.0468, -0.1206, -0.0995, -0.1102,
        -0.0860, -0.1429, -0.0662, -0.1174, -0.0646, -0.1317, -0.0695, -0.1335,
        -0.0994, -0.1069, -0.0740, -0.1254, -0.0723, -0.1146, -0.0589, -0.1432,
        -0.0931, -0.1014, -0.1107, -0.1698, -0.0842, -0.1510, -0.0872, -0.1038,
        -0.0246, -0.1472, -0.0649, -0.0735, -0.0720, -0.1285, -0.0494, -0.0944,
        -0.0869, -0.2384, -0.0704, -0.0825, -0.0837, -0.1367, -0.0870, -0.0759,
        -0.0806, -0.1455, -0.0956, -0.1022, -0.2064, -0.1465, -0.0599, -0.1012,
        -0.0934, -0.0996, -0.0909, -0.1317, -0.0345, -0.1039, -0.0829, -0.1135,
        -0.0885, -0.1090, -0.0848, -0.1109, -0.0459, -0.1328, -0.1182, -0.1443,
        -0.0544, -0.1597, -0.0960, -0.1631, -0.0855, -0.0870, -0.0978, -0.0963,
        -0.1030, -0.0942, -0.0825, -0.1312, -0.0729, -0.0922, -0.1130, -0.0845,
        -0.0841, -0.1486, -0.0616, -0.1383, -0.0654, -0.1198, -0.0825, -0.1456,
        -0.0803, -0.1296, -0.0687, -0.0704, -0.1637, -0.1157, -0.0730, -0.1155,
        -0.0558, -0.1708, -0.0967, -0.1017, -0.0682, -0.1238, -0.0602, -0.1460,
        -0.1102, -0.0980, -0.0533, -0.1069, -0.0579, -0.1072, -0.0677, -0.1043],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[-0.0579, -0.0047, -0.0343,  ..., -0.0021, -0.0044,  0.0330],
        [-0.0187, -0.0102, -0.0026,  ...,  0.0353,  0.0214, -0.0169],
        [ 0.0059, -0.0330,  0.0067,  ..., -0.0013, -0.0448,  0.0233],
        ...,
        [-0.0034, -0.0271,  0.0126,  ..., -0.0327,  0.0334, -0.0079],
        [-0.0559,  0.0793, -0.0703,  ...,  0.0284, -0.0007,  0.0321],
        [-0.0507, -0.0848, -0.0384,  ...,  0.0196, -0.0109,  0.0074]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[ 0.0297, -0.0796, -0.0130,  ..., -0.0214, -0.0090,  0.0346],
        [ 0.0072, -0.0208,  0.0100,  ...,  0.0115, -0.0356,  0.0483],
        [ 0.0068,  0.0172,  0.0004,  ..., -0.0470, -0.0047,  0.0269],
        ...,
        [-0.0208, -0.0229, -0.0636,  ..., -0.0140, -0.0374, -0.1293],
        [-0.0290,  0.0428, -0.0394,  ...,  0.0086, -0.0513,  0.0525],
        [-0.1542, -0.0242, -0.0294,  ..., -0.0253, -0.0142, -0.0046]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[ 1.9485e-02,  3.8544e-02,  5.4535e-02,  ..., -2.5997e-03,
         -4.0527e-02, -9.7046e-03],
        [-3.2135e-02, -8.6670e-03,  6.2256e-02,  ..., -3.2806e-02,
          3.1921e-02, -1.8692e-02],
        [ 1.2436e-02, -3.3722e-02, -5.3864e-03,  ..., -2.8976e-02,
         -7.9712e-02,  3.8586e-03],
        ...,
        [ 4.7607e-02, -2.3621e-02,  1.9440e-02,  ..., -1.4816e-02,
          2.1393e-02,  5.8929e-02],
        [-3.0533e-02,  3.7628e-02,  2.4643e-02,  ..., -4.8697e-05,
          1.8097e-02,  2.3453e-02],
        [ 2.8000e-02,  8.0933e-02,  6.4926e-03,  ...,  6.4697e-03,
          8.1558e-03, -1.8539e-02]], device='cuda:0', dtype=torch.float16,
       requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[-0.0093,  0.0365, -0.0149,  ..., -0.0324, -0.0903, -0.0147],
        [ 0.0012, -0.0376,  0.0178,  ...,  0.0076, -0.0079, -0.0316],
        [ 0.0468, -0.0728, -0.0620,  ...,  0.0431, -0.0589,  0.0461],
        ...,
        [ 0.0398, -0.0530,  0.0204,  ..., -0.0027, -0.0451,  0.0798],
        [-0.0435, -0.0311,  0.0399,  ...,  0.0457,  0.0236, -0.0059],
        [ 0.0259,  0.0023,  0.0028,  ..., -0.0654,  0.0301,  0.0094]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([ 2.6459e-02, -3.1204e-02, -1.6356e-03, -1.2367e-02,  3.9459e-02,
         8.4305e-03,  2.2186e-02, -2.1713e-02,  1.0857e-02,  3.3630e-02,
        -5.2376e-03, -2.9419e-02, -2.1957e-02, -3.5278e-02,  6.9771e-03,
         7.0839e-03, -2.8214e-02, -4.0131e-02, -2.9190e-02,  4.9934e-03,
         1.3542e-03, -3.2196e-02, -3.0273e-02, -1.8219e-02, -5.0430e-03,
         1.2848e-02,  3.0411e-02, -4.8706e-02,  3.5675e-02,  2.5845e-03,
        -8.7738e-03, -3.5973e-03, -5.2986e-03,  2.9392e-03, -1.7107e-05,
        -8.7967e-03,  2.7527e-02, -3.5278e-02, -3.4790e-02, -9.1019e-03,
         2.4429e-02,  2.8015e-02,  1.4473e-02,  9.6588e-03, -1.0328e-03,
        -9.4833e-03,  2.5034e-04,  2.3224e-02, -3.2291e-03,  9.2936e-04,
         1.3214e-02,  2.2461e-02, -5.0659e-03, -1.2573e-02, -6.1188e-03,
        -1.1360e-02, -2.8046e-02, -2.0584e-02,  3.0327e-03, -7.3357e-03,
        -4.1389e-03, -1.8982e-02, -4.7112e-03,  2.4338e-02, -1.0323e-02,
         7.2556e-03, -1.8250e-02, -4.6967e-02,  3.6072e-02, -3.2158e-03,
        -1.1368e-02, -3.2379e-02,  2.3422e-02, -3.1929e-03, -4.0779e-03,
         3.8361e-02, -2.8946e-02, -3.6285e-02, -2.4628e-02,  1.4671e-02,
         6.3858e-03,  1.6270e-03,  1.7672e-03, -1.6449e-02, -7.9060e-04,
        -1.3229e-02, -2.0428e-03, -4.3091e-02, -3.4666e-04, -2.5085e-02,
        -1.6022e-02,  4.7493e-03, -1.6693e-02,  2.1561e-02,  3.8872e-03,
        -2.4094e-02, -2.6306e-02, -1.6556e-02, -5.3253e-03,  1.8570e-02,
        -6.5575e-03, -2.5463e-03,  7.0229e-03,  1.6708e-02, -7.6866e-03,
        -1.4198e-02,  3.1647e-02,  2.6367e-02, -1.1459e-02,  1.0628e-02,
         4.2267e-03, -3.1052e-02,  2.4200e-02, -3.1174e-02,  3.9864e-03,
        -5.6305e-03, -1.6647e-02, -4.1962e-02, -4.7379e-03,  4.6120e-03,
         3.6469e-03,  8.3923e-03, -2.7065e-03, -1.7242e-03, -2.3331e-02,
         2.3651e-02, -2.0172e-02,  1.4130e-02,  6.7520e-03,  1.9165e-02,
         3.6346e-02,  1.9241e-02,  1.2070e-02,  2.7866e-03,  1.6785e-02,
         1.6815e-02, -8.4457e-03,  2.5436e-02,  1.1093e-02, -6.5918e-03,
         1.3306e-02, -5.4979e-04, -8.2932e-03, -3.7598e-02,  2.4445e-02,
         2.1393e-02,  3.2379e-02,  2.0096e-02, -7.3204e-03,  7.3929e-03,
        -3.1967e-03,  4.0283e-03, -1.2794e-02,  2.3499e-02,  7.5817e-04,
         8.8577e-03,  1.0824e-03, -2.4399e-02,  2.7878e-02,  2.8839e-02,
         2.2736e-02,  2.2263e-02, -3.2013e-02, -1.6251e-02, -1.9196e-02,
         4.1504e-02,  1.2993e-02,  1.7227e-02,  2.9694e-02,  4.8523e-02,
         3.2196e-02,  9.0714e-03,  2.2934e-02, -1.8677e-02, -2.5959e-03,
        -1.1292e-02, -1.2253e-02, -2.2720e-02, -9.1705e-03, -2.3956e-02,
        -7.3166e-03,  1.1589e-02, -6.6795e-03,  2.9869e-03, -2.8473e-02,
         1.5129e-02, -3.2837e-02, -7.5531e-04,  1.7517e-02,  3.8452e-03,
         1.8158e-03, -8.6060e-03, -2.6108e-02,  8.2855e-03, -3.2043e-02,
         2.4414e-02,  1.0406e-02, -2.0187e-02,  7.1144e-03,  6.0539e-03,
         1.1002e-02,  3.1982e-02,  7.2517e-03,  2.2018e-02, -1.2138e-02,
        -1.2306e-02,  6.0844e-03,  2.3834e-02,  2.1301e-02,  5.6534e-03,
         1.0468e-02, -1.8219e-02, -3.5522e-02, -2.5345e-02,  8.4076e-03,
         4.4983e-02,  3.0701e-02,  2.0172e-02, -3.3112e-02,  2.9480e-02,
        -6.4392e-03,  2.8381e-02,  1.8082e-02, -8.1253e-03,  1.4963e-03,
         3.3630e-02,  9.6588e-03, -3.1952e-02, -2.8503e-02, -1.9288e-04,
        -2.7756e-02,  4.3976e-02,  1.2695e-02,  3.8357e-03, -1.6251e-02,
        -1.8188e-02,  2.3468e-02,  1.4982e-03,  5.7487e-03,  4.7668e-02,
        -2.1317e-02, -2.6733e-02,  3.3173e-02,  2.5040e-02, -6.7711e-03,
         3.1433e-02,  3.4389e-03,  2.8259e-02, -2.6428e-02,  1.3840e-02,
         2.6031e-02,  3.7026e-04, -1.0700e-03, -4.9782e-03, -3.0384e-03,
         1.8631e-02,  2.2925e-01, -2.3866e-04,  2.9545e-03,  1.5793e-02,
         3.8605e-02,  7.3051e-03,  2.1408e-02,  9.1705e-03, -2.7740e-02,
        -1.3809e-02,  3.2806e-03, -1.1497e-02, -4.0192e-02,  2.5330e-02,
         6.3438e-03,  1.7334e-02,  1.0727e-02,  9.6436e-03, -1.5717e-02,
        -3.2166e-02, -1.4809e-02, -9.9716e-03, -4.5967e-03, -5.0888e-03,
         1.6251e-02, -1.1719e-02,  2.5883e-03, -1.5373e-02, -2.6596e-02,
        -1.2016e-02, -3.6438e-02,  3.3386e-02, -2.3605e-02,  5.5618e-03,
         1.0849e-02,  1.9226e-02, -4.5227e-02, -3.0079e-03,  1.4114e-02,
         1.7258e-02, -3.5706e-02, -1.5419e-02, -4.3121e-02,  1.7958e-03,
        -5.8060e-03,  1.3763e-02, -2.2217e-02, -1.5918e-01,  7.1259e-03,
        -1.8890e-02,  6.7940e-03,  2.6505e-02, -2.6535e-02, -2.4170e-02,
         2.0752e-02,  1.5326e-03,  1.5701e-02, -1.4870e-02,  2.3529e-02,
         3.5522e-02, -5.9433e-03,  2.1057e-02,  3.2005e-03, -2.5986e-02,
         1.7075e-02,  3.0670e-02,  1.3931e-02, -2.0279e-02, -1.7715e-02,
         3.4546e-02, -3.2990e-02,  1.7147e-03,  2.4094e-02,  2.6413e-02,
        -3.8055e-02,  7.1487e-03,  1.4244e-02,  2.4933e-02, -1.3817e-02,
        -1.4046e-02,  9.2545e-03,  5.7068e-03,  1.0399e-02,  3.5461e-02,
        -2.1301e-02,  2.7115e-02, -5.5962e-03, -2.8954e-03, -4.9072e-02,
         1.1742e-02,  2.1118e-02, -5.7030e-03, -2.7603e-02,  4.9774e-02,
        -3.1769e-02,  8.6670e-03,  1.7334e-02, -1.4984e-02,  2.6993e-02,
         2.2552e-02, -7.9117e-03,  3.5706e-02, -4.2236e-02, -9.4833e-03,
         1.8326e-02,  5.8174e-03, -3.5400e-03,  2.7637e-03, -1.4168e-02,
        -1.0239e-02, -2.1835e-02,  3.3722e-02, -2.0065e-02,  2.0401e-02,
        -3.8013e-03,  1.2436e-02, -1.8829e-02, -6.4735e-03, -1.1429e-02,
         1.2741e-02, -1.3611e-02,  3.4271e-02,  2.5406e-02, -8.4457e-03,
        -3.1891e-02,  2.1729e-02, -2.7420e-02,  3.6469e-02,  1.1566e-02,
         1.8646e-02, -3.7651e-03,  3.3783e-02, -2.2186e-02,  3.7079e-02,
         1.9547e-02, -2.1988e-02,  3.0991e-02, -3.6804e-02, -1.2283e-02,
        -1.7746e-02,  2.6947e-02,  4.3579e-02,  2.3499e-03,  2.6215e-02,
         4.9210e-03,  3.9825e-02, -1.2192e-02,  2.3193e-02,  3.1113e-02,
         1.4248e-03, -4.3335e-02,  4.2633e-02,  1.9165e-02, -4.0321e-03,
        -1.8875e-02,  1.2840e-02,  3.6926e-02,  2.2721e-04, -4.1504e-02,
        -3.9482e-03, -6.2103e-03,  1.6830e-02, -1.3535e-02, -1.3458e-02,
        -2.6855e-02,  1.0239e-02, -2.1877e-03, -1.6342e-02,  4.8676e-03,
         1.1696e-02, -6.0272e-03, -2.7893e-02, -1.2840e-02,  1.8661e-02,
         1.3779e-02,  1.7441e-02, -6.7993e-02,  2.3163e-02, -1.8433e-02,
         2.5452e-02, -7.2060e-03,  4.2572e-02, -3.9459e-02,  6.8760e-04,
        -1.0895e-02, -1.7838e-02,  1.0490e-03,  1.9012e-02, -2.5238e-02,
         2.7451e-02,  7.3767e-04,  5.6648e-03, -2.6917e-02,  4.0283e-03,
        -4.9934e-03,  2.3666e-02, -9.0027e-03,  2.6642e-02,  1.5701e-02,
         3.0685e-02,  2.0477e-02,  1.6663e-02,  8.8654e-03,  8.9340e-03,
         2.4853e-03,  2.1683e-02, -5.3955e-02,  6.4278e-03, -3.6499e-02,
        -2.2781e-02, -1.3054e-02,  3.9825e-02,  1.3802e-02, -3.5583e-02,
         1.7654e-02,  2.8564e-02,  1.7807e-02, -4.0100e-02,  1.7792e-02,
        -2.0676e-02, -5.4474e-03,  3.0869e-02,  1.9714e-02,  3.0174e-03,
        -3.7018e-02,  2.1469e-02, -2.1992e-03,  4.7943e-02, -2.5146e-02,
        -2.1286e-02, -1.3885e-02, -2.9240e-03, -1.7166e-02,  1.7197e-02,
         2.4857e-02,  1.6205e-02, -1.8036e-02,  2.8397e-02, -2.3834e-02,
        -1.2497e-02,  4.9515e-03, -2.6123e-02, -2.1790e-02,  3.7811e-02,
        -2.2781e-02,  2.4368e-02,  1.4458e-02,  2.6047e-02, -2.7649e-02,
         3.1250e-02, -2.5742e-02, -5.9700e-03,  1.3367e-02, -9.9869e-03,
         6.9656e-03,  2.2278e-02, -2.7649e-02, -9.3918e-03, -3.8788e-02,
         1.6663e-02, -2.2755e-03,  1.4656e-02, -9.8572e-03,  1.8433e-02,
        -2.4811e-02,  6.9656e-03, -4.3243e-02,  3.0975e-02, -2.8503e-02,
         2.6077e-02,  2.1267e-03, -6.6795e-03, -2.3300e-02,  5.1697e-02,
        -2.4155e-02, -1.3062e-02,  1.2764e-02,  1.5762e-02, -2.6321e-02,
         1.6998e-02, -3.5034e-02,  4.9133e-03,  1.6159e-02, -2.2995e-02,
         1.7426e-02,  3.7842e-02, -2.4597e-02,  3.5400e-02, -4.7150e-02,
         1.6495e-02,  4.9770e-05,  4.5410e-02, -1.8539e-02, -1.5007e-02,
         2.1805e-02, -8.9035e-03, -3.0579e-02,  6.5269e-03, -1.5930e-02,
        -4.4403e-03, -5.9319e-03, -9.0408e-03,  4.6921e-03,  4.3945e-02,
        -8.8806e-03, -3.0918e-03, -2.3453e-02,  2.6611e-02, -3.9734e-02,
         1.2482e-02, -2.9869e-03, -1.7700e-03, -1.5762e-02, -1.6212e-03,
        -1.5518e-02,  3.7498e-03,  7.4707e-02,  4.6814e-02, -2.8580e-02,
         2.7527e-02, -8.1177e-03, -8.3466e-03,  2.3819e-02,  3.5278e-02,
         2.3544e-02,  1.9958e-02, -2.2995e-02,  2.2995e-02, -8.3542e-03,
         3.0319e-02, -2.6749e-02,  1.1551e-02, -1.9197e-03,  3.2013e-02,
        -3.4851e-02,  1.4442e-02,  9.8343e-03, -2.1484e-02, -2.0561e-03,
         1.5305e-02,  1.0643e-03, -2.9312e-02, -1.6144e-02,  1.3947e-02,
         2.2842e-02,  1.2848e-02,  2.3071e-02, -7.3586e-03, -4.1260e-02,
        -7.1144e-04, -2.5848e-02,  2.5146e-02,  1.6159e-02,  4.0588e-02,
        -1.9531e-02, -4.9400e-03,  2.3098e-03,  3.0838e-02,  1.2825e-02,
         1.2512e-02,  2.0618e-03, -4.7455e-03, -2.3392e-02, -9.6283e-03,
         1.8448e-02,  3.8544e-02, -1.9821e-02,  3.9612e-02,  1.1612e-02,
         1.8829e-02, -3.2227e-02, -1.7166e-02, -3.3264e-02,  1.4557e-02,
        -1.1436e-02, -1.1627e-02,  2.1194e-02,  2.3163e-02, -2.8656e-02,
         3.8376e-03,  9.1705e-03, -1.9638e-02, -1.5945e-02,  6.1569e-03],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([0.9551, 0.9512, 0.9556, 0.9404, 0.9268, 0.8496, 0.8833, 0.8916, 0.8647,
        0.9302, 0.8931, 0.9639, 0.9111, 0.7852, 0.9385, 0.9023, 0.9385, 0.9014,
        0.9214, 0.8867, 0.8633, 0.8594, 0.9199, 0.9048, 0.9565, 0.8975, 0.9224,
        0.9287, 0.8955, 0.9038, 0.8921, 0.8730, 0.9351, 0.8916, 0.9233, 0.9189,
        0.9390, 0.9199, 0.9062, 0.9375, 0.8965, 0.9126, 0.9238, 0.9253, 0.9312,
        0.8955, 0.9351, 0.9365, 0.8545, 0.8838, 0.9370, 0.9463, 0.9326, 0.8882,
        0.9204, 0.8374, 0.9185, 0.9424, 0.9248, 0.9204, 0.9585, 0.9033, 0.9058,
        0.9575, 0.9082, 0.8931, 0.8159, 0.9512, 0.8926, 0.9170, 0.8931, 0.8755,
        0.8794, 0.9185, 0.9272, 0.8584, 0.8799, 0.9375, 0.9189, 0.9058, 0.9316,
        0.8862, 0.9067, 0.9492, 0.8872, 0.8530, 0.9033, 0.9238, 0.9780, 0.8687,
        0.8774, 0.9038, 0.9209, 0.8955, 0.9219, 0.9604, 0.8589, 0.9316, 0.9727,
        0.9028, 0.9492, 0.9326, 0.8931, 0.9277, 0.9390, 0.8921, 0.8569, 0.8550,
        0.8882, 0.8730, 0.9399, 0.9297, 0.9341, 0.9380, 0.8838, 0.9248, 0.8711,
        0.9302, 0.8604, 0.9033, 0.9033, 0.9336, 0.9688, 0.9521, 0.8901, 0.8921,
        0.8960, 0.9106, 0.8955, 0.9146, 0.7788, 0.9497, 0.9434, 0.9854, 0.9819,
        0.9185, 0.9585, 0.8950, 0.8711, 0.9189, 0.8403, 0.9727, 0.8921, 0.9570,
        0.8833, 0.8999, 0.9185, 0.9053, 0.8921, 0.9209, 0.9150, 0.9414, 0.9019,
        0.9971, 0.9243, 0.8799, 0.9092, 0.9985, 0.9097, 0.9692, 0.9458, 0.8535,
        0.9741, 0.8984, 0.9082, 0.9414, 0.9214, 0.7905, 0.9731, 0.9165, 0.9360,
        0.9341, 0.8950, 0.9053, 0.9590, 0.9624, 0.9077, 0.9717, 0.8721, 0.9619,
        0.8779, 0.8706, 0.8643, 0.9453, 0.9458, 0.8774, 0.8887, 0.9658, 0.9390,
        0.9341, 0.9595, 0.9072, 0.9463, 0.8794, 0.8706, 0.9038, 0.9258, 0.9746,
        0.9336, 0.9590, 0.9253, 0.9478, 0.9614, 0.9019, 0.9014, 0.9229, 0.9707,
        0.9111, 0.9551, 0.9341, 0.9355, 0.9346, 0.9116, 0.9004, 0.8804, 0.8892,
        0.9385, 0.9102, 0.8950, 0.9023, 0.9199, 0.8926, 0.9082, 0.9146, 0.9038,
        0.9395, 0.9688, 0.8789, 0.8853, 0.9248, 0.8857, 0.9263, 0.9424, 0.9624,
        0.9941, 0.9199, 0.9463, 0.9102, 0.9438, 0.9434, 0.9263, 0.8999, 0.8999,
        0.9639, 0.8994, 0.9209, 0.9551, 0.9556, 0.9307, 0.8291, 0.8926, 0.7661,
        0.8979, 0.9492, 0.9810, 0.9595, 0.5811, 0.9038, 0.8838, 0.8774, 0.8794,
        0.9316, 0.9385, 0.9414, 0.9053, 0.9380, 0.9531, 0.9238, 0.9600, 0.9121,
        0.9160, 0.9424, 0.8989, 0.9194, 0.8672, 0.8950, 0.8862, 0.8325, 0.9131,
        0.9053, 0.9375, 0.8936, 0.9775, 0.9556, 0.9609, 0.9922, 0.9038, 0.7759,
        0.8999, 0.9131, 0.9019, 0.9585, 0.9346, 0.8892, 0.9204, 0.9473, 0.9229,
        0.9185, 0.9395, 0.8970, 0.8926, 0.8848, 0.9160, 0.6182, 0.8950, 0.9453,
        0.9609, 0.9287, 0.9121, 0.9204, 0.9033, 0.9131, 0.9194, 0.8965, 0.8550,
        0.8701, 0.9097, 0.7915, 0.9409, 0.8643, 0.8340, 0.9697, 0.8447, 0.9351,
        0.9331, 0.8901, 0.8687, 0.9326, 0.9541, 0.9580, 0.9180, 0.9580, 0.9893,
        0.9507, 0.9165, 0.8994, 0.9009, 0.9087, 0.9683, 0.9004, 0.9507, 0.9697,
        0.9355, 0.8965, 0.9443, 0.9194, 0.9351, 1.0420, 0.9336, 0.9150, 0.8755,
        0.9272, 0.9155, 0.8911, 0.9331, 0.9326, 0.8936, 0.9468, 0.9404, 0.9434,
        0.9468, 0.9614, 0.9019, 0.8555, 0.9819, 0.8843, 0.9023, 0.9424, 0.9424,
        0.8491, 0.9365, 0.9014, 0.8989, 0.9185, 0.9219, 0.9575, 0.9126, 0.8936,
        0.8970, 0.8276, 0.9194, 0.8921, 0.9375, 0.9189, 0.9438, 0.9429, 0.8550,
        0.9019, 0.9727, 0.9253, 0.8882, 0.8408, 0.8745, 0.8711, 0.9219, 0.8789,
        0.8188, 0.9150, 0.9019, 0.8818, 0.9116, 0.9209, 0.8848, 0.9009, 0.9214,
        0.9155, 0.9023, 0.9175, 0.9585, 0.8716, 0.9336, 0.8379, 0.8491, 0.9160,
        0.8823, 0.8726, 0.8535, 0.9258, 0.9292, 0.9487, 0.9033, 0.9473, 0.8828,
        0.9556, 0.8262, 0.7983, 0.9316, 0.9316, 0.9131, 0.9209, 0.9126, 0.8960,
        0.9077, 0.8970, 0.9102, 0.9502, 0.8984, 0.9478, 0.8975, 0.9087, 0.8647,
        0.9146, 0.8716, 0.8887, 0.9116, 0.9209, 0.9150, 0.9385, 0.9116, 0.8887,
        0.9150, 0.9443, 0.8584, 0.8945, 0.8760, 0.9585, 0.8877, 0.8877, 0.8633,
        0.9639, 0.9131, 0.9282, 0.9346, 0.9570, 0.9287, 0.8892, 0.9282, 0.9331,
        0.8945, 0.9351, 0.9473, 0.9253, 0.9653, 0.7085, 0.9751, 0.7773, 0.9102,
        0.9497, 0.8911, 0.8872, 0.8760, 0.9404, 0.8672, 0.9712, 0.8945, 0.9268,
        0.8872, 0.9536, 0.9180, 0.8936, 0.8320, 0.9556, 0.8975, 0.8447, 0.9170,
        0.8438, 0.9189, 0.9453, 0.8721, 0.9243, 0.8931, 0.9424, 0.9160, 0.8662,
        0.9189, 0.9175, 0.9028, 0.8638, 0.7954, 0.9321, 0.8428, 0.8589, 0.8682,
        0.9038, 0.8730, 0.8921, 0.9189, 0.9160, 0.9175, 0.9160, 0.9238, 0.9233,
        0.9126, 0.8828, 0.9307, 0.8853, 0.8760, 0.8979, 0.9224, 0.9067, 0.9292,
        0.9673, 0.9136, 0.8696, 0.9033, 0.8799, 0.9268, 0.9092, 0.9355, 0.8901,
        0.8828, 0.9126, 0.9072, 0.9116, 0.9419, 0.9604, 0.9067, 0.9204, 0.9282,
        0.9419, 0.9155, 0.8955, 0.8599, 0.9458, 0.9180, 0.9194, 0.9014, 0.9961,
        0.8955, 0.8979, 0.8901, 0.8608, 0.9102, 0.9248, 0.8784, 0.9507, 0.9326,
        0.8008, 0.8716, 0.8994, 0.9297, 0.9038, 0.6294, 0.9507, 0.9209, 0.9204,
        0.9116, 0.9092, 0.9111, 0.8813, 0.9556, 0.8701, 0.8994, 0.8735, 0.8984,
        0.9473, 0.9097, 0.9409, 0.9478, 0.9136, 0.9570, 0.9248, 0.9165, 0.9575,
        0.9307, 0.9048, 0.8828, 0.8374, 0.8340, 0.8975, 0.9429, 0.8921, 0.9282,
        0.9175, 0.9395, 0.9453, 0.9268, 0.9048, 0.9224, 0.9185, 0.9126, 0.9048,
        0.9087, 0.8560, 0.9082, 0.9419, 0.8916, 0.7598, 0.9316, 0.8379, 0.8999,
        0.9302, 0.9155, 0.8950, 0.9302, 0.9146, 0.9180, 0.9502, 0.9824, 0.9653,
        0.9219, 0.9048, 0.8701, 0.8984, 0.9785, 0.9443, 0.9023, 0.8779, 0.8940,
        0.8989], device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([ 5.9326e-02,  5.6000e-02, -3.7079e-03, -5.7922e-02,  6.3171e-02,
        -2.4490e-02, -1.8280e-02,  2.2392e-03,  9.6970e-03,  3.2501e-02,
        -1.0818e-02, -4.8950e-02, -3.9673e-03, -2.5803e-02,  1.6113e-02,
         3.4241e-02, -2.3834e-02,  5.0781e-02, -1.4320e-02, -1.4160e-02,
         6.9809e-03,  2.5196e-03,  8.9798e-03, -3.5553e-02,  3.2501e-02,
        -2.7313e-02, -1.1047e-02,  6.6223e-03,  2.4719e-02, -5.6229e-03,
         2.6199e-02,  6.8817e-03,  1.2672e-02, -7.4081e-03, -3.4576e-02,
         3.2104e-02, -4.7485e-02, -4.8920e-02, -5.6213e-02,  2.5681e-02,
        -3.1616e-02, -5.0018e-02, -3.3203e-02,  5.9265e-02, -1.0260e-01,
        -1.0010e-02, -1.1810e-01,  3.6133e-02,  4.2664e-02, -3.2425e-03,
        -5.7312e-02, -5.6793e-02,  5.5573e-02,  2.7657e-03, -3.1555e-02,
        -2.4166e-03,  7.5317e-02,  2.3956e-02, -1.7227e-02,  2.6855e-02,
        -4.5135e-02, -3.5210e-03, -3.2654e-02,  3.6621e-02,  5.2856e-02,
        -5.5725e-02, -2.3529e-02,  1.7868e-02,  1.2693e-03, -3.1036e-02,
         2.5375e-02,  2.1347e-02, -2.8961e-02,  3.9795e-02,  1.2886e-02,
        -4.0314e-02,  3.6285e-02, -1.5717e-02,  1.4473e-02,  1.9264e-03,
        -2.4277e-02,  7.6523e-03, -9.4376e-03, -7.4097e-02,  8.1055e-02,
        -1.4809e-02,  1.2291e-02,  1.1383e-01, -4.3701e-02,  2.4033e-02,
         2.3560e-02, -4.5738e-03,  9.7046e-02,  2.2217e-02, -4.1534e-02,
         8.6182e-02,  1.2039e-02,  1.3977e-02, -4.9072e-02,  8.0261e-02,
         5.4688e-02,  1.7853e-02,  7.2823e-03,  1.5228e-02,  2.9449e-02,
         3.1982e-02,  2.5818e-02, -5.5389e-02,  3.7170e-02, -1.2802e-02,
         1.9760e-02,  3.8940e-02, -5.4626e-02,  3.9917e-02,  1.7166e-02,
         3.0746e-02,  6.7566e-02, -4.7874e-03,  2.7664e-02,  2.8133e-04,
         2.1683e-02, -2.2842e-02,  2.4994e-02,  3.3646e-03,  2.6825e-02,
         3.2806e-02,  2.2736e-02, -6.8283e-03,  4.8004e-02,  3.4729e-02,
        -2.1332e-02,  5.0964e-02,  1.3908e-02, -3.4149e-02, -2.2858e-02,
         6.3049e-02, -2.5879e-02,  4.0710e-02,  6.2500e-02,  3.2654e-02,
        -5.5618e-03,  5.6213e-02,  1.6937e-02,  4.1733e-03, -1.0971e-02,
         4.0192e-02,  1.4885e-02, -5.6801e-03, -3.5820e-03,  2.9861e-02,
         1.4612e-01,  5.8289e-02,  3.8879e-02, -3.9703e-02,  4.3915e-02,
         3.6987e-02,  8.7158e-02, -6.9458e-02, -1.1223e-02, -4.2542e-02,
        -2.8885e-02,  2.5314e-02,  5.0011e-03,  6.2256e-03, -8.0032e-03,
         3.3936e-02,  2.9739e-02, -5.8472e-02,  8.5266e-02,  2.7054e-02,
        -2.4841e-02, -8.4381e-03,  1.9958e-02,  1.4839e-02,  4.2542e-02,
         9.7427e-03, -3.7750e-02, -2.5368e-04, -4.7211e-02,  3.0518e-02,
         5.0934e-02,  3.3783e-02, -1.9363e-02, -6.2805e-02,  7.6843e-02,
        -3.0193e-03,  7.9498e-03,  8.2642e-02,  9.9915e-02,  2.3392e-02,
        -1.1673e-02,  7.2937e-02, -9.5215e-03,  1.5427e-02, -4.5746e-02,
         3.9520e-02,  2.3819e-02,  4.6509e-02,  2.5902e-03,  5.2124e-02,
        -2.4979e-02,  5.2521e-02, -3.2562e-02, -2.5864e-02, -2.1317e-02,
         1.5945e-02, -3.7109e-02, -1.4648e-02,  3.4485e-02,  3.6316e-02,
         6.3095e-03,  1.8814e-02,  5.0507e-02,  5.0476e-02, -5.0568e-02,
         6.0181e-02,  1.1368e-02,  3.7537e-02,  3.6030e-03,  1.7990e-02,
         3.3661e-02,  6.2637e-03, -8.5678e-03, -2.4261e-03,  5.9052e-03,
         6.9885e-02,  8.0627e-02,  4.7363e-02,  4.1565e-02, -4.6722e-02,
        -1.4450e-02,  1.8692e-02,  6.0043e-03,  4.6444e-04, -3.6804e-02,
         2.3712e-02,  6.9885e-03,  1.0674e-02,  3.8635e-02, -3.6255e-02,
         1.5022e-02,  2.9709e-02, -8.1873e-04,  2.7695e-02, -1.3939e-02,
        -2.7664e-02,  2.0630e-02,  5.1361e-02, -2.9251e-02,  3.4760e-02,
         6.8207e-03, -5.6427e-02,  1.3489e-02,  2.2446e-02, -3.1525e-02,
        -6.6452e-03, -2.1167e-01,  4.2450e-02,  3.1799e-02,  4.5837e-02,
        -6.5956e-03,  2.0966e-02, -2.0618e-03,  2.2034e-02,  4.4647e-02,
         1.9569e-03,  1.1032e-02, -2.1515e-02, -1.4214e-02, -4.5128e-03,
         2.2415e-02,  6.2561e-03,  2.3941e-02,  3.9062e-02,  1.8265e-02,
         3.5004e-02,  7.0496e-03,  2.9694e-02,  1.3218e-03,  3.9948e-02,
         3.8409e-04,  1.4963e-03,  1.8951e-02, -3.6682e-02,  1.7441e-02,
        -3.0350e-02,  5.8319e-02, -3.9215e-02,  7.4402e-02,  2.7512e-02,
        -8.1406e-03,  6.6406e-02,  2.9984e-02,  1.7380e-02,  9.1858e-03,
         5.3345e-02, -4.8485e-03,  2.8900e-02,  5.8594e-02,  1.1436e-02,
         2.0844e-02,  3.0304e-02,  1.0815e-03,  1.8652e-01, -1.5747e-02,
         1.2451e-02, -1.7517e-02, -3.1860e-02,  1.4534e-02, -1.4915e-02,
        -2.1210e-02,  7.5500e-02,  8.2321e-03, -1.7410e-02, -1.1692e-03,
         6.9702e-02,  1.7258e-02,  4.4891e-02,  8.9493e-03,  3.7415e-02,
        -1.7868e-02, -1.2878e-02, -1.3000e-02,  5.8807e-02,  6.0089e-02,
         6.6833e-02,  4.4281e-02,  5.2277e-02,  3.9276e-02,  5.6061e-02,
        -7.8735e-03,  9.0088e-02,  4.5685e-02,  8.8379e-02, -5.0888e-03,
         1.5915e-02,  1.7929e-02, -7.8735e-03,  7.6538e-02,  3.6133e-02,
        -5.2795e-02, -3.4912e-02, -5.2765e-02,  2.4689e-02, -6.9946e-02,
         3.0212e-02,  5.2490e-02, -5.7404e-02, -2.0844e-02,  6.0455e-02,
         4.6997e-02,  5.7182e-03,  3.8330e-02,  3.1403e-02, -2.1301e-02,
        -3.5400e-02, -5.9509e-02,  4.7180e-02, -5.1155e-03, -8.3694e-03,
        -5.5161e-03,  1.2494e-01, -1.4053e-02,  5.1880e-02, -7.0557e-02,
         5.4901e-02, -4.3152e-02,  6.5369e-02, -3.0334e-02,  1.8463e-02,
         8.8013e-02,  2.6947e-02,  6.6719e-03,  1.2329e-02,  3.4302e-02,
        -4.7424e-02, -9.5749e-03, -3.3203e-02,  5.8014e-02,  4.7424e-02,
        -2.1072e-02,  6.5125e-02,  4.7255e-04,  5.2277e-02, -3.3997e-02,
        -3.0075e-02,  1.1909e-02,  2.1301e-02, -4.4647e-02,  4.3365e-02,
        -5.3894e-02,  4.8645e-02,  6.4812e-03, -3.1982e-02,  5.1361e-02,
         5.2795e-02, -8.1177e-02,  7.3669e-02,  2.1591e-02,  1.2444e-02,
         5.7037e-02,  1.8784e-02, -1.1360e-02,  9.8705e-04, -5.2376e-03,
         3.8086e-02, -5.3467e-02,  2.7786e-02,  1.1238e-02,  7.4402e-02,
        -7.2510e-02,  8.3130e-02, -8.1482e-02,  1.8326e-02, -3.1891e-02,
        -2.0004e-02, -1.8692e-02,  4.4037e-02,  4.8065e-03, -1.1406e-02,
         3.7872e-02,  5.6488e-02, -1.1276e-02,  1.6260e-03, -1.3000e-02,
         1.0089e-01,  7.7026e-02, -2.8717e-02, -7.3425e-02, -3.6896e-02,
        -2.0691e-02,  6.9237e-03, -3.6407e-02,  1.4870e-02,  4.4525e-02,
         2.6703e-02,  3.3905e-02,  5.2063e-02, -2.0523e-02, -7.4158e-03,
        -5.3925e-02,  4.8920e-02,  4.2114e-02, -9.6893e-03,  3.3630e-02,
        -2.1713e-02, -3.8338e-03,  7.2205e-02, -2.5635e-02,  7.4280e-02,
        -4.7546e-02, -9.8877e-03,  8.2169e-03, -7.9422e-03,  2.2736e-02,
         1.1826e-02,  7.0374e-02,  7.7026e-02,  1.9145e-04,  2.6382e-02,
         2.7115e-02,  5.0446e-02, -2.1912e-02,  3.9490e-02, -2.5192e-02,
         1.2756e-02,  8.4229e-03,  8.5205e-02,  3.0548e-02,  2.8152e-02,
         2.3804e-03,  6.9580e-02, -4.7211e-02,  1.3147e-01,  9.7839e-02,
         5.5351e-03, -2.7176e-02,  3.1860e-02, -3.0273e-02,  4.5990e-02,
         1.8143e-02, -1.4282e-02,  2.4689e-02,  6.4758e-02,  4.0649e-02,
         3.3997e-02, -3.6278e-03, -2.2079e-02,  2.8366e-02,  3.3936e-02,
        -4.5074e-02,  3.6682e-02,  1.0979e-02, -1.3132e-03, -2.4033e-02,
         1.2299e-01, -1.1482e-02, -2.9373e-03, -3.0869e-02, -1.9852e-02,
         2.0081e-02,  7.8201e-03, -2.5665e-02,  3.4058e-02,  3.5858e-02,
         5.5389e-03,  2.2964e-02,  9.9716e-03, -4.7516e-02,  4.3518e-02,
         2.6836e-03, -1.1490e-02,  2.8214e-02, -3.2715e-02, -8.2016e-03,
         4.6997e-02, -6.2744e-02,  4.8553e-02,  2.7561e-03, -3.5156e-02,
        -4.8859e-02,  8.0185e-03,  5.1117e-02, -2.0752e-02,  2.4536e-02,
         1.4259e-02,  9.9258e-03,  4.2816e-02,  4.6387e-02,  6.7566e-02,
         2.9892e-02,  2.8580e-02, -1.0406e-02,  4.1351e-02, -7.5264e-03,
         2.5146e-02,  4.0100e-02,  4.2664e-02, -5.0964e-03,  2.9221e-02,
        -2.7542e-02,  9.6130e-03, -1.5350e-02, -3.6896e-02, -3.6926e-02,
         3.6454e-04,  3.2104e-02,  2.9984e-02,  1.0022e-01,  4.4434e-02,
         5.7739e-02,  7.5798e-03,  7.5073e-03,  3.7048e-02,  8.5327e-02,
        -4.1107e-02, -5.1270e-02, -3.6804e-02, -2.2385e-02,  4.2999e-02,
        -5.2307e-02, -1.0704e-02, -3.0731e-02,  1.8372e-02,  4.4586e-02,
        -2.2324e-02, -2.2369e-02,  4.6661e-02,  1.8997e-02,  5.8380e-02,
        -2.7802e-02,  2.2400e-02, -1.9043e-01,  7.2571e-02,  6.4926e-03,
        -8.8043e-03, -6.3477e-02,  1.6052e-02,  5.2582e-02,  1.0345e-02,
         1.0246e-02,  6.8893e-03, -1.5717e-02,  2.3849e-02,  6.9702e-02,
         5.0323e-02, -3.1052e-02, -3.7628e-02,  7.7629e-04, -2.3636e-02,
        -4.4220e-02,  3.1494e-02, -1.5625e-02, -5.6885e-02,  4.5074e-02,
         9.1248e-03, -2.9114e-02,  4.4342e-02, -2.2125e-02,  5.3894e-02,
         5.3558e-02,  4.1992e-02, -2.6230e-02,  1.0730e-01, -1.7868e-02,
        -1.9062e-04,  3.1006e-02,  6.5857e-02,  1.4893e-02, -5.5275e-03,
        -4.1618e-03, -1.1589e-02, -6.1493e-02,  1.2280e-01,  4.5593e-02,
         3.9886e-02,  3.4821e-02, -6.8115e-02,  2.9221e-03, -3.5381e-03,
         6.4758e-02,  3.1799e-02,  6.7078e-02,  2.8046e-02,  1.6556e-02,
         1.4626e-02, -7.0190e-02,  1.8784e-02, -4.0222e-02, -3.3661e-02,
         2.8641e-02,  1.3588e-02, -2.6382e-02, -1.8097e-02, -6.9809e-03,
         4.2206e-02,  4.1138e-02,  5.9265e-02,  2.5803e-02,  2.4506e-02],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[-0.0091,  0.0875,  0.0466,  ..., -0.0451, -0.0168,  0.0672],
        [ 0.0104,  0.0867, -0.0210,  ...,  0.0343, -0.0607, -0.0113],
        [-0.0244,  0.0151, -0.0345,  ...,  0.0091,  0.0011, -0.0273],
        ...,
        [ 0.0049, -0.0332,  0.0409,  ..., -0.0280,  0.0202, -0.0093],
        [-0.0086,  0.0198, -0.0697,  ..., -0.0039, -0.0404,  0.0318],
        [-0.0318,  0.0663,  0.0192,  ..., -0.0288,  0.0931, -0.0209]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([ 0.0308,  0.0130,  0.0107,  ...,  0.0292,  0.0370, -0.0227],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[-0.0359, -0.0132, -0.0651,  ..., -0.0422, -0.0438,  0.0899],
        [ 0.0037, -0.0089, -0.0170,  ..., -0.0126, -0.0022, -0.0277],
        [ 0.0020,  0.0042,  0.0059,  ..., -0.0269, -0.0087,  0.0242],
        ...,
        [-0.0148,  0.0332,  0.0330,  ...,  0.0306, -0.0072, -0.0430],
        [ 0.0243,  0.0825, -0.0374,  ..., -0.0396, -0.0131,  0.0333],
        [ 0.0038,  0.0005, -0.0599,  ...,  0.0224, -0.0708, -0.0202]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([ 2.6474e-02,  1.7059e-02, -1.3664e-02, -1.1871e-02,  4.4983e-02,
        -5.2309e-04, -8.1329e-03, -2.5024e-02,  1.7288e-02,  4.4128e-02,
         7.9346e-03, -4.2801e-03, -3.3173e-02, -2.1973e-02,  2.3117e-02,
         3.4790e-02,  1.6449e-02, -1.7899e-02, -6.8512e-03,  1.2100e-02,
         2.7832e-02,  2.1378e-02, -3.2005e-03,  1.4008e-02,  1.8112e-02,
         4.1016e-02,  7.8506e-03, -7.5645e-03,  3.4393e-02, -2.0523e-02,
        -1.4900e-02,  1.3046e-02, -5.1994e-03, -2.5043e-03,  1.5945e-03,
         1.4572e-02,  2.9945e-03, -1.6203e-03, -3.0502e-02, -3.8643e-03,
        -1.0902e-02, -2.0050e-02,  1.9882e-02,  3.1830e-02, -3.0060e-02,
        -7.0114e-03, -1.8082e-02,  3.0655e-02, -1.4748e-02, -6.5346e-03,
        -1.9318e-02, -5.5725e-02,  1.3634e-02, -1.2100e-02, -1.7822e-02,
         3.0289e-02,  3.2623e-02,  6.4230e-04, -2.5024e-02,  6.6471e-04,
        -2.3788e-02, -1.1044e-03,  7.2266e-02, -4.8096e-02,  3.4607e-02,
         1.3741e-02,  1.8127e-02, -3.8330e-02,  2.2568e-02, -3.9673e-02,
         1.4282e-02,  1.7349e-02,  1.6006e-02,  2.6047e-02, -2.0813e-02,
         3.5645e-02,  1.1200e-02, -1.7822e-02, -4.1168e-02,  1.6403e-02,
        -2.7054e-02,  3.5152e-03, -3.7041e-03, -1.1787e-02,  1.0010e-02,
         3.6652e-02, -1.0826e-02,  4.4159e-02, -1.0582e-02,  1.0529e-02,
         2.9709e-02, -4.4006e-02, -1.2672e-02,  1.2321e-02, -1.7456e-02,
         2.1988e-02, -2.6112e-03,  3.8879e-02, -2.0050e-02,  1.6647e-02,
         4.6692e-02,  3.9253e-03,  2.6932e-02,  1.2077e-02,  3.4515e-02,
         1.1772e-02,  6.7377e-04,  1.3306e-02, -8.0338e-03,  1.3245e-02,
         7.7057e-03,  1.7128e-03, -2.6978e-02, -2.6352e-02,  2.1576e-02,
         3.2959e-02,  3.9856e-02, -3.1189e-02,  2.4384e-02, -2.5368e-03,
        -7.5378e-03,  1.8530e-03,  4.3457e-02, -2.7451e-02,  7.6599e-03,
        -1.2321e-02, -2.5436e-02,  4.4556e-03, -9.4147e-03,  1.3672e-02,
         2.4796e-02,  1.3054e-02,  2.3453e-02,  2.6154e-02,  3.8239e-02,
        -1.3184e-02, -2.9831e-02,  3.4302e-02, -4.3915e-02,  1.0521e-02,
        -1.6235e-02, -1.9684e-02,  3.1769e-02, -4.6417e-02, -2.5196e-03,
         1.3676e-03, -1.0880e-02, -5.3558e-03,  2.3605e-02,  1.6815e-02,
        -6.6719e-03, -1.0099e-03,  3.0899e-02, -1.4847e-02,  1.4374e-02,
         3.1616e-02,  3.2318e-02, -3.3264e-02, -3.3997e-02,  1.0300e-02,
        -1.0071e-02,  6.4507e-03, -6.7759e-04, -6.0455e-02, -2.3743e-02,
         2.2259e-03,  1.7303e-02,  3.4363e-02,  2.6260e-02, -1.1986e-02,
        -1.4824e-02, -3.5706e-03, -1.2184e-02, -1.1543e-02, -2.4170e-02,
        -3.1616e-02, -1.3939e-02, -1.3924e-02, -2.1866e-02,  2.6642e-02,
         3.0182e-02,  1.0429e-02, -7.7629e-03, -1.9714e-02,  1.1818e-02,
        -7.3493e-05, -1.9058e-02, -7.0419e-03,  2.7828e-03,  6.3553e-03,
         1.9653e-02,  2.0981e-03, -1.1978e-02, -2.5009e-02, -1.0386e-03,
        -3.6804e-02, -2.6493e-03,  1.3298e-02,  2.0828e-02,  2.3994e-03,
         9.7885e-03, -1.2466e-02, -1.1520e-02, -2.3949e-04, -6.7520e-03,
        -6.8436e-03,  7.8049e-03,  6.6223e-03, -2.8961e-02,  3.3783e-02,
         1.3138e-02,  3.9177e-03,  6.7062e-03,  2.0752e-02, -5.4443e-02,
         1.0437e-02,  2.8534e-02,  1.8158e-02, -3.9154e-02,  8.4305e-03,
         3.4027e-02, -4.7272e-02, -7.8659e-03,  1.6190e-02, -7.6752e-03,
         6.2180e-03,  2.0889e-02, -3.6377e-02, -5.0163e-03, -2.0233e-02,
         1.6068e-02, -3.6106e-03, -1.9272e-02, -5.2376e-03, -1.1436e-02,
         1.4305e-03, -4.1504e-03,  2.7176e-02, -2.8061e-02, -1.6174e-02,
        -2.3758e-02, -4.6875e-02, -9.0179e-03,  2.0081e-02, -2.6840e-02,
        -3.9642e-02, -5.6038e-03,  1.3618e-02, -2.5589e-02, -4.0070e-02,
        -1.0254e-02,  8.1482e-03, -5.2185e-03,  7.8506e-03, -2.5665e-02,
        -1.4648e-02, -1.9577e-02, -4.5563e-02,  2.5158e-03,  3.9032e-02,
        -2.2385e-02, -1.5884e-02,  9.9564e-03,  3.4424e-02,  3.0624e-02,
        -5.8533e-02, -2.5558e-02, -2.5787e-02, -3.8395e-03, -4.0527e-02,
         9.2220e-04,  1.9913e-02, -2.0462e-02, -2.8534e-02,  2.5177e-02,
        -1.1375e-02,  2.5314e-02, -3.7201e-02, -2.1820e-02,  4.1351e-02,
         1.7792e-02, -5.3368e-03, -4.8518e-04, -3.1433e-02,  1.1284e-02,
        -2.3514e-02, -7.7934e-03, -3.8116e-02,  2.3407e-02, -5.9090e-03,
        -4.2343e-03,  1.1604e-02, -1.9394e-02, -8.3923e-03,  5.7343e-02,
         2.7108e-04,  1.2413e-02, -1.1292e-02, -4.5013e-03, -2.6718e-02,
        -3.1805e-04, -4.8553e-02,  1.7502e-02, -3.1708e-02, -3.9124e-02,
         8.8196e-03, -1.7517e-02, -2.9861e-02,  1.0208e-02,  7.4272e-03,
        -1.5402e-03,  2.6825e-02,  6.2370e-03, -3.1147e-03, -2.6016e-02,
        -9.3231e-03, -5.9547e-03,  4.3945e-02,  3.9711e-03, -2.3392e-02,
         1.6281e-02, -1.0872e-02, -3.8643e-03,  2.1042e-02,  2.0401e-02,
         1.0262e-02, -2.5894e-02,  1.0712e-02,  4.6448e-02, -3.4424e-02,
        -1.3184e-02,  1.4702e-02,  2.3880e-02, -3.1948e-04, -1.0233e-03,
        -3.6102e-02, -6.4316e-03, -3.6407e-02, -4.0436e-03,  1.0597e-02,
        -1.7517e-02, -4.6730e-03, -1.8509e-02, -1.4626e-02, -2.4780e-02,
         1.0786e-03,  1.8692e-02, -2.9129e-02,  2.3880e-02, -1.4858e-03,
         1.3527e-02,  1.0651e-02,  2.0645e-02,  6.3515e-04, -1.6708e-02,
        -1.6174e-02, -3.8208e-02, -1.2520e-02,  6.6662e-04,  4.2114e-02,
        -2.1305e-03,  3.6316e-02, -1.3657e-02, -2.8305e-02,  6.8665e-03,
         2.0111e-02, -9.3002e-03, -1.4748e-02, -3.5248e-02,  1.0338e-02,
         2.1652e-02, -1.7643e-03, -6.4964e-03,  1.7014e-02,  3.6011e-03,
         9.6741e-03,  1.1696e-02, -9.9792e-03,  1.0061e-03,  1.5312e-02,
        -5.9242e-03, -2.5043e-03, -1.2466e-02, -2.2583e-02, -1.6357e-02,
        -1.5137e-02, -2.2659e-02, -5.3520e-03, -3.6530e-02, -5.7831e-03,
        -4.7188e-03, -3.9398e-02,  1.4503e-02, -2.8824e-02,  1.9760e-02,
        -6.8741e-03,  1.7914e-02,  1.3283e-02,  2.0279e-02, -1.2611e-02,
        -1.7822e-02, -1.0063e-02,  3.3020e-02, -3.1311e-02, -9.9106e-03,
         1.2344e-02, -4.6570e-02,  1.2253e-02, -6.6340e-05, -2.4155e-02,
        -2.7344e-02, -2.5421e-02,  5.9631e-02, -2.3026e-02, -4.4708e-02,
        -4.9362e-03, -1.9836e-03,  1.8616e-02,  3.4504e-03,  1.6556e-02,
         2.6875e-03,  1.6602e-02, -3.4088e-02,  3.4294e-03,  3.0499e-03,
        -2.4002e-02,  1.5434e-02, -3.1219e-02, -4.2229e-03, -4.9286e-03,
        -4.4060e-03,  3.3295e-02, -2.8412e-02, -2.5730e-03,  5.3772e-02,
        -1.1816e-03, -5.3406e-03, -1.1177e-02, -3.7781e-02, -1.5450e-02,
         8.3771e-03,  6.5384e-03,  2.2720e-02, -1.0429e-02, -2.3621e-02,
        -2.4216e-02, -1.5594e-02,  3.0327e-03, -3.4485e-02, -9.6283e-03,
        -4.9553e-03, -2.3425e-04, -2.3972e-02, -6.6452e-03,  1.0452e-02,
        -1.1177e-02,  3.1113e-02,  2.0386e-02,  3.0273e-02,  2.0859e-02,
         1.9623e-02, -5.9013e-03,  1.5793e-02, -3.7811e-02, -2.0630e-02,
        -2.0981e-02, -9.4833e-03, -1.0849e-02,  3.0411e-02,  2.2903e-02,
         1.1101e-02, -1.3557e-02, -1.0567e-02, -2.8915e-02,  1.3418e-03,
        -1.3618e-02, -7.2289e-03, -1.8402e-02,  1.5778e-02, -2.6276e-02,
         1.7044e-02,  9.5139e-03,  3.5461e-02, -1.5221e-02, -1.0384e-02,
         3.9635e-03,  9.2545e-03, -9.0103e-03,  3.4821e-02,  3.3455e-03,
         1.8311e-02, -1.4633e-02, -1.4320e-02,  1.3313e-03,  1.4503e-02,
         8.0261e-03, -3.1708e-02, -3.2745e-02,  3.2440e-02, -5.5695e-02,
         1.6037e-02,  1.1200e-02,  1.9436e-03,  6.0577e-03, -7.6485e-03,
        -1.4137e-02, -2.0874e-02, -2.7496e-02,  2.3422e-02,  3.1143e-02,
         1.8158e-02, -2.8976e-02, -2.5238e-02, -2.8442e-02,  2.2766e-02,
        -1.0506e-02, -3.7415e-02,  2.5711e-02,  1.2680e-02, -8.5526e-03,
        -2.0966e-02,  1.0376e-03,  1.3168e-02,  3.6926e-02, -1.3214e-02,
        -4.7302e-03,  2.4796e-02,  2.6978e-02,  6.7139e-03,  4.2542e-02,
         6.9962e-03,  1.9516e-02,  1.6113e-02, -5.0903e-02, -1.7624e-02,
        -6.5430e-02,  3.6987e-02,  6.1607e-03,  5.8167e-02,  2.0752e-02,
        -1.3084e-02, -2.8412e-02, -2.5635e-02, -6.8970e-03, -1.6617e-02,
        -1.9897e-02,  1.2436e-02, -5.4550e-03,  3.9482e-03,  5.0240e-03,
        -2.5482e-02, -1.2993e-02,  2.4748e-04,  7.3967e-03,  2.7893e-02,
         3.7518e-03,  1.0323e-02,  1.4481e-02,  1.4954e-02,  2.1408e-02,
        -2.0172e-02,  3.0556e-03,  1.9867e-02, -2.5539e-03,  3.8727e-02,
        -2.1683e-02,  3.2101e-03, -3.4027e-02,  6.5613e-03,  4.4327e-03,
         1.5686e-02,  2.8534e-02, -1.9882e-02,  5.8289e-03,  1.1696e-02,
        -6.9084e-03, -1.6220e-02, -7.8735e-03,  2.1133e-03, -3.4485e-02,
         1.0155e-02, -3.4943e-02,  4.5227e-02, -1.8860e-02, -1.1833e-02,
         3.3016e-03,  2.5902e-03, -4.9225e-02,  1.5068e-02, -2.1301e-02,
         1.4679e-02, -4.0680e-02,  4.2999e-02,  1.4648e-02,  1.5312e-02,
         1.5457e-02,  1.9531e-02, -2.2644e-02,  1.2619e-02, -2.0924e-03,
         1.3519e-02, -4.7241e-02, -7.1068e-03,  1.6647e-02, -1.0269e-02,
        -2.4429e-02,  2.3941e-02, -6.7215e-03, -2.3468e-02, -1.6220e-02,
         1.2131e-02, -6.4964e-03, -1.4854e-02,  9.5596e-03,  1.9426e-03,
         8.8501e-04,  2.1469e-02,  1.3756e-02, -2.6215e-02, -6.7749e-03,
         2.6321e-03,  1.4114e-02,  2.5360e-02,  7.7477e-03, -5.5504e-03,
         7.7133e-03,  1.1856e-02,  1.3313e-02, -1.8326e-02, -1.5640e-02,
         3.7766e-03, -3.9276e-02, -4.1199e-02, -3.4714e-03,  5.9652e-04,
        -2.2873e-02, -2.5146e-02,  1.5488e-02,  3.2139e-03, -3.5828e-02],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[-0.0338, -0.0111, -0.0251,  ...,  0.0130,  0.0095,  0.0758],
        [-0.0177,  0.0105,  0.0114,  ...,  0.0047, -0.0180,  0.0124],
        [ 0.0072, -0.0331,  0.0149,  ..., -0.0085, -0.0301,  0.0121],
        ...,
        [-0.0609,  0.0375,  0.0155,  ...,  0.0158, -0.0131,  0.0048],
        [-0.0027, -0.0317, -0.0153,  ..., -0.0476,  0.0732,  0.0206],
        [ 0.0602, -0.0051, -0.0186,  ...,  0.0283, -0.0223,  0.0305]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([-1.7441e-02,  1.2917e-02,  1.4725e-02,  1.0880e-02,  8.5068e-03,
         1.1835e-03, -2.1149e-02,  1.9241e-02,  4.1771e-03, -1.6937e-02,
         1.1642e-02, -1.1597e-02, -6.3419e-04, -4.5121e-05, -3.4809e-03,
         1.0948e-03,  1.9623e-02,  3.9917e-02, -9.3765e-03,  3.7292e-02,
         2.3178e-02,  7.1602e-03, -4.5990e-02,  2.4445e-02,  6.8130e-03,
         2.9556e-02, -9.3918e-03,  1.4595e-02,  1.1520e-02, -3.1796e-03,
         2.6657e-02,  1.2688e-02, -1.1616e-03,  2.5818e-02, -6.9542e-03,
        -1.3634e-02,  1.2009e-02,  1.7059e-02, -4.1351e-02, -3.0746e-02,
        -8.7738e-03, -2.1820e-02,  1.0872e-02, -1.1108e-02, -3.7251e-03,
         1.3077e-04, -3.8605e-02, -9.1248e-03,  1.0094e-02, -6.3820e-03,
         3.3661e-02, -5.4596e-02, -7.4291e-04,  3.5400e-02,  1.7654e-02,
        -2.4910e-03,  6.0699e-02,  2.2430e-02, -3.2410e-02,  3.9177e-03,
        -2.8702e-02,  6.7444e-03,  6.9199e-03, -3.1738e-02,  2.5299e-02,
        -6.4507e-03, -2.6703e-02,  1.3084e-03,  1.7548e-02, -2.4887e-02,
         4.3488e-02,  4.5090e-03, -3.5667e-03, -1.1921e-03,  2.1042e-02,
        -3.4637e-02,  6.4148e-02,  2.4164e-04, -2.2079e-02, -4.0222e-02,
         4.2992e-03,  1.3611e-02,  1.1703e-02,  2.1500e-02,  4.7577e-02,
        -1.2863e-02,  1.6495e-02, -2.9663e-02,  3.6545e-03, -1.0201e-02,
        -2.4704e-02, -7.9575e-03, -5.9387e-02,  1.9623e-02, -4.8256e-03,
        -1.9150e-02,  5.2567e-03,  4.4525e-02, -5.4893e-03,  1.2619e-02,
        -2.4887e-02,  5.9776e-03, -3.2318e-02, -1.9455e-02, -2.7618e-02,
         1.6083e-02, -4.8218e-02,  3.2379e-02, -1.0567e-03,  3.1921e-02,
         2.3376e-02, -2.8580e-02, -1.3191e-02,  6.0940e-04,  5.6763e-03,
         1.0361e-02, -8.5144e-03, -2.4231e-02,  2.0950e-02,  1.9394e-02,
         1.2039e-02, -6.9237e-03, -3.2616e-03, -2.7115e-02,  1.6785e-04,
         5.2338e-03,  8.2159e-04, -2.5368e-04,  2.5902e-03, -3.6716e-03,
        -4.9019e-03, -7.5302e-03,  3.0228e-02,  1.9104e-02,  6.7635e-03,
        -3.0441e-02, -2.2247e-02,  3.5370e-02,  9.8572e-03, -5.4092e-03,
        -6.8359e-03, -5.9692e-02,  1.3039e-02,  2.2095e-02,  2.6932e-02,
         1.6235e-02, -5.0476e-02,  1.9791e-02,  1.3504e-02, -9.4986e-03,
        -5.4092e-03, -1.2199e-02,  7.4387e-03,  1.9855e-03,  3.1677e-02,
         2.5543e-02, -9.2087e-03, -3.2684e-02,  1.0620e-02, -1.3397e-02,
         3.4088e-02, -1.3664e-02,  3.4785e-04,  3.2349e-02,  1.9821e-02,
         4.1534e-02, -2.1687e-03, -2.9694e-02, -1.2007e-03, -2.4734e-02,
        -4.6844e-02,  4.5502e-02, -1.6785e-02,  2.5833e-02, -3.1113e-02,
        -1.4282e-02, -1.8036e-02,  2.0859e-02, -7.0000e-03, -2.3384e-03,
        -1.5068e-02, -2.5009e-02,  3.0350e-02, -2.1667e-02, -4.3396e-02,
        -1.0700e-03, -6.8398e-03, -2.7573e-02,  1.4160e-02, -4.5105e-02,
         2.2614e-02,  3.8361e-02,  5.1546e-04, -8.3466e-03, -4.8904e-03,
         2.5803e-02,  8.1329e-03,  9.9106e-03,  3.9093e-02,  1.2901e-02,
         2.2064e-02, -1.4496e-02,  1.4099e-02,  6.7871e-02, -2.9175e-02,
        -3.8971e-02, -1.7197e-02, -1.5793e-02,  1.4343e-03,  1.4503e-02,
        -2.0370e-03,  2.3605e-02,  1.5593e-04, -3.3997e-02,  2.8858e-03,
         1.2894e-02,  4.1351e-02, -2.9846e-02,  2.8477e-03,  3.0121e-02,
        -1.8875e-02, -2.8183e-02,  1.4153e-02, -1.8677e-02,  1.6281e-02,
        -8.5388e-02, -3.9612e-02, -4.1534e-02, -4.1870e-02,  2.1866e-02,
        -2.5543e-02, -4.1870e-02,  1.1406e-02,  2.4281e-03, -2.4857e-02,
        -1.9577e-02, -2.0386e-02, -8.6746e-03, -2.1484e-02, -2.2293e-02,
        -3.2043e-02,  5.6953e-03,  4.8950e-02,  1.6815e-02,  4.1962e-03,
         1.6174e-02, -3.3173e-02,  7.1030e-03,  9.8648e-03,  3.2318e-02,
         2.4002e-02, -2.0187e-02, -2.3441e-03, -7.7896e-03, -2.4597e-02,
         5.5809e-03, -3.7026e-04,  1.3405e-02,  1.9730e-02,  3.4607e-02,
        -2.7008e-02, -3.6133e-02, -7.3891e-03,  2.6569e-03, -2.1591e-03,
         1.2962e-02,  3.2990e-02, -2.2202e-02, -2.0126e-02,  6.4163e-03,
         1.0422e-02,  2.7740e-02, -2.0561e-03, -5.2582e-02,  2.3224e-02,
         2.2202e-02, -2.3773e-02, -1.3176e-02, -5.6061e-02,  2.9236e-02,
         1.4847e-02, -1.8097e-02,  4.0092e-03, -2.3422e-03, -1.8482e-03,
        -3.7109e-02, -1.3885e-02, -4.7028e-02,  2.6722e-03,  9.7961e-03,
         1.2489e-02,  2.1927e-02, -2.4200e-02, -1.8127e-02,  6.6757e-03,
        -3.7899e-03,  6.0415e-04, -4.3091e-02,  3.7785e-03, -1.5465e-02,
        -1.9455e-02,  1.6083e-02,  3.5686e-03, -2.9266e-02,  1.6602e-02,
         2.9984e-03, -4.2206e-02, -5.8327e-03,  9.5459e-02, -1.9897e-02,
         1.8478e-02, -2.0676e-02, -8.8425e-03,  4.0627e-03,  5.0812e-03,
         1.0939e-03,  3.2104e-02,  2.3556e-03,  5.4703e-03, -2.7634e-02,
        -1.4732e-02,  3.1090e-03, -1.0910e-03,  9.2850e-03, -4.8943e-03,
         2.8534e-02,  2.0142e-02, -5.5389e-03, -1.0361e-02,  5.0385e-02,
         1.0750e-02, -5.6686e-03,  1.8616e-02,  6.9313e-03,  2.0676e-02,
        -1.6586e-02, -3.1342e-02,  1.5268e-03,  4.8256e-03,  1.3153e-02,
         2.4841e-02,  2.8396e-04,  2.8946e-02, -3.7598e-02, -7.1564e-03,
        -2.3575e-02,  8.4839e-03,  1.0933e-02,  1.3092e-02,  2.0309e-02,
         8.9874e-03,  4.3249e-04,  3.2715e-02,  4.6825e-04, -2.2812e-02,
        -1.2817e-02,  3.7842e-02,  2.7878e-02, -2.6550e-03, -1.4107e-02,
        -8.7509e-03, -1.5612e-03,  2.2293e-02,  3.6926e-02,  3.6377e-02,
        -4.0092e-03,  2.6138e-02,  1.1223e-02,  5.0079e-02, -3.4241e-02,
         2.5284e-02,  1.4809e-02,  3.6530e-02, -2.5269e-02,  2.4281e-03,
        -1.2077e-02,  6.7863e-03, -1.2306e-02,  2.6947e-02, -2.8824e-02,
         7.3318e-03,  1.4946e-02,  9.3231e-03,  5.2521e-02,  1.7746e-02,
        -5.7648e-02, -8.5602e-03,  1.5121e-02,  7.5607e-03,  1.6342e-02,
         1.2390e-02, -3.4515e-02,  6.1035e-03, -1.4595e-02, -1.0307e-02,
         1.3687e-02,  1.5480e-02, -4.3518e-02, -1.2901e-02,  1.8402e-02,
         5.6793e-02, -1.1513e-02,  7.4654e-03, -4.7073e-03, -4.8981e-02,
        -9.6359e-03, -2.2202e-02, -4.2191e-03,  1.0590e-02, -1.7309e-03,
         6.9199e-03,  1.8814e-02,  3.9185e-02,  4.8561e-03, -1.7349e-02,
        -1.5610e-02, -1.4221e-02,  1.5173e-03,  8.9798e-03, -9.6381e-05,
         4.4891e-02,  2.7023e-02, -1.6069e-03,  1.2886e-02,  4.1840e-02,
         1.9638e-02, -4.9469e-02,  5.8174e-03, -3.2196e-02, -2.8782e-03,
        -2.1362e-02, -3.3386e-02, -2.1637e-02,  2.0126e-02,  3.0045e-02,
         1.1246e-02,  4.5471e-03, -8.1482e-03,  1.6205e-02,  4.1138e-02,
        -8.5526e-03,  1.2878e-02, -1.1002e-02,  1.5244e-02, -3.1006e-02,
        -1.6861e-02, -3.7308e-03,  5.2887e-02, -1.7578e-02, -7.9193e-03,
         1.6342e-02, -1.1642e-02, -9.7809e-03, -6.2752e-03, -4.6883e-03,
         1.4023e-02,  2.9083e-02, -1.3107e-02, -4.0483e-04, -3.5400e-02,
        -1.4679e-02, -1.3039e-02,  3.5645e-02, -1.8631e-02,  1.3046e-03,
         1.7487e-02, -8.8348e-03, -3.7872e-02,  6.4850e-03,  3.0838e-02,
         1.3161e-02, -7.6294e-02, -1.0178e-02,  6.3896e-03,  3.9711e-03,
         1.4603e-02,  3.2349e-03,  2.6276e-02,  4.2152e-03,  2.6166e-05,
         1.8341e-02,  4.0405e-02,  2.5055e-02,  3.9093e-02, -3.4058e-02,
        -1.6861e-02, -6.3667e-03, -9.0714e-03, -4.6570e-02,  2.3941e-02,
         2.6230e-02, -7.3051e-03,  1.1147e-02,  6.7749e-03,  7.6942e-03,
        -5.2414e-03,  2.6459e-02, -3.0289e-03,  7.2517e-03,  4.6661e-02,
        -1.5884e-02,  1.5068e-03,  2.7740e-02,  1.9287e-02,  7.8964e-03,
         2.4628e-02,  1.6312e-02, -7.5245e-04, -2.0279e-02,  2.4323e-02,
        -3.2864e-03, -2.1210e-02, -2.2186e-02, -1.8265e-02,  8.9025e-04,
         2.5040e-02, -1.4748e-02,  3.4393e-02, -3.1860e-02,  1.8661e-02,
        -1.6708e-02, -5.0392e-03,  2.1332e-02, -2.7557e-02, -1.4938e-02,
         1.2558e-02, -8.0948e-03,  8.9417e-03, -2.6886e-02, -2.2919e-02,
         2.0020e-02, -5.4230e-02, -2.4002e-02,  2.7561e-03, -6.6452e-03,
        -8.1778e-04, -4.8370e-02, -4.7684e-03,  2.5711e-02, -2.1362e-02,
         2.2369e-02, -4.2572e-03, -7.7820e-03,  1.2222e-02, -1.5182e-03,
         2.5894e-02,  6.0730e-03, -9.8877e-03, -1.0704e-02, -8.1482e-03,
         1.3718e-02, -3.3539e-02,  2.1973e-02,  5.5809e-03, -6.8359e-03,
        -2.0004e-02,  9.6893e-03, -5.9166e-03,  3.5431e-02,  1.1017e-02,
         3.6865e-02, -1.0605e-03, -2.9984e-02, -2.7939e-02,  3.9490e-02,
         3.1082e-02,  1.0193e-02,  3.8879e-02,  2.8625e-02, -8.0338e-03,
        -1.6651e-03,  1.2123e-02, -5.3444e-03,  1.0941e-02,  3.1738e-02,
        -1.1612e-02, -1.3596e-02,  1.0977e-03,  1.6724e-02, -1.0262e-02,
        -1.5823e-02, -2.0199e-03, -4.3182e-02, -2.4933e-02,  4.6509e-02,
        -5.7312e-02, -4.4159e-02, -1.6418e-02,  1.5182e-03, -3.6964e-03,
        -3.6011e-02,  1.3466e-02,  1.6830e-02, -7.4730e-03,  9.5081e-04,
        -3.8361e-02, -2.2675e-02,  3.5915e-03,  7.0419e-03, -1.5091e-02,
         2.7752e-04, -1.4710e-04, -3.5915e-03,  6.0852e-02, -9.5940e-04,
         5.0774e-03,  1.0292e-02, -5.8975e-03, -1.3535e-02,  1.3138e-02,
        -3.4058e-02,  1.8845e-02,  6.0654e-04,  1.0948e-02, -1.3931e-02,
         1.2642e-02, -1.7548e-02, -9.1705e-03,  1.9424e-02, -4.5586e-03,
        -4.7760e-03,  1.2093e-02,  9.6054e-03,  6.3667e-03, -3.0228e-02,
        -4.1466e-03, -9.5901e-03,  1.5961e-02,  1.1063e-02, -2.0905e-02,
         1.5244e-02, -2.0477e-02,  2.2766e-02,  1.2337e-02,  3.2349e-03,
         3.4729e-02,  3.4580e-03, -1.3344e-02,  4.2839e-03, -1.2428e-02],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([0.5479, 0.6523, 0.6436, 0.6309, 0.6152, 0.5996, 0.6709, 0.5952, 0.6504,
        0.6777, 0.5522, 0.5645, 0.5459, 0.5684, 0.6089, 0.6064, 0.5659, 0.5801,
        0.5776, 0.6113, 0.6245, 0.6128, 0.6411, 0.7563, 0.5840, 0.6123, 0.6753,
        0.6865, 0.7158, 0.6318, 0.6138, 0.5557, 0.6514, 0.5952, 0.6074, 0.6187,
        0.5767, 0.6372, 0.6133, 0.6509, 0.6123, 0.5688, 0.5933, 0.5298, 0.5679,
        0.7046, 0.6260, 0.6426, 0.5854, 0.6494, 0.6865, 0.6787, 0.6909, 0.5752,
        0.7012, 0.5771, 0.6616, 0.6367, 0.6611, 0.6230, 0.6060, 0.5522, 0.6479,
        0.6909, 0.6123, 0.5801, 0.6753, 0.6670, 0.6519, 0.6953, 0.6719, 0.7056,
        0.6665, 0.6724, 0.6597, 0.7451, 0.7285, 0.5708, 0.7017, 0.6255, 0.6553,
        0.7437, 0.7153, 0.6567, 0.7290, 0.7656, 0.7202, 0.7598, 0.7036, 0.6802,
        0.7954, 0.7266, 0.7280, 0.7310, 0.7759, 0.7080, 0.7383, 0.6875, 0.7344,
        0.5366, 0.6172, 0.7036, 0.5923, 0.7168, 0.5942, 0.6577, 0.5996, 0.6689,
        0.6655, 0.6113, 0.6714, 0.5718, 0.6489, 0.5898, 0.6504, 0.6924, 0.7109,
        0.6973, 0.6963, 0.7051, 0.6226, 0.7134, 0.5908, 0.6094, 0.6284, 0.6870,
        0.6421, 0.6685, 0.6592, 0.5801, 0.6230, 0.6504, 0.6724, 0.6040, 0.6245,
        0.6343, 0.6636, 0.6035, 0.6167, 0.6382, 0.6650, 0.6484, 0.6216, 0.7139,
        0.6089, 0.6133, 0.6855, 0.6909, 0.6533, 0.6587, 0.7588, 0.6870, 0.7129,
        0.6860, 0.7583, 0.7266, 0.7227, 0.7231, 0.6567, 0.7285, 0.6611, 0.6294,
        0.7739, 0.7031, 0.6733, 0.7983, 0.7295, 0.7100, 0.6831, 0.7378, 0.7124,
        0.6069, 0.5845, 0.5957, 0.6787, 0.6011, 0.6035, 0.5854, 0.6621, 0.6797,
        0.5591, 0.6362, 0.5659, 0.6025, 0.5244, 0.6128, 0.6309, 0.5278, 0.5469,
        0.4639, 0.7422, 0.6958, 0.6836, 0.7603, 0.6875, 0.6685, 0.6138, 0.6660,
        0.6665, 0.6953, 0.6821, 0.5825, 0.6494, 0.6865, 0.6548, 0.5811, 0.6309,
        0.6382, 0.6821, 0.6309, 0.6372, 0.6226, 0.6694, 0.4680, 0.5894, 0.5991,
        0.5596, 0.5454, 0.5547, 0.6265, 0.6187, 0.5894, 0.5122, 0.5776, 0.5576,
        0.5742, 0.6147, 0.6084, 0.5088, 0.5815, 0.6895, 0.7295, 0.6729, 0.7280,
        0.7651, 0.6772, 0.7480, 0.7764, 0.6006, 0.7046, 0.6470, 0.6865, 0.6357,
        0.6909, 0.6553, 0.5825, 0.6475, 0.6699, 0.6338, 0.6631, 0.6108, 0.6606,
        0.6802, 0.6514, 0.6582, 0.6138, 0.6929, 0.5273, 0.5679, 0.6309, 0.6602,
        0.6299, 0.6665, 0.6431, 0.6436, 0.6309, 0.6250, 0.7583, 0.5859, 0.6562,
        0.6538, 0.6240, 0.7100, 0.6553, 0.5537, 0.6602, 0.7085, 0.6929, 0.5938,
        0.6611, 0.6479, 0.6641, 0.6602, 0.6245, 0.6392, 0.6084, 0.6416, 0.6479,
        0.7354, 0.7500, 0.6187, 0.6460, 0.6782, 0.5249, 0.6626, 0.6729, 0.6694,
        0.6816, 0.6348, 0.5698, 0.6514, 0.6782, 0.6455, 0.6201, 0.6865, 0.6333,
        0.5742, 0.6270, 0.6621, 0.5835, 0.6367, 0.6611, 0.6104, 0.6011, 0.5913,
        0.6992, 0.6367, 0.6714, 0.6763, 0.6235], device='cuda:0',
       dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([-1.8494e-02,  6.2012e-02, -6.2981e-03,  4.2328e-02,  8.7051e-03,
         1.2337e-02,  3.2104e-02, -1.4685e-01,  6.6345e-02,  7.0007e-02,
         4.0436e-02,  3.8788e-02,  4.8950e-02, -1.0248e-01,  3.7460e-03,
        -6.5735e-02,  6.8848e-02,  8.8440e-02,  1.1066e-01,  7.7209e-02,
        -6.0608e-02, -2.9488e-03, -1.6980e-01,  7.4402e-02,  9.2346e-02,
         5.4657e-02,  6.2943e-03,  1.0663e-01, -3.1525e-02,  1.1932e-01,
        -1.7197e-02,  1.0962e-01,  1.3184e-02,  8.5815e-02, -9.8511e-02,
        -4.1351e-02,  1.5552e-01, -3.0380e-02, -1.9760e-02, -4.2267e-02,
         2.4536e-02, -7.9834e-02,  1.9638e-02,  2.6245e-01,  1.3342e-01,
        -6.9275e-02, -8.7463e-02, -2.3022e-01, -3.0823e-02, -1.5027e-01,
         1.5479e-01,  7.0923e-02, -6.4026e-02, -1.0608e-01,  1.9141e-01,
        -2.2369e-02, -2.7130e-02, -6.5231e-04,  8.5327e-02, -2.4719e-02,
         1.1420e-01,  1.0931e-01, -1.0358e-01, -1.1713e-01,  1.0962e-01,
         1.3171e-01, -2.7374e-02, -1.3574e-01, -3.6865e-02,  5.8044e-02,
         4.5898e-02,  1.2901e-02,  2.1521e-01, -9.8572e-02,  2.3911e-02,
        -5.1605e-02,  1.4929e-01,  4.6051e-02,  4.0016e-03,  1.7688e-01,
         2.6688e-02, -1.3855e-01, -5.3833e-02, -7.8613e-02, -1.4392e-01,
         1.8585e-02,  1.8356e-02, -9.1476e-03,  1.3818e-01, -1.1743e-01,
         5.9021e-02, -3.0136e-02,  6.4468e-03,  2.7051e-01, -1.2537e-01,
        -1.0757e-02,  1.1810e-01,  8.2764e-02,  6.3049e-02, -1.0400e-01,
        -1.0840e-01,  8.2031e-02,  1.7542e-01, -1.2878e-01, -1.2407e-03,
         7.9651e-02,  6.5674e-02,  3.1021e-02,  9.2773e-02, -2.5146e-01,
        -1.1584e-01, -4.3213e-02,  4.6051e-02,  5.8777e-02,  6.6467e-02,
         1.3440e-01, -6.2378e-02, -3.1616e-02, -2.3605e-02,  4.2450e-02,
         1.5430e-01, -1.9760e-02,  1.1682e-01,  9.4055e-02, -2.3682e-01,
         4.5357e-03, -5.8746e-02, -9.8694e-02, -4.1046e-02,  1.8701e-01,
        -5.1208e-02,  1.8518e-01,  4.5563e-02, -7.4097e-02,  3.1113e-02,
         1.3947e-02,  1.0880e-02, -5.6763e-02, -9.0170e-04, -1.1780e-02,
         1.1467e-02,  2.1802e-01,  2.0129e-01,  4.6295e-02, -1.9189e-01,
        -9.9487e-03, -3.2288e-02,  1.5076e-01,  6.9580e-02, -4.6661e-02,
         2.1393e-02,  4.0466e-02,  8.4961e-02,  4.0436e-03, -1.1755e-01,
         1.0834e-03, -1.5823e-02,  1.4722e-01,  1.1292e-02,  7.1167e-02,
         9.3689e-02,  4.1962e-02, -7.4348e-03, -2.8000e-02,  1.0632e-01,
        -3.0737e-01,  1.4351e-02, -4.6967e-02, -1.8631e-02, -1.5945e-02,
        -2.0544e-01,  1.7319e-02,  6.9733e-03, -1.6943e-01, -4.7607e-02,
         6.3660e-02,  7.1350e-02,  1.0443e-01, -4.4678e-02,  1.1090e-01,
         5.4688e-02, -2.4211e-04, -8.0994e-02,  9.3628e-02, -1.3687e-02,
         5.9723e-02, -6.4148e-02,  1.7615e-01, -2.3730e-01,  2.0630e-01,
        -5.0140e-02,  1.4136e-01, -1.0605e-02, -6.2622e-02,  2.7985e-02,
         6.1768e-02, -2.7954e-02, -5.4962e-02,  1.5881e-01, -2.5803e-02,
         5.7800e-02, -1.3123e-01,  9.7961e-02, -1.5808e-01,  1.4087e-01,
         1.0437e-01,  4.8920e-02, -8.1177e-02,  1.0872e-02, -5.0262e-02,
        -9.6619e-02,  6.8054e-02,  6.7444e-02,  2.2876e-01, -1.1810e-02,
         5.2277e-02, -1.6589e-01, -4.1412e-02, -6.4270e-02, -5.3680e-02,
         3.2227e-02, -8.8013e-02, -2.0837e-01, -1.3611e-01, -1.3318e-01,
        -4.8248e-02, -3.9185e-02, -2.2498e-01,  4.2542e-02,  7.8857e-02,
         6.6528e-02, -1.0260e-01, -1.1499e-01, -2.3636e-02, -3.9520e-02,
        -1.3013e-01, -7.6477e-02, -1.6309e-01,  1.1700e-01, -5.4291e-02,
        -7.2266e-02,  1.5820e-01,  1.0376e-01, -1.3084e-02, -7.2144e-02,
        -2.0007e-01, -1.2610e-01,  2.4521e-02,  3.8544e-02,  1.0461e-01,
         1.2317e-01,  2.4445e-02,  1.9104e-01,  5.6671e-02, -1.3733e-01,
        -1.9562e-02, -9.5337e-02, -7.4219e-02,  5.7343e-02, -3.4943e-02,
         1.0620e-02, -1.0950e-01,  4.4060e-03, -7.6599e-02,  1.2952e-01,
         1.3892e-01,  1.0248e-01, -1.0333e-01, -6.4514e-02, -9.0881e-02,
        -7.9651e-02,  9.1309e-02,  2.6550e-02, -3.6774e-02, -2.2797e-02,
        -7.5012e-02,  5.9540e-02, -1.2085e-01, -6.9519e-02,  8.8959e-03,
         5.0110e-02,  6.9641e-02, -1.6589e-01, -7.2876e-02, -8.2169e-03,
         1.1737e-01,  1.5915e-02, -4.0070e-02, -2.6291e-02,  5.3345e-02,
         1.5088e-01, -1.9974e-02,  4.6326e-02, -1.7700e-02, -7.5531e-03,
         2.7084e-02, -9.5337e-02,  1.2245e-03, -4.3427e-02, -1.3794e-01,
         9.0332e-02,  2.9999e-02,  9.9915e-02,  2.0447e-03,  7.4646e-02,
         3.1952e-02,  8.6304e-02,  1.1279e-01,  1.2978e-02,  5.7159e-02,
        -6.1981e-02,  2.5063e-03, -5.2582e-02,  2.1326e-01, -1.9974e-02,
         1.1401e-01, -7.9193e-03, -1.6345e-01,  7.1045e-02, -1.5906e-01],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[ 0.0003,  0.0117,  0.0096,  ..., -0.0397,  0.0345,  0.0178],
        [-0.0403, -0.0125, -0.0108,  ...,  0.0039,  0.0055,  0.0054],
        [ 0.0095,  0.0035,  0.0198,  ...,  0.0435,  0.0463,  0.0177],
        ...,
        [-0.0133,  0.0077,  0.0142,  ..., -0.0048, -0.0288,  0.0007],
        [ 0.0109,  0.0291, -0.0362,  ..., -0.0448,  0.0230, -0.0224],
        [-0.0027,  0.0337,  0.0141,  ...,  0.0346,  0.0343, -0.0313]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([ 5.9540e-02,  3.7903e-02, -2.3270e-03, -3.2196e-02,  2.3956e-02,
         4.0558e-02,  1.8478e-02,  3.4546e-02,  8.2031e-02,  1.1249e-01,
         1.3452e-01, -5.9082e-02, -3.3173e-02,  4.7211e-02, -1.0303e-01,
        -8.1787e-02,  7.1411e-02,  6.4636e-02,  4.9973e-03, -8.5938e-02,
         3.5126e-02, -4.4037e-02, -4.5433e-03,  1.0345e-01, -1.1224e-01,
         2.9221e-02, -1.1346e-01,  8.0505e-02,  1.7868e-02, -7.7881e-02,
         9.1309e-02, -1.5869e-02, -1.2195e-01, -3.5950e-02, -4.6967e-02,
        -1.8644e-04,  1.1243e-01,  1.5369e-01,  9.7900e-02, -8.9798e-03,
        -4.1931e-02,  5.9784e-02,  3.5431e-02,  1.4397e-02,  1.6388e-02,
        -7.8678e-04, -3.3478e-02,  2.5421e-02, -8.3435e-02,  1.0767e-01,
        -5.1231e-03,  1.5588e-01,  4.6005e-03,  1.0150e-01,  8.1787e-02,
        -6.4270e-02, -7.4646e-02,  7.1411e-02, -6.2256e-02, -1.0870e-01,
        -5.6000e-02,  2.7451e-02, -4.7791e-02, -6.2561e-02,  6.3232e-02,
        -8.3252e-02,  1.1591e-01,  4.3610e-02, -5.7556e-02, -3.2959e-02,
        -5.6000e-03,  4.7852e-02, -1.2122e-01,  1.2482e-02, -1.6785e-02,
         9.6970e-03, -3.0956e-03,  5.3650e-02, -6.9214e-02, -1.2817e-01,
         8.6975e-03,  3.8879e-02,  2.8564e-02, -5.5008e-03, -2.4109e-02,
        -9.3323e-02,  3.9337e-02, -1.3257e-01,  6.6040e-02,  1.0345e-01,
         4.8790e-03,  9.9869e-03,  8.2031e-02,  3.7201e-02, -9.8724e-03,
         2.4994e-02, -3.1982e-02,  7.0190e-02, -6.8726e-02,  2.9343e-02,
         1.8661e-02, -6.0638e-02, -5.1819e-02, -1.6162e-01,  4.4281e-02,
         1.5369e-01, -9.4910e-02,  9.4299e-02, -1.1713e-01, -4.5013e-02,
         1.2684e-03, -9.4238e-02,  3.1891e-02,  7.9224e-02,  1.0712e-01,
        -1.0077e-01, -6.2103e-02, -1.7151e-01, -6.7200e-02, -5.7434e-02,
        -2.2675e-02,  9.2346e-02,  5.3528e-02,  2.5488e-01,  1.0547e-01,
        -1.0858e-01,  9.5154e-02, -5.4962e-02, -2.7496e-02,  1.3953e-01,
        -8.9417e-02,  1.3831e-01,  4.3373e-03, -1.5393e-01,  6.3965e-02,
        -8.7341e-02,  6.3416e-02,  9.7656e-03,  8.4534e-02,  5.7159e-02,
         5.2643e-02, -1.0048e-02, -6.5063e-02, -7.7148e-02,  4.5441e-02,
         5.5542e-02,  8.6548e-02, -1.5320e-02,  1.1981e-01, -1.4771e-01,
         1.6211e-01, -7.9468e-02,  1.2244e-01,  1.5820e-01, -3.2837e-02,
        -2.5768e-03, -1.9928e-02,  4.4159e-02,  5.2856e-02, -2.1469e-02,
         1.0712e-01,  1.8814e-02, -9.7961e-02,  2.9053e-02, -1.1011e-01,
        -1.9385e-01, -3.9368e-02, -4.3640e-02,  3.9398e-02, -1.0559e-01,
        -6.7017e-02,  8.7738e-03, -3.5492e-02, -3.8330e-02, -5.3680e-02,
        -1.5076e-02,  8.4412e-02,  7.7087e-02,  6.2744e-02, -5.3070e-02,
        -5.8441e-02, -3.5278e-02,  5.4504e-02, -1.1798e-01, -1.6525e-02,
        -9.9182e-04, -7.4387e-03, -1.1066e-01,  3.3417e-03, -1.0590e-01,
         4.3182e-02, -2.4166e-03,  4.6570e-02, -1.0034e-01, -4.9774e-02,
         3.1769e-02,  1.1334e-01,  4.0009e-02, -6.3354e-02, -7.5722e-03,
         8.5510e-02, -3.2776e-02,  1.1755e-01, -9.2010e-03,  1.2805e-01,
        -1.4795e-01, -1.5430e-01, -2.1826e-01, -5.0354e-02,  1.7059e-02,
         3.0945e-02, -5.2063e-02,  5.2216e-02,  9.0942e-02, -1.3374e-02,
        -8.5632e-02,  4.3762e-02, -2.2217e-01,  1.0394e-01,  4.2486e-04,
         1.7505e-01,  5.0873e-02,  1.6638e-01, -5.1727e-02, -7.5256e-02,
        -8.6548e-02,  1.9739e-01, -1.2927e-01,  6.9641e-02, -1.2195e-01,
        -5.2948e-02, -2.4414e-02, -2.2888e-02, -7.1411e-02, -4.0466e-02,
        -5.7037e-02,  7.0862e-02,  1.2915e-01,  1.8463e-02, -3.5024e-04,
         3.9917e-02,  3.3691e-02,  1.3723e-03,  4.5593e-02,  4.8920e-02,
        -2.8305e-02,  2.0782e-02,  6.0425e-03,  3.8574e-02, -8.7280e-02,
         1.1749e-01, -1.3477e-01,  3.9795e-02, -1.2457e-01, -3.0167e-02,
        -5.2124e-02,  5.2216e-02, -1.5955e-01, -5.8716e-02, -9.1553e-02,
         1.3159e-01, -5.2521e-02,  2.4536e-02, -1.9409e-01,  2.7661e-01,
        -5.0659e-02,  4.7577e-02, -1.2688e-02,  9.2773e-02, -1.1279e-01,
         4.5410e-02,  1.1993e-02, -2.2659e-02, -1.3696e-01,  6.9275e-02,
        -9.6069e-02, -8.7097e-02, -5.0842e-02, -3.1338e-03,  5.2124e-02,
         9.8450e-02, -1.2537e-01, -7.5867e-02, -7.9346e-02, -5.2734e-02,
        -7.1533e-02,  8.1299e-02, -1.6516e-01,  3.1052e-02,  6.2073e-02,
        -2.9114e-02, -1.2854e-01, -1.9089e-02, -5.0568e-02,  1.7822e-01,
        -5.7312e-02,  5.5603e-02,  1.4197e-01,  3.9764e-02, -1.6699e-01,
         1.0490e-03, -3.7262e-02,  3.0899e-02, -7.0190e-02,  3.7567e-02,
        -4.9683e-02,  9.1492e-02,  6.2256e-03,  1.2152e-01,  1.0620e-01,
         9.8083e-02, -9.7168e-02, -8.9600e-02,  1.2891e-01,  8.7463e-02,
         1.9971e-01, -1.5991e-02, -1.4807e-01,  3.2532e-02, -1.3660e-01],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([1.0039, 1.1758, 0.9917, 1.0615, 1.0625, 0.8721, 0.9580, 0.9658, 0.9897,
        1.0234, 0.8438, 0.8750, 0.9883, 1.0273, 0.9922, 1.0557, 0.9531, 0.9478,
        0.9102, 1.0146, 0.9673, 0.9556, 0.9746, 0.9146, 1.0107, 0.9194, 0.9902,
        0.9888, 1.0693, 0.9624, 0.8960, 0.8726, 1.0146, 0.9463, 0.9395, 0.9556,
        1.1123, 0.9199, 0.8721, 0.9907, 0.9868, 0.9629, 0.9385, 1.0098, 1.0449,
        0.9985, 1.0342, 0.8853, 1.0068, 0.9253, 0.9937, 1.0332, 0.9741, 0.9600,
        0.8286, 1.1631, 0.9561, 0.9189, 0.9575, 1.1055, 0.9746, 1.0234, 1.0205,
        1.1543, 1.0293, 1.0625, 0.8018, 0.8730, 0.9243, 1.0195, 1.0674, 1.1348,
        1.0820, 1.1143, 0.9839, 0.8613, 1.0352, 1.0410, 0.9448, 1.1064, 1.0762,
        0.9956, 1.0557, 1.0957, 1.1152, 1.0469, 0.9956, 1.0527, 1.0723, 0.8057,
        1.0996, 1.0518, 0.9233, 0.9053, 0.9434, 1.0303, 0.9756, 1.1416, 1.1084,
        0.9077, 0.9116, 1.0166, 1.0293, 1.0078, 0.9966, 0.8779, 1.1494, 0.7124,
        1.0596, 0.9805, 1.0430, 1.0088, 1.0908, 0.9077, 0.8452, 0.9165, 0.9985,
        1.1260, 1.0176, 1.0205, 1.0811, 1.0293, 1.0391, 0.7051, 0.9849, 1.1035,
        1.1045, 1.0420, 1.0801, 0.9375, 0.9468, 0.8047, 1.0742, 0.9727, 0.8179,
        0.9722, 0.9844, 0.9692, 1.0742, 0.9946, 1.0635, 1.0840, 1.0547, 0.9746,
        1.0342, 1.0000, 1.0244, 0.8252, 1.0449, 0.9819, 0.8677, 1.0088, 0.9517,
        0.7783, 1.1240, 0.9941, 0.8647, 0.8618, 0.9590, 0.9619, 0.9888, 0.9912,
        0.9956, 1.0508, 0.9756, 0.9971, 0.9531, 0.9507, 1.0156, 1.0391, 1.0947,
        0.9194, 1.0938, 1.0264, 0.9482, 1.0400, 0.9990, 0.7734, 1.0234, 1.0166,
        1.0576, 1.0996, 0.9365, 1.0996, 1.0566, 0.9424, 0.9604, 0.9595, 0.9565,
        0.9736, 0.9775, 0.9995, 0.9370, 1.0312, 1.0967, 0.9292, 1.0674, 0.8862,
        1.0781, 0.9990, 0.9653, 1.0010, 0.7993, 0.9790, 1.0078, 0.9614, 1.0381,
        0.9595, 0.9590, 1.1006, 0.9937, 0.8945, 0.9282, 1.0723, 0.9893, 1.0684,
        1.0586, 0.8779, 0.9492, 0.8442, 0.9971, 1.0176, 0.8296, 1.0088, 0.9199,
        0.9668, 0.8931, 0.9868, 1.0557, 0.9438, 1.0625, 0.9951, 0.8887, 0.9663,
        1.0332, 0.9619, 0.9121, 0.7651, 1.0693, 0.9756, 1.0361, 0.9136, 1.1064,
        0.9927, 1.0293, 1.0811, 0.8999, 1.0186, 1.0205, 0.9497, 1.0537, 0.9771,
        0.9995, 1.0430, 0.9922, 1.0410, 0.9556, 1.0098, 1.0918, 1.0039, 0.9697,
        1.0420, 1.0713, 0.9263, 0.7993, 0.9067, 0.9722, 1.0205, 1.0264, 1.0264,
        1.0918, 1.0869, 1.0098, 0.9839, 0.9697, 1.0176, 0.9292, 0.9810, 1.1240,
        1.0547, 0.9712, 0.9512, 1.0566, 0.9585, 1.0293, 1.0127, 0.9131, 1.0400,
        1.0439, 1.1143, 1.0205, 1.1689, 0.9878, 0.9214, 1.1055, 0.9316, 1.1045,
        0.7485, 1.1133, 0.9482, 0.9102, 0.9414, 1.0273, 1.0322, 1.0283, 0.8452,
        1.0420, 1.0420, 1.0664, 1.0098, 0.9443, 1.0010, 1.0430, 0.7832, 0.9561,
        0.7881, 1.0605, 1.0205, 0.9482, 0.8667], device='cuda:0',
       dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([-2.3636e-02, -5.0354e-02, -6.7749e-02, -2.2263e-02, -4.3274e-02,
         1.2672e-02, -7.6172e-02, -3.5156e-02, -7.7759e-02,  1.4296e-03,
        -1.1316e-01,  5.2429e-02, -7.3776e-03, -3.6316e-02,  1.5495e-02,
         2.2984e-04, -5.5878e-02, -6.2012e-02, -8.5388e-02, -3.4637e-02,
         1.5228e-02,  3.4729e-02,  2.5589e-02, -5.2704e-02,  1.3168e-02,
        -1.1391e-02, -3.2776e-02, -3.4302e-02, -4.6570e-02, -4.8904e-03,
        -1.0168e-01, -8.3496e-02, -4.3640e-03,  1.4297e-02, -4.9103e-02,
        -5.2124e-02,  5.5432e-06, -5.2307e-02, -9.1370e-02, -2.2232e-02,
         5.9052e-02, -1.4748e-02, -8.8440e-02, -6.6833e-02, -7.1533e-02,
        -1.0891e-03, -1.6846e-02,  4.9774e-02, -5.5206e-02, -8.6853e-02,
        -5.0934e-02, -8.0627e-02, -5.5664e-02, -6.8848e-02, -1.3257e-01,
        -3.0251e-03, -3.0533e-02,  3.7994e-02,  3.3386e-02, -2.6413e-02,
        -2.5223e-02, -8.0750e-02, -3.4485e-02, -2.6840e-02, -5.8411e-02,
         1.6602e-02, -1.5125e-01, -9.0576e-02,  1.5778e-02, -9.3201e-02,
        -7.7698e-02, -5.4352e-02, -2.6642e-02, -4.3152e-02, -6.2164e-02,
        -1.2463e-01, -9.3445e-02, -6.3965e-02, -1.0321e-01, -5.1483e-02,
        -1.3342e-01, -7.4097e-02, -1.0065e-01, -7.7148e-02, -3.9886e-02,
        -8.4595e-02, -1.2671e-01, -2.1347e-02, -4.9652e-02, -1.1993e-01,
        -4.4006e-02, -6.7139e-02, -1.0382e-01,  3.6407e-02, -4.8615e-02,
        -7.4280e-02,  2.5146e-02, -8.8745e-02, -6.0577e-02, -7.7148e-02,
        -9.0942e-02, -1.0931e-01, -7.2327e-02, -5.3482e-03, -9.5459e-02,
        -1.3586e-01, -3.2745e-02, -1.6028e-01,  1.5961e-02, -1.2646e-01,
        -2.6245e-02, -3.2196e-02, -7.2670e-03, -1.2018e-01, -1.1206e-01,
         5.8868e-02, -9.2102e-02, -5.9479e-02, -3.9154e-02, -2.0355e-02,
        -6.2622e-02, -5.1910e-02, -4.7119e-02, -1.2830e-01, -1.1279e-01,
        -7.7820e-02, -1.0719e-02, -9.9060e-02, -4.5868e-02, -1.1633e-01,
        -7.5569e-03, -1.2549e-01, -3.6713e-02, -1.1487e-01, -7.5562e-02,
        -1.3840e-02, -7.1472e-02, -1.2866e-01, -4.5868e-02, -1.1066e-01,
        -5.3955e-02, -1.0565e-01, -5.9662e-03, -2.7893e-02, -3.0807e-02,
        -6.0516e-02, -3.1281e-02, -1.3977e-01, -6.2447e-03, -3.2379e-02,
        -1.3098e-01, -8.3313e-02, -8.9233e-02, -1.2659e-01, -4.3854e-02,
        -8.9539e-02,  5.3467e-02, -1.3037e-01, -5.1697e-02, -4.6295e-02,
        -3.0502e-02, -1.1731e-01,  5.1178e-02, -9.6802e-02,  1.4435e-02,
        -6.3232e-02, -8.1299e-02, -9.9670e-02, -8.6670e-03, -5.4199e-02,
        -6.4802e-04, -3.3436e-03, -2.1317e-02, -7.4341e-02,  1.2291e-02,
        -3.0792e-02, -4.6234e-03, -9.8755e-02, -5.4657e-02, -8.2321e-03,
        -3.1708e-02, -8.8379e-02, -1.0815e-01, -9.3689e-02, -7.0618e-02,
        -1.2375e-02,  4.3457e-02, -1.1078e-01, -9.2773e-02, -3.1471e-03,
        -8.6609e-02, -6.3660e-02, -1.1517e-01, -3.9551e-02, -2.1011e-02,
        -1.1612e-02, -5.9296e-02, -1.1273e-01,  7.2060e-03, -4.7943e-02,
        -7.5256e-02, -1.2561e-01, -9.1125e-02, -6.8787e-02, -6.8848e-02,
        -1.3962e-02, -4.6936e-02,  3.8940e-02, -6.6406e-02, -1.4636e-01,
        -5.5939e-02,  2.3117e-02,  4.8401e-02, -1.1041e-01, -6.0005e-03,
        -4.2877e-02, -1.2550e-02,  4.5410e-02, -8.7585e-02, -1.1859e-01,
        -6.4148e-02, -1.0498e-01, -1.2695e-01, -7.3547e-02,  6.7322e-02,
        -8.0719e-03, -1.1359e-01, -6.4880e-02, -2.5085e-02, -1.2794e-02,
        -3.6591e-02, -1.0052e-01, -5.6519e-02, -8.8806e-02, -3.1097e-02,
        -8.9600e-02, -2.5986e-02, -1.5796e-01, -5.8685e-02, -9.1125e-02,
        -4.2389e-02,  1.8753e-02, -2.9404e-02, -4.7394e-02, -7.8613e-02,
        -1.0602e-01, -6.9275e-02, -3.7109e-02,  2.8610e-03, -7.4036e-02,
        -6.0089e-02, -4.3549e-02,  2.3499e-02, -8.2458e-02,  1.4305e-03,
        -6.0272e-02, -1.6541e-02, -3.8391e-02,  4.9934e-03, -3.5706e-02,
        -9.3384e-02, -5.5695e-02, -3.1891e-02,  3.5156e-02, -1.2201e-01,
        -1.3440e-01, -4.6448e-02, -7.9529e-02, -4.3274e-02, -5.6152e-02,
        -4.9316e-02, -6.6589e-02, -2.2949e-02, -1.9211e-02,  1.7868e-02,
        -6.3110e-02,  3.3081e-02, -7.5623e-02, -1.4816e-02, -1.1841e-01,
        -8.5999e-02, -3.4821e-02, -1.9043e-02, -1.0818e-02,  3.7933e-02,
        -1.5778e-02, -7.6538e-02, -5.1147e-02, -3.7140e-02, -1.1072e-01,
        -6.5674e-02, -5.2521e-02,  7.0953e-03,  1.4542e-02, -4.1870e-02,
         1.8082e-02, -9.0866e-03, -1.4771e-01, -4.5502e-02,  7.6818e-04,
        -7.4951e-02, -1.6129e-02, -1.2520e-02, -8.1970e-02, -3.6713e-02,
        -1.0773e-01,  3.5019e-03, -9.6252e-02, -9.0485e-03, -7.7332e-02,
        -5.6030e-02, -8.2825e-02, -7.6538e-02, -1.2000e-01, -4.2786e-02,
        -1.5002e-01, -5.9937e-02, -5.1117e-02, -4.3915e-02,  4.2938e-02],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[-0.0248, -0.0568,  0.0259,  ..., -0.0324,  0.0728,  0.0098],
        [ 0.1018, -0.0172, -0.0248,  ...,  0.0050, -0.0131, -0.0018],
        [-0.0023,  0.0363, -0.0675,  ..., -0.0084, -0.0029, -0.0542],
        ...,
        [-0.0456, -0.1153,  0.0255,  ...,  0.0198, -0.0728,  0.0004],
        [ 0.1246,  0.0825, -0.0224,  ..., -0.0204, -0.0192, -0.0622],
        [-0.0693, -0.0018, -0.0046,  ..., -0.0034, -0.0283, -0.0039]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[-0.0536, -0.1003, -0.0659,  ..., -0.0367, -0.0605,  0.0036],
        [-0.0212, -0.0936, -0.0124,  ...,  0.0967,  0.0177, -0.0039],
        [ 0.0515,  0.0003,  0.0479,  ..., -0.0088, -0.0749, -0.0342],
        ...,
        [-0.0076, -0.0388,  0.0171,  ...,  0.0409, -0.0174, -0.0182],
        [ 0.0396,  0.0082, -0.0188,  ..., -0.1265,  0.0236,  0.0184],
        [-0.0776,  0.0261, -0.0366,  ...,  0.0320, -0.0297, -0.0479]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[ 0.0124,  0.0310,  0.0384,  ...,  0.0419,  0.0075, -0.0308],
        [-0.0158, -0.0036,  0.0053,  ...,  0.0620,  0.0284, -0.0005],
        [-0.0183,  0.0171,  0.0116,  ...,  0.0206, -0.0061, -0.0179],
        ...,
        [-0.0751,  0.0199,  0.0280,  ..., -0.0122, -0.0641, -0.0449],
        [ 0.0200,  0.0221, -0.0201,  ...,  0.0208,  0.0519, -0.0511],
        [-0.0116,  0.0620, -0.0573,  ..., -0.0046,  0.0534,  0.0295]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[-0.0516,  0.1008,  0.0310,  ..., -0.0111,  0.0353,  0.0437],
        [-0.0218, -0.0090,  0.0412,  ...,  0.0057, -0.0275,  0.0390],
        [ 0.1136,  0.0725,  0.0289,  ..., -0.0034,  0.0588,  0.0896],
        ...,
        [-0.0118,  0.0286,  0.0118,  ..., -0.0410, -0.0340,  0.0456],
        [ 0.0234, -0.0159,  0.0136,  ...,  0.1179, -0.0558,  0.0578],
        [-0.0132,  0.0324,  0.0048,  ..., -0.0117,  0.0892,  0.0058]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([-1.0544e-02,  3.0518e-02, -5.5237e-03,  3.6835e-02,  9.5596e-03,
         4.7546e-02, -5.5725e-02, -1.7288e-02,  2.1133e-02, -3.4637e-02,
        -6.0196e-03,  5.1514e-02,  6.8054e-03,  2.6245e-02, -3.5095e-02,
         3.1403e-02,  1.0895e-02,  3.5828e-02,  2.2934e-02,  3.0548e-02,
         3.6888e-03,  2.3605e-02,  3.2959e-02, -1.1816e-03, -3.0014e-02,
         2.9083e-02,  1.1833e-02,  2.3544e-02,  1.6159e-02, -1.7033e-03,
         3.6682e-02, -4.6844e-02, -3.3641e-04, -1.9424e-02, -2.8076e-02,
         2.9388e-02,  6.4575e-02,  3.7415e-02,  2.5726e-02, -3.8330e-02,
         5.5603e-02, -4.2725e-03, -3.3051e-02,  3.3844e-02, -3.3081e-02,
         9.8114e-03,  1.0544e-02,  1.9394e-02, -1.0239e-02,  1.2169e-02,
        -1.8234e-02, -2.1000e-03, -5.6519e-02, -1.1253e-02,  4.9400e-03,
        -1.2230e-02,  8.4381e-03,  5.1025e-02,  1.4214e-02, -4.0558e-02,
         1.8051e-02,  1.4732e-02, -2.0645e-02,  1.7441e-02, -2.3346e-02,
        -9.9182e-03, -6.9351e-03, -1.1276e-02, -1.8473e-03, -2.2339e-02,
         1.5747e-02, -2.1469e-02, -4.1901e-02,  9.7351e-03, -5.0934e-02,
         9.8343e-03,  1.2245e-02,  4.7073e-03, -5.2551e-02,  2.0615e-02,
        -4.4983e-02,  3.2318e-02, -3.8086e-02,  3.9764e-02, -1.9165e-02,
        -4.0222e-02, -1.1154e-02,  4.9927e-02,  4.1779e-02,  2.8763e-02,
         2.7466e-02,  3.7201e-02,  1.2703e-03,  5.0140e-02,  1.6495e-02,
         2.2049e-03,  3.5217e-02, -7.3967e-03,  1.1187e-03, -2.4261e-02,
         2.5177e-02,  9.5596e-03, -2.9739e-02,  6.7520e-03, -3.3356e-02,
        -3.7842e-03,  3.1891e-02, -8.9417e-02, -5.5134e-05, -1.2634e-02,
         2.2125e-02, -3.6530e-02, -1.2718e-02, -2.1545e-02, -1.2726e-02,
        -4.3106e-03,  5.6076e-03,  1.6693e-02,  2.5650e-02,  3.4637e-02,
        -1.2970e-02, -1.7517e-02,  4.1008e-03, -3.9520e-02, -3.7880e-03,
         3.1403e-02,  9.4299e-03, -3.2501e-02,  1.4229e-02, -1.7977e-04,
        -3.7109e-02,  8.0261e-03, -1.1551e-02, -3.9368e-02, -5.0110e-02,
         2.8290e-02, -1.3382e-02, -5.5573e-02, -1.2070e-02,  7.9285e-02,
        -2.4506e-02, -2.5131e-02,  3.9551e-02,  8.4229e-03,  1.3649e-02,
        -1.0811e-02,  5.0812e-02, -1.8646e-02, -3.8727e-02, -3.1189e-02,
         6.3904e-02,  5.5908e-02, -1.2924e-02, -4.1931e-02, -2.4979e-02,
        -3.0472e-02,  3.4393e-02, -1.7822e-02,  3.2745e-02,  1.8417e-02,
         4.9988e-02, -2.8381e-02, -8.6899e-03, -9.5749e-03,  1.9806e-02,
        -7.2449e-02, -1.5930e-02,  5.4131e-03,  6.1378e-03, -1.6907e-02,
        -2.4246e-02,  1.7548e-02, -1.6495e-02, -2.8473e-02, -1.2993e-02,
         5.8556e-03,  5.6793e-02,  7.0381e-03,  1.2527e-02,  4.8187e-02,
        -1.0223e-02,  1.0590e-02, -4.6600e-02,  1.9073e-02, -1.8814e-02,
         1.8616e-02,  4.2175e-02,  1.2070e-02, -3.3630e-02, -4.0527e-02,
        -4.2877e-02, -5.9433e-03, -1.0437e-02,  2.2079e-02,  5.0087e-03,
         4.2480e-02,  3.1071e-03, -2.8473e-02, -2.1164e-02, -8.0643e-03,
        -2.1515e-03, -2.2842e-02,  1.0834e-03,  1.6525e-02, -5.3070e-02,
        -2.1042e-02,  1.7944e-02,  1.2192e-02, -1.7653e-03, -2.3605e-02,
        -1.5198e-02,  4.0436e-02,  4.3884e-02, -2.3022e-03,  1.1177e-02,
        -1.3939e-02, -1.8387e-02, -3.7292e-02,  3.4698e-02, -9.4116e-02,
         8.1421e-02,  7.2861e-04, -3.6449e-03, -2.7588e-02, -1.6312e-02,
         7.3120e-02,  4.6959e-03,  1.9989e-02,  5.3070e-02, -5.2765e-02,
         2.0523e-02, -4.7852e-02, -4.1321e-02, -1.4793e-02,  1.1780e-02,
        -2.8629e-03,  1.4259e-02, -1.6373e-02, -1.5060e-02,  9.6893e-03,
        -1.5190e-02,  5.2521e-02, -8.0643e-03,  3.2135e-02, -5.2795e-02,
        -4.9057e-03,  2.6550e-02, -4.2847e-02, -8.5068e-03,  1.2634e-02,
        -2.6566e-02, -5.4718e-02,  8.4457e-03, -5.5328e-02,  2.5284e-02,
         5.6885e-02,  1.6953e-02, -4.9011e-02,  2.1011e-02, -1.5732e-02,
         3.3051e-02,  4.9744e-02, -4.8462e-02, -2.0218e-02,  7.0152e-03,
        -9.3567e-02, -2.9892e-02,  4.8485e-03,  2.3010e-02, -4.6051e-02,
         2.0813e-02,  1.9241e-02,  1.9669e-02,  1.5099e-02,  1.0277e-02,
        -3.1372e-02,  2.2873e-02, -1.3710e-02, -3.5248e-02, -4.8309e-02,
        -3.4027e-02,  6.4941e-02,  4.1504e-02,  2.8095e-03,  1.5688e-03,
        -1.6083e-02, -5.0140e-02, -5.8014e-02, -2.4857e-02,  4.2114e-02,
        -2.2079e-02,  3.2776e-02,  2.1378e-02,  2.3254e-02,  2.0920e-02,
         5.5176e-02,  2.0508e-02, -6.0425e-02, -1.2123e-02, -5.4741e-03,
        -2.3376e-02,  4.5959e-02,  4.4891e-02, -1.6830e-02,  2.0126e-02,
         3.3646e-03, -1.1658e-02,  5.0354e-03,  2.5742e-02,  1.0089e-01,
         1.6638e-01,  9.6970e-03, -2.7679e-02,  1.0101e-02,  3.0945e-02,
         3.9337e-02,  1.6724e-02, -9.0027e-03, -2.5360e-02,  5.0049e-02],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([1.1182, 1.4746, 0.9673, 1.0508, 1.0791, 1.0186, 0.9844, 1.0449, 1.1133,
        1.0996, 0.9331, 1.0361, 1.1191, 1.0928, 1.0889, 1.1611, 0.9834, 1.0762,
        0.9736, 1.1367, 1.0889, 1.1191, 1.2051, 1.0547, 1.0098, 1.0361, 0.9512,
        1.0205, 1.0938, 1.0996, 0.9097, 1.0635, 1.0234, 0.9165, 1.0518, 1.1064,
        1.1895, 0.9497, 0.8896, 1.1523, 1.1221, 0.9561, 1.0430, 0.9331, 1.1045,
        0.9995, 1.1133, 1.0967, 1.0850, 0.9780, 1.1338, 1.0293, 0.9937, 0.9375,
        1.0303, 1.1182, 0.9678, 1.1836, 1.0811, 0.9961, 1.0635, 1.0928, 1.1289,
        1.2109, 1.1484, 1.1221, 0.8125, 0.9727, 1.0059, 1.1113, 1.0518, 0.9951,
        0.9526, 1.1104, 1.0576, 1.0645, 1.1240, 1.1445, 1.0039, 1.0410, 1.0811,
        1.0156, 0.9673, 1.2227, 1.1670, 1.0957, 1.0615, 1.1064, 0.9897, 0.8970,
        1.1152, 1.0859, 0.8037, 1.1357, 0.9263, 0.9893, 1.1104, 1.0859, 1.0977,
        1.0615, 1.0703, 0.9932, 1.1035, 1.0283, 1.0938, 1.0938, 1.0752, 1.0996,
        1.0410, 1.0420, 1.0273, 1.0898, 1.1211, 1.0830, 1.1064, 1.1152, 1.0645,
        0.9819, 1.0703, 0.9863, 1.0723, 1.0674, 1.0371, 0.8320, 0.9761, 1.0088,
        1.1709, 0.9976, 1.0713, 1.0801, 0.9990, 0.9795, 1.2441, 1.0840, 1.0508,
        1.0859, 1.0635, 1.0283, 1.2656, 0.7729, 1.0771, 1.1416, 1.0947, 1.1113,
        1.1475, 1.0215, 1.1289, 1.0391, 1.0830, 1.0371, 0.8203, 0.9341, 1.1387,
        1.1133, 1.1943, 0.9961, 1.0078, 0.9419, 1.0352, 1.1084, 1.0146, 1.0488,
        1.0664, 1.0244, 1.1182, 1.0293, 1.0947, 1.0449, 1.1592, 1.0859, 1.2080,
        1.0000, 1.1279, 1.0635, 0.9946, 1.1064, 0.9893, 1.1123, 1.0439, 1.0156,
        0.9663, 1.0693, 1.0332, 1.1104, 1.1055, 1.0459, 1.1504, 1.0996, 1.0752,
        0.9956, 1.0244, 1.0596, 1.0527, 1.0742, 1.1270, 0.9917, 1.0674, 0.9966,
        1.1299, 1.0488, 1.1094, 1.1787, 0.8120, 1.0615, 1.1592, 1.0225, 1.0938,
        1.0498, 1.0723, 1.0986, 0.9204, 1.1406, 1.0117, 1.0029, 1.0420, 1.1064,
        1.0654, 1.0459, 1.0596, 0.9932, 0.9062, 1.0928, 0.8364, 1.0264, 1.1523,
        1.0479, 0.8540, 0.9966, 1.1035, 0.9795, 1.1055, 0.9624, 1.0713, 0.9429,
        1.1270, 1.0977, 1.0566, 0.8672, 1.1953, 1.0615, 1.0449, 1.0332, 1.1729,
        1.0508, 1.1074, 1.0801, 1.0107, 1.0605, 1.0420, 1.0508, 1.1162, 0.9536,
        1.1318, 1.0195, 1.0381, 1.0820, 1.0723, 1.0312, 1.0830, 0.9985, 1.0459,
        1.1035, 1.0361, 0.9741, 0.8853, 0.9048, 1.1406, 1.0605, 1.0029, 1.0117,
        1.0137, 1.1992, 1.1094, 1.0977, 1.0410, 1.0732, 1.0488, 1.0664, 1.0557,
        1.0723, 1.1406, 1.1055, 1.0967, 1.0723, 1.1709, 1.0459, 1.0684, 1.0947,
        1.0654, 0.9688, 1.0605, 1.0967, 1.0498, 1.0186, 1.0674, 1.0264, 1.2246,
        0.9565, 1.1025, 1.0596, 0.9727, 0.9761, 1.1104, 1.0195, 1.0518, 0.9482,
        1.1592, 1.0840, 1.2129, 0.8799, 0.7896, 0.9282, 1.0625, 0.7842, 1.0234,
        0.8691, 1.1738, 0.9785, 1.0039, 1.0117], device='cuda:0',
       dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([-6.5369e-02, -4.8065e-02, -7.9163e-02, -4.9622e-02, -3.6194e-02,
        -1.3550e-02, -6.7261e-02,  3.2067e-05, -3.2501e-02, -2.1515e-02,
        -8.1055e-02,  1.7576e-03, -4.7150e-02, -1.1467e-02, -1.0628e-02,
        -2.9922e-02, -7.7820e-02, -5.0629e-02, -4.3579e-02, -9.9945e-03,
        -3.7567e-02, -2.9190e-02, -5.9784e-02, -3.5065e-02, -1.7868e-02,
        -8.8272e-03, -8.8318e-02, -5.2094e-02, -3.0457e-02, -3.2166e-02,
        -1.0370e-01, -4.6906e-02,  3.6163e-02,  2.6688e-02, -3.8513e-02,
        -5.0415e-02, -3.7323e-02, -6.6223e-02, -7.8857e-02, -2.2873e-02,
        -3.1708e-02, -2.8656e-02, -1.1696e-02, -4.7394e-02, -4.0985e-02,
        -7.3128e-03, -1.5015e-02, -3.5370e-02, -2.1469e-02, -2.9953e-02,
        -3.0548e-02, -7.6416e-02, -6.5918e-02, -7.7026e-02, -8.9600e-02,
        -3.6896e-02, -3.0807e-02, -3.0106e-02, -4.9561e-02,  2.1439e-02,
        -6.2195e-02, -3.3783e-02, -4.0314e-02, -1.9028e-02, -9.4299e-02,
        -3.7708e-03, -1.0071e-01, -9.1492e-02, -1.2184e-02, -2.6154e-02,
        -2.0477e-02, -6.3660e-02, -1.3580e-02, -7.2693e-02, -4.5197e-02,
        -7.4951e-02, -5.4413e-02, -7.3547e-02, -1.8250e-02, -5.9357e-03,
        -4.2389e-02, -1.0468e-01, -4.7974e-02, -7.6477e-02, -6.6895e-02,
        -7.5806e-02, -9.0942e-02, -4.4006e-02, -8.0078e-02, -1.1005e-01,
        -5.8624e-02, -4.8065e-02, -1.1066e-01, -3.3661e-02, -7.3730e-02,
        -1.5961e-02,  1.0956e-02, -6.3416e-02, -1.5160e-02, -4.0649e-02,
        -4.4434e-02, -8.2336e-02, -4.7424e-02, -3.9154e-02, -4.5471e-02,
        -1.0278e-01, -4.2969e-02, -8.6365e-02, -2.4536e-02, -7.0068e-02,
        -6.2012e-02, -5.5634e-02, -1.6571e-02, -7.9895e-02, -9.9792e-02,
        -5.2277e-02, -6.3477e-02, -7.6065e-03, -3.1860e-02, -2.0676e-02,
        -1.5778e-02, -6.0303e-02, -7.8857e-02, -9.8755e-02, -9.0515e-02,
        -4.6692e-02, -4.6997e-02, -2.7054e-02, -9.4360e-02, -8.6792e-02,
         2.1896e-02, -9.9731e-02, -2.2308e-02, -1.1475e-02, -4.1077e-02,
        -4.7546e-02, -3.0991e-02, -8.8379e-02, -3.8208e-02, -1.1279e-01,
        -4.4464e-02, -7.3914e-02, -2.9373e-02, -5.4932e-02, -5.2521e-02,
        -1.0022e-01, -1.9424e-02, -1.0486e-01, -2.8809e-02, -4.7699e-02,
        -1.1517e-01, -1.0968e-01, -4.8859e-02, -6.6223e-02, -5.6244e-02,
        -3.1082e-02, -1.7593e-02, -9.7778e-02, -3.3813e-02, -4.9316e-02,
        -4.0710e-02, -3.1525e-02, -8.8959e-03, -7.7148e-02, -3.4618e-03,
        -1.4832e-02, -4.1351e-03, -5.6305e-02, -1.1301e-04, -5.7800e-02,
        -1.5396e-02, -2.5314e-02, -4.2175e-02, -5.2460e-02,  9.3155e-03,
        -5.7159e-02, -2.8503e-02, -8.7769e-02, -1.9699e-02, -3.7537e-02,
         3.7048e-02, -5.2032e-02, -4.2511e-02, -9.0454e-02, -2.0416e-02,
        -5.1514e-02, -3.4454e-02, -9.7717e-02, -7.0007e-02, -2.6443e-02,
        -1.0414e-02, -3.8147e-02, -5.6030e-02, -9.4238e-02,  2.3232e-03,
        -1.7563e-02, -4.5044e-02, -4.7211e-02, -1.4229e-02, -3.0701e-02,
        -3.5675e-02, -7.1045e-02, -7.2021e-02, -5.5603e-02, -4.0070e-02,
        -3.0258e-02, -2.5040e-02, -3.8025e-02, -7.0381e-03, -6.6956e-02,
        -3.5278e-02, -5.6396e-02, -5.7495e-02, -8.8074e-02, -2.8839e-02,
        -6.1523e-02,  2.9343e-02, -9.5596e-03, -5.8929e-02, -3.1586e-02,
        -7.1106e-02, -8.7402e-02, -9.5825e-02, -3.5950e-02, -1.2688e-02,
        -3.7109e-02, -1.3208e-01, -3.0792e-02, -4.1428e-03, -8.2169e-03,
        -1.6541e-02, -5.4901e-02,  1.0576e-03, -1.2030e-01, -2.3987e-02,
        -9.4055e-02, -1.0643e-02, -7.7637e-02, -2.0828e-02, -4.4983e-02,
        -4.1382e-02, -5.3253e-02, -2.5604e-02, -1.1383e-01, -2.2385e-02,
        -6.9153e-02, -5.0995e-02, -3.0487e-02, -1.0803e-02, -2.6932e-02,
        -3.6896e-02, -1.2445e-03,  8.3542e-03, -4.2206e-02, -3.1006e-02,
        -5.8350e-02, -1.5717e-02, -2.5208e-02,  7.0724e-03, -5.9052e-02,
        -3.4058e-02, -8.0994e-02, -1.7563e-02,  5.9052e-03, -9.1553e-02,
         5.8842e-04, -1.4542e-02, -9.2346e-02, -5.1544e-02, -3.7506e-02,
        -7.5867e-02, -7.2144e-02, -4.0955e-02, -8.2458e-02, -3.5065e-02,
        -7.7332e-02, -1.6129e-02, -4.1138e-02, -3.6259e-03, -8.6731e-02,
        -5.7281e-02, -8.8501e-02, -3.2990e-02, -4.7272e-02, -1.9974e-02,
        -4.1901e-02, -3.2288e-02, -4.2938e-02, -4.5319e-02, -1.0242e-01,
        -6.5369e-02, -9.3079e-02, -1.4763e-02, -2.7039e-02, -7.1533e-02,
        -3.0502e-02, -3.3112e-02, -1.1108e-01, -3.8879e-02, -5.3436e-02,
        -4.4708e-02, -1.2497e-02, -7.1960e-02, -4.8279e-02, -3.5583e-02,
        -1.0754e-01, -1.2131e-02, -5.8380e-02, -1.9974e-02, -1.0834e-01,
        -1.1157e-01, -2.8259e-02,  3.0556e-03, -7.9224e-02, -4.0863e-02,
        -9.9792e-02, -4.0924e-02, -1.9104e-02, -4.8737e-02, -3.8483e-02],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[ 0.0338,  0.0051,  0.1206,  ..., -0.0131, -0.1234, -0.0073],
        [ 0.0643,  0.0482, -0.0036,  ...,  0.0853,  0.0645,  0.0167],
        [ 0.0537,  0.0127,  0.0462,  ...,  0.1176, -0.0355, -0.0351],
        ...,
        [ 0.0353, -0.0073, -0.0322,  ...,  0.0831, -0.0374,  0.0306],
        [-0.0782, -0.0403, -0.0195,  ..., -0.0392,  0.0125,  0.0509],
        [ 0.0750, -0.0640, -0.0237,  ..., -0.0213,  0.0848,  0.0388]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[ 0.0307,  0.0961,  0.0242,  ..., -0.0726, -0.0002, -0.0292],
        [ 0.0078,  0.0270,  0.0393,  ..., -0.0118, -0.0475,  0.0358],
        [-0.0526, -0.0443, -0.0246,  ...,  0.0435,  0.0327, -0.0267],
        ...,
        [-0.0443, -0.0361, -0.0460,  ...,  0.0891,  0.0150, -0.0243],
        [ 0.0232,  0.0017, -0.0209,  ...,  0.0123,  0.0283, -0.0126],
        [-0.0870, -0.0623,  0.0920,  ...,  0.0928, -0.1284, -0.0049]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[ 0.0214,  0.0078, -0.0004,  ..., -0.0209, -0.1156,  0.0209],
        [-0.0060, -0.0229, -0.0131,  ...,  0.0258, -0.0286, -0.0221],
        [-0.0022, -0.0052, -0.0340,  ..., -0.0441, -0.0448, -0.0613],
        ...,
        [ 0.0380,  0.0528, -0.0008,  ...,  0.0297, -0.0327,  0.0256],
        [ 0.0499, -0.0126, -0.0529,  ...,  0.0409,  0.0100, -0.0706],
        [ 0.0133,  0.0521, -0.0507,  ...,  0.0254, -0.0554, -0.0192]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[-0.0156, -0.0223,  0.0238,  ..., -0.0510, -0.0120,  0.0523],
        [-0.0183, -0.0574, -0.0885,  ...,  0.0389, -0.0421, -0.0729],
        [ 0.0087,  0.0559, -0.0447,  ...,  0.0583, -0.0354,  0.0404],
        ...,
        [ 0.0197, -0.0379,  0.0199,  ...,  0.0124, -0.0211, -0.0557],
        [ 0.0788,  0.0695, -0.0064,  ...,  0.0163, -0.0174, -0.0106],
        [ 0.0008,  0.0043,  0.0458,  ...,  0.0319,  0.0948, -0.0054]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([ 4.4403e-02,  2.9388e-02, -7.4692e-03, -2.5513e-02, -3.8605e-02,
         3.0045e-02, -3.8757e-02, -2.2980e-02,  2.9053e-02,  1.0704e-02,
        -2.3972e-02,  2.7252e-02, -1.0048e-02,  2.8717e-02,  9.8801e-03,
        -4.1687e-02, -9.6436e-03, -3.5461e-02, -4.0924e-02,  8.4839e-03,
        -3.6194e-02, -1.6281e-02,  3.2288e-02,  3.1616e-02, -7.0038e-03,
        -1.8219e-02, -4.8126e-02,  4.6295e-02,  4.3526e-03,  1.0612e-02,
        -1.8921e-02, -1.4809e-02, -1.9669e-02,  2.7878e-02, -3.2623e-02,
        -3.4058e-02,  1.8341e-02, -2.0721e-02, -1.0878e-04, -4.6631e-02,
        -1.2161e-02, -3.2867e-02, -2.1286e-02,  8.4839e-03,  1.6403e-02,
        -5.1758e-02, -2.9022e-02,  2.2491e-02,  2.2980e-02,  3.6979e-04,
         8.0872e-04,  1.1551e-02,  2.4643e-02,  2.9037e-02,  2.8076e-03,
        -5.8136e-02,  3.0716e-02,  5.1453e-02, -3.8727e-02,  4.6356e-02,
         9.9850e-04,  2.9850e-03,  1.0574e-02,  4.6997e-02,  3.5675e-02,
        -6.6147e-03, -3.0106e-02, -2.7542e-02, -6.5851e-04, -7.4951e-02,
        -4.5380e-02, -3.2978e-03,  2.5574e-02,  2.2995e-02,  3.3813e-02,
        -1.8600e-02, -1.4824e-02,  1.4908e-02, -2.9678e-02,  1.3802e-02,
        -9.0103e-03, -2.4887e-02, -1.3992e-02,  1.3130e-02,  2.7451e-02,
         9.9182e-03,  3.2135e-02, -1.4954e-02, -3.0075e-02, -3.3386e-02,
         1.2703e-02,  3.3661e-02, -9.6970e-03, -1.4145e-02, -5.5695e-03,
         5.0262e-02,  2.6337e-02, -3.9749e-03, -3.2593e-02,  6.4125e-03,
         5.2795e-03, -1.2001e-02,  3.0014e-02,  2.9327e-02, -1.0788e-02,
         4.7577e-02,  2.6672e-02,  3.3752e-02, -2.0462e-02,  1.4755e-02,
        -2.2736e-02,  4.5563e-02,  2.6443e-02, -4.6387e-03, -3.3966e-02,
         4.4250e-02,  4.2725e-02,  9.5558e-04, -1.4450e-02,  2.0828e-02,
        -1.3084e-02, -1.1993e-02,  9.3412e-04, -5.6671e-02,  3.4122e-03,
         5.2338e-02, -2.7222e-02,  2.9419e-02, -2.9938e-02, -5.9753e-02,
        -8.1970e-02,  4.1504e-02, -1.9958e-02, -5.2185e-02,  8.9569e-03,
         1.4153e-02,  3.3855e-03,  4.9469e-02, -4.3884e-02,  5.1086e-02,
         1.7853e-02, -5.8985e-04, -3.2806e-02, -1.5625e-02,  9.4528e-03,
         8.8806e-03,  1.7776e-02, -5.1737e-04,  2.6169e-02,  4.5288e-02,
         1.8845e-02,  3.9215e-02,  3.3813e-02, -3.7823e-03, -9.0942e-03,
         3.3936e-02,  2.3499e-02, -6.6757e-03, -4.1504e-02,  4.2908e-02,
        -1.3573e-02,  1.4183e-02, -2.2003e-02,  3.6804e-02,  1.4679e-02,
        -1.7273e-02, -7.6065e-03,  3.4618e-03,  2.3041e-02, -7.7820e-04,
         1.6022e-02, -3.2532e-02, -6.6162e-02, -4.7058e-02, -6.8176e-02,
         1.3397e-02, -2.0218e-02, -1.4572e-02,  2.9312e-02,  4.5532e-02,
        -2.2217e-02,  5.8929e-02, -5.6244e-02,  3.6102e-02, -4.0833e-02,
         3.4943e-02, -6.8741e-03, -6.2027e-03, -3.5736e-02, -2.8748e-02,
        -2.6276e-02,  4.3869e-03, -6.2981e-03,  3.2410e-02,  2.0981e-02,
         2.0096e-02,  2.2385e-02, -1.2268e-02, -7.0686e-03, -6.1846e-04,
        -3.4218e-03,  1.2184e-02,  3.4363e-02,  4.2297e-02,  3.1342e-02,
         6.2683e-02,  1.5221e-02, -1.5587e-02,  3.7323e-02, -2.6199e-02,
        -8.4829e-04,  4.3427e-02, -4.4708e-02,  1.9867e-02,  1.0735e-02,
         3.1586e-02,  3.7262e-02, -1.9875e-03,  1.7700e-02, -1.7456e-02,
        -1.6296e-02,  5.8502e-02, -5.0140e-02, -7.1716e-03,  4.0710e-02,
         3.2501e-02, -8.4534e-02, -3.0365e-02, -2.0523e-02,  9.1324e-03,
        -2.5635e-02,  3.3234e-02, -4.3297e-03,  4.5898e-02, -3.5492e-02,
        -3.6011e-02, -2.8336e-02,  9.1400e-03,  3.0563e-02,  8.3389e-03,
         3.2593e-02, -8.9493e-03, -9.8896e-04,  1.0246e-02, -3.3813e-02,
         7.3730e-02,  7.9041e-03, -5.8670e-03,  3.2776e-02,  1.3901e-02,
         3.4580e-03,  7.1487e-03,  3.1052e-02,  3.3905e-02, -1.0292e-02,
         1.5511e-02, -4.1656e-03,  7.8201e-03,  3.2867e-02,  6.5918e-02,
         3.0685e-02,  3.2654e-02, -3.5797e-02, -2.7359e-02, -7.2083e-02,
         8.9188e-03, -2.8427e-02, -2.5543e-02, -2.2156e-02, -5.9509e-02,
         4.7836e-03, -3.1769e-02, -3.0304e-02,  5.7434e-02, -4.4861e-02,
         7.9193e-03,  2.4399e-02,  1.3977e-02, -4.4525e-02, -2.1698e-02,
        -2.2831e-03,  1.1971e-02, -4.2084e-02,  4.1870e-02,  2.1881e-02,
        -8.6060e-03,  2.7191e-02,  2.9022e-02, -6.6711e-02, -3.5675e-02,
        -5.6854e-02,  1.5335e-02, -3.4698e-02, -2.3605e-02,  1.9531e-03,
         8.2111e-04, -8.8501e-04, -2.4307e-02,  1.3786e-02, -8.8959e-03,
         1.4221e-02, -1.1536e-02, -2.6550e-02,  5.1178e-02, -2.8198e-02,
        -5.1849e-02, -5.2673e-02,  1.6083e-02,  4.4006e-02,  7.0923e-02,
         1.2891e-01,  1.1721e-03,  5.0592e-04,  5.1086e-02, -5.2612e-02,
         6.6162e-02, -4.3793e-02, -1.1230e-02,  1.6556e-02,  1.0864e-02],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([1.1846, 1.1602, 1.0654, 1.1562, 1.0332, 1.1338, 1.1172, 1.1758, 1.1836,
        1.0859, 1.1660, 1.1436, 1.1348, 1.1260, 1.1123, 1.1367, 1.1064, 1.1230,
        1.1426, 1.1230, 1.2285, 1.1562, 1.1797, 1.2129, 1.0791, 1.1953, 1.0869,
        1.2012, 1.1807, 1.1748, 1.0586, 1.2676, 1.0996, 1.1475, 1.2119, 1.1650,
        1.1162, 0.9858, 0.9443, 1.1436, 1.1338, 1.0967, 1.0713, 1.0811, 1.2734,
        1.1416, 1.2510, 1.2705, 1.2471, 1.1201, 1.1729, 1.0674, 1.0859, 0.9751,
        1.1611, 1.1016, 1.0723, 1.1680, 1.0498, 1.2002, 1.1709, 1.1465, 1.1797,
        1.1836, 1.2139, 1.1514, 0.9048, 1.2871, 1.1377, 1.0146, 1.0342, 1.0986,
        1.0879, 1.1201, 1.0938, 1.1660, 1.1777, 1.1572, 1.1172, 1.1230, 1.1611,
        1.1572, 1.1807, 1.2988, 1.1211, 1.2051, 1.0859, 1.1006, 1.1592, 1.0762,
        1.2129, 1.2129, 0.9473, 1.2158, 1.2012, 1.2021, 1.1631, 1.1543, 1.2002,
        1.1162, 1.1357, 1.1553, 1.1299, 1.1445, 1.1475, 1.1895, 1.1064, 1.2051,
        1.1494, 1.1553, 1.1279, 1.1709, 1.1973, 1.1250, 1.1748, 1.2510, 1.1123,
        1.1172, 1.1436, 1.2041, 1.1855, 1.1748, 1.1445, 0.9692, 1.1260, 1.1377,
        1.1377, 1.0967, 1.1348, 1.1445, 0.8589, 1.1699, 1.1670, 0.9375, 1.1650,
        1.1943, 1.2471, 1.1436, 1.2754, 0.7930, 1.1562, 1.1572, 1.1387, 1.1748,
        1.1230, 1.1777, 1.1982, 1.1660, 1.1641, 1.1543, 0.9937, 1.0439, 1.2852,
        1.0830, 1.1514, 1.0244, 1.1621, 1.0879, 1.1562, 1.0703, 1.0967, 1.0010,
        1.2314, 1.1162, 1.1406, 1.0391, 1.1758, 1.1553, 1.1162, 1.0117, 1.1299,
        1.1211, 1.0967, 1.1924, 1.0781, 1.1426, 0.9556, 1.2002, 1.1738, 1.1533,
        1.0068, 1.2207, 1.1328, 1.2021, 1.1426, 1.2148, 1.1865, 1.3359, 1.1670,
        1.0225, 1.1172, 1.2139, 1.0391, 1.2227, 1.0498, 1.1250, 1.0469, 1.1309,
        1.1602, 1.1758, 1.2041, 1.1289, 0.8428, 1.2021, 1.2041, 1.0889, 1.2021,
        1.1152, 1.0791, 1.0908, 1.1299, 1.1133, 1.1445, 1.0928, 1.0811, 1.0439,
        1.1650, 1.1416, 0.9087, 1.1436, 0.8794, 1.1445, 0.9316, 1.1357, 1.0811,
        1.2041, 1.0527, 1.1592, 1.0996, 1.2002, 1.1719, 1.1719, 1.1162, 1.0059,
        1.0674, 1.2227, 1.2715, 1.0996, 1.1016, 1.3135, 1.2520, 1.0713, 1.1279,
        1.1982, 1.2158, 1.2568, 1.2383, 1.0986, 1.1982, 1.2510, 1.2627, 0.9868,
        1.0625, 1.1553, 1.0459, 1.1963, 1.2666, 1.2158, 1.1123, 1.0830, 1.1426,
        1.1729, 1.1338, 1.1133, 1.1289, 1.0225, 1.2051, 1.2070, 1.1221, 0.9517,
        1.0127, 1.1611, 1.1582, 1.1660, 1.1865, 1.1719, 1.1465, 1.0703, 1.2139,
        1.2070, 1.2080, 1.2607, 1.1797, 1.1484, 1.1777, 1.1406, 1.0459, 1.1543,
        1.1445, 1.0674, 1.1787, 1.1289, 1.1787, 1.0322, 1.0537, 1.1455, 1.2139,
        1.1377, 1.0420, 1.2041, 1.0732, 1.1963, 1.1807, 1.1924, 1.1367, 1.1211,
        1.2090, 1.1836, 1.1885, 0.8784, 0.7720, 1.1123, 1.1367, 0.8403, 1.1133,
        0.9556, 1.2432, 1.0576, 1.2295, 1.1465], device='cuda:0',
       dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([ 0.1074,  0.0997,  0.0171,  0.0703, -0.0656, -0.1510, -0.0518,  0.1482,
         0.0834, -0.0218, -0.0491, -0.2181,  0.1306,  0.0120, -0.1688,  0.0082,
         0.1412,  0.1117, -0.1741,  0.0939, -0.0671, -0.0083, -0.0426,  0.1576,
        -0.0614,  0.1158, -0.0123,  0.1081,  0.1246,  0.1085,  0.0231, -0.1866,
        -0.1018, -0.1593, -0.1055,  0.0528,  0.1527,  0.0315, -0.0460, -0.0859,
        -0.1169, -0.0760,  0.0242,  0.0424,  0.1234, -0.0417,  0.0372, -0.0013,
        -0.1655,  0.0250,  0.1537,  0.1851, -0.1188, -0.0443,  0.0383, -0.0630,
         0.0157,  0.0638,  0.0370, -0.0328,  0.0084, -0.0759,  0.0928,  0.0842,
         0.0546, -0.0248, -0.0181,  0.1511, -0.0470, -0.0451, -0.0880,  0.0610,
         0.1174,  0.2332,  0.0573,  0.2744, -0.1073, -0.1017, -0.0736, -0.0094,
         0.0005,  0.0961,  0.0105, -0.0207,  0.0714,  0.0729,  0.1437, -0.0175,
        -0.0496,  0.1064,  0.1796,  0.1482,  0.0020,  0.0397, -0.1153, -0.1801,
         0.0085,  0.0598, -0.0903, -0.0376,  0.1598, -0.1490,  0.0012, -0.0831,
        -0.0346,  0.1006, -0.0340,  0.1768, -0.0641, -0.0143,  0.1375,  0.1522,
         0.0736,  0.0732, -0.0642,  0.0747,  0.0385, -0.0866,  0.1381,  0.0177,
        -0.1053,  0.0381,  0.1641,  0.0057,  0.0590, -0.0806, -0.1621,  0.0099,
        -0.1205,  0.0033,  0.0504,  0.0986,  0.0225,  0.0499, -0.0350,  0.0780,
        -0.1731, -0.0201, -0.1349, -0.0562,  0.2112,  0.0434, -0.0338, -0.0077,
        -0.0204,  0.1906,  0.0853,  0.0499, -0.0221,  0.0668, -0.0329, -0.0267,
        -0.0306, -0.0331, -0.0290, -0.0149, -0.2228, -0.0521, -0.0763,  0.0706,
         0.0845,  0.0119,  0.1296,  0.1826, -0.2947, -0.0055,  0.1219,  0.1797,
         0.0542, -0.0127, -0.0027, -0.0190, -0.0956, -0.1011, -0.0811,  0.1686,
         0.1063,  0.1471, -0.1483, -0.0764, -0.0667,  0.0261,  0.0944,  0.2085,
        -0.0934,  0.1428,  0.2305, -0.2335, -0.0217,  0.0602, -0.0956, -0.0042,
         0.1100,  0.1497, -0.0059, -0.0826,  0.0660, -0.0093, -0.0696, -0.0114,
        -0.0683,  0.0826, -0.0980,  0.1946,  0.1281, -0.0484, -0.1917, -0.1137,
         0.0241,  0.0764,  0.0148,  0.0060, -0.0750,  0.0524,  0.1135, -0.0541,
         0.0851, -0.1770,  0.0185, -0.1130, -0.0840,  0.0482, -0.2419,  0.1277,
         0.0359,  0.2009, -0.0566,  0.0599, -0.2427, -0.0446, -0.0902,  0.0243,
        -0.0637, -0.0385, -0.0371,  0.0288, -0.0378,  0.0465,  0.0740, -0.0623,
         0.1295, -0.1438,  0.0287,  0.1810, -0.0888,  0.1609,  0.1805,  0.0004,
         0.0849,  0.0743,  0.0016,  0.0518, -0.0876, -0.0847,  0.0564,  0.1714,
         0.0295, -0.0662, -0.0173, -0.0076,  0.0594,  0.0795, -0.0978, -0.0428,
         0.2314, -0.0556, -0.1179,  0.1935, -0.0856, -0.0264,  0.0282, -0.1132,
         0.2357,  0.0973, -0.0715,  0.1141,  0.0178,  0.0352, -0.0502, -0.1220,
        -0.1914,  0.1312,  0.0432, -0.0899, -0.0852,  0.0280,  0.0438,  0.0428,
        -0.0816, -0.1642, -0.1221,  0.0626, -0.1936, -0.0379,  0.0662,  0.0569,
         0.2186,  0.0768,  0.0204,  0.0665,  0.2261, -0.1201,  0.0733, -0.0295,
        -0.0565,  0.0106, -0.0490,  0.1880,  0.1255, -0.0026, -0.0113, -0.0349,
        -0.0950, -0.0228, -0.1765,  0.0298,  0.1104, -0.0629, -0.1134,  0.0472],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[ 0.0437,  0.0258,  0.0609,  ...,  0.0015, -0.0683, -0.0005],
        [ 0.0148,  0.0054, -0.0046,  ..., -0.0964,  0.0721, -0.0995],
        [ 0.0108, -0.0202, -0.0679,  ..., -0.0750, -0.0297,  0.0416],
        ...,
        [ 0.0127, -0.0178, -0.0176,  ...,  0.0078,  0.0089,  0.0321],
        [-0.0776, -0.0289,  0.0122,  ...,  0.0525, -0.0338,  0.0147],
        [-0.0044, -0.0082, -0.0019,  ...,  0.0134, -0.0289,  0.0029]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([-0.0323,  0.0471, -0.0050,  ...,  0.0622, -0.0654, -0.0304],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[-1.1116e-02,  1.6937e-02, -9.4712e-05,  ...,  1.2024e-02,
         -5.1788e-02,  1.8204e-02],
        [ 3.0991e-02,  5.9692e-02,  4.1342e-04,  ...,  3.1677e-02,
          4.7180e-02, -2.0432e-02],
        [ 2.1225e-02, -3.7018e-02,  1.5167e-02,  ..., -2.0599e-02,
          1.6077e-01, -9.4376e-03],
        ...,
        [ 5.9906e-02,  4.8027e-03, -8.0933e-02,  ..., -3.1921e-02,
         -6.4880e-02,  4.0314e-02],
        [-5.2109e-03, -2.4948e-02,  5.4230e-02,  ...,  8.7769e-02,
          1.4465e-01, -1.6602e-02],
        [-6.7711e-03, -1.5289e-02,  2.7871e-04,  ...,  4.2152e-03,
         -2.2842e-02,  1.2388e-03]], device='cuda:0', dtype=torch.float16,
       requires_grad=True) is not None
Gradient for Parameter containing:
tensor([ 0.0100,  0.0213,  0.0067,  0.0723,  0.0188, -0.0234, -0.0295,  0.0139,
         0.0352,  0.0185, -0.0093,  0.0018,  0.0359,  0.0009,  0.0378, -0.0191,
         0.0808, -0.0110,  0.0157,  0.0170, -0.0475, -0.0159, -0.0287,  0.0269,
        -0.0392,  0.0854, -0.0364,  0.0464,  0.0390,  0.0157,  0.0658, -0.0416,
        -0.0617, -0.0288,  0.0143,  0.0297,  0.0481,  0.0371, -0.0106,  0.0223,
        -0.0779, -0.0124, -0.0606,  0.0164,  0.0269, -0.0614, -0.0461, -0.0396,
         0.0223,  0.0313,  0.0780,  0.0747, -0.0818,  0.0328,  0.0513,  0.0382,
         0.0662,  0.0315, -0.0189, -0.0049, -0.0626, -0.0399,  0.0062, -0.0125,
        -0.0266, -0.0744,  0.0442, -0.0482,  0.0108, -0.0579, -0.0057, -0.0300,
         0.0469,  0.0528, -0.0852, -0.0100,  0.0151,  0.0116,  0.0260, -0.0865,
        -0.1199,  0.0299, -0.0611, -0.0085,  0.0696,  0.0397,  0.0367, -0.0160,
        -0.0575,  0.0196,  0.0782, -0.0015,  0.0334,  0.0528, -0.0217,  0.0427,
        -0.0200, -0.0260, -0.0340, -0.0638,  0.0224, -0.0489,  0.0100, -0.0319,
        -0.0095,  0.0499, -0.0095,  0.0290, -0.0963,  0.0436, -0.0123,  0.0246,
        -0.0060,  0.0379,  0.0468, -0.0079,  0.0445, -0.0523,  0.0194,  0.0136,
        -0.0029, -0.0124, -0.0188,  0.0167, -0.0016, -0.0437, -0.0148, -0.0276,
         0.0175,  0.0644, -0.0566,  0.0479, -0.0845, -0.0162,  0.0200, -0.0165,
         0.0359, -0.0436, -0.0441,  0.0333, -0.0432,  0.0426, -0.0439, -0.0072,
        -0.0160,  0.0839,  0.0077, -0.0499, -0.0388, -0.0272,  0.0499, -0.0304,
         0.0407,  0.0558, -0.0453,  0.0754, -0.0666, -0.0151, -0.0150, -0.0320,
        -0.0090, -0.0281, -0.0402,  0.0855, -0.0803, -0.0331,  0.0459,  0.0263,
         0.0499, -0.0361,  0.0209, -0.0485,  0.0263, -0.0539, -0.0648,  0.0589,
         0.0157,  0.0520, -0.0202, -0.0681, -0.0234,  0.0306,  0.0536,  0.0242,
        -0.0174, -0.0194,  0.0447,  0.0512, -0.0054,  0.0661, -0.0081,  0.0394,
         0.0121,  0.0040, -0.0357, -0.0018,  0.0688,  0.0140,  0.0301, -0.0629,
        -0.0656, -0.0296,  0.0168, -0.0368,  0.0388, -0.0543, -0.0251, -0.0184,
         0.0033,  0.0078, -0.0026, -0.0079,  0.0424,  0.0985,  0.0275, -0.1460,
         0.0213, -0.0398,  0.0390, -0.0423, -0.0491, -0.0109,  0.0209,  0.0071,
         0.0322,  0.0294,  0.0533, -0.0091,  0.0157,  0.0274, -0.0949,  0.0208,
        -0.1022, -0.0085, -0.1119, -0.0013, -0.0325,  0.0262, -0.0054, -0.0612,
        -0.0741, -0.0220, -0.0094, -0.0076,  0.0376, -0.0188,  0.0762, -0.0519,
         0.0895,  0.0387,  0.0009, -0.0446,  0.0504, -0.0742,  0.0629,  0.0450,
         0.0278,  0.0235, -0.0011, -0.0239,  0.0248, -0.0260, -0.0651, -0.0351,
         0.0128, -0.0022, -0.0618,  0.0814, -0.0569,  0.0141,  0.0623, -0.0354,
         0.0331, -0.0099,  0.0556, -0.0712, -0.0461,  0.0879,  0.0893,  0.0006,
         0.0348, -0.0275,  0.0226,  0.0168, -0.0854,  0.0059,  0.0061,  0.0421,
         0.0375, -0.0487, -0.0200, -0.0153, -0.0294, -0.1187,  0.0951,  0.0125,
        -0.0189,  0.0203,  0.0179, -0.0141,  0.0444, -0.0071,  0.0878, -0.0323,
         0.0205,  0.0013, -0.0556,  0.0603, -0.0038,  0.0137,  0.0052, -0.0724,
         0.0002,  0.0663, -0.0492,  0.0277,  0.0500,  0.0016, -0.0430, -0.0385],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[-0.0025,  0.0374,  0.0151,  ...,  0.0696,  0.0244,  0.0179],
        [-0.0305, -0.0826,  0.0003,  ...,  0.1033, -0.0349, -0.0616],
        [-0.0031, -0.0215, -0.0185,  ..., -0.0189,  0.0504,  0.0054],
        ...,
        [-0.0132, -0.0632,  0.0365,  ...,  0.0417,  0.0440,  0.0334],
        [-0.0346, -0.0112, -0.0400,  ...,  0.0486,  0.0091,  0.0838],
        [-0.0518, -0.0108,  0.0772,  ...,  0.0074, -0.0273,  0.0362]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([ 4.0169e-03, -1.8097e-02,  4.6783e-02, -1.2350e-03,  6.9092e-02,
        -1.0910e-02,  2.2095e-02,  4.1473e-02,  8.9844e-02,  3.6713e-02,
         3.9398e-02, -3.7811e-02,  5.8319e-02, -2.4612e-02,  4.4937e-03,
        -1.2199e-02,  6.2347e-02,  2.6199e-02,  2.6978e-02,  5.0545e-03,
        -3.9825e-02, -6.6162e-02, -6.3721e-02, -6.4850e-03,  4.1687e-02,
        -9.1553e-03, -2.6398e-02, -4.4403e-02,  2.5665e-02, -5.6702e-02,
        -1.8326e-02,  2.8152e-02,  3.8147e-02,  3.2959e-02,  5.7144e-03,
        -1.0384e-02, -5.8655e-02,  5.8563e-02,  3.7048e-02,  8.4305e-03,
         2.3254e-02,  1.6510e-02, -4.6112e-02, -3.7567e-02,  2.0294e-03,
         2.8870e-02, -3.8643e-03, -1.1047e-02, -1.1978e-02,  8.5297e-03,
        -1.0765e-02, -6.0608e-02, -1.6541e-02, -1.0269e-02,  4.4067e-02,
         1.1406e-02, -3.5553e-02,  4.7989e-03,  3.6001e-05,  1.9703e-03,
        -7.4196e-03,  3.8391e-02, -8.9569e-03,  3.2806e-02, -7.5073e-02,
        -8.3389e-03,  4.2389e-02, -9.4452e-03,  1.5915e-02, -5.0690e-02,
         3.2990e-02, -6.6414e-03, -9.7290e-02,  4.6577e-03, -1.8555e-02,
         5.6091e-02,  1.6800e-02, -4.9500e-02,  5.1819e-02, -2.1454e-02,
        -1.9287e-02, -1.3756e-02,  3.9032e-02, -1.4626e-02,  4.5288e-02,
        -5.6885e-02,  3.3936e-02,  1.0168e-01, -3.1128e-02,  4.6844e-03,
        -4.2847e-02,  1.5778e-02,  5.5237e-03, -3.6926e-02, -4.4342e-02,
        -3.2166e-02,  4.9316e-02, -4.7302e-02, -6.0768e-03,  2.4612e-02,
         2.5803e-02,  2.3224e-02, -2.3071e-02,  9.8724e-03, -4.5662e-03,
         3.3081e-02,  6.8848e-02,  2.7054e-02, -5.4789e-04,  1.3065e-03,
         2.7863e-02,  7.7393e-02,  5.4688e-02, -4.4464e-02, -3.8727e-02,
         2.6367e-02, -1.8875e-02, -1.6556e-02,  3.2471e-02, -1.6998e-02,
         3.7109e-02,  4.8004e-02, -6.2134e-02,  5.7281e-02, -7.7667e-03,
        -2.1133e-02,  4.4670e-03,  4.2648e-03, -3.3539e-02,  4.6753e-02,
         6.7200e-02,  1.5701e-02,  1.6663e-02,  9.1095e-03,  2.0966e-02,
        -2.6810e-02,  4.5746e-02, -3.1708e-02,  5.8014e-02, -3.1830e-02,
        -8.6060e-03,  1.7776e-02,  5.6458e-03,  1.7319e-02, -4.2999e-02,
        -3.6530e-02,  3.5065e-02, -2.5894e-02, -1.1208e-02, -6.2012e-02,
        -9.8648e-03,  4.6234e-02, -1.8097e-02,  1.6449e-02,  9.6664e-03,
         5.6976e-02, -2.9190e-02, -9.7900e-02,  4.4174e-03, -1.4639e-04,
        -2.7649e-02, -2.7222e-02, -1.5396e-02, -5.5298e-02,  2.3895e-02,
         1.4656e-02,  1.0666e-02, -3.0518e-02, -2.5635e-02, -1.6174e-02,
        -1.1444e-02, -7.2998e-02, -3.3661e-02,  3.2288e-02,  1.8219e-02,
        -1.6418e-02, -1.0178e-02,  1.0681e-02, -3.5675e-02,  1.9440e-02,
         3.8223e-03,  9.0332e-03,  3.5187e-02,  1.0201e-02, -1.1848e-02,
         5.8105e-02,  1.8005e-02, -5.8842e-04,  2.0844e-02,  1.6495e-02,
        -2.8038e-04,  3.9215e-02, -5.6854e-02,  1.5404e-02,  1.5747e-02,
        -2.3575e-03,  1.4244e-02,  1.3626e-02, -7.2998e-02,  1.0757e-02,
         4.6906e-02, -1.5251e-02,  2.0111e-02, -2.8061e-02,  2.7130e-02,
        -3.1525e-02, -2.1561e-02,  5.0049e-02,  2.9709e-02, -7.3853e-02,
        -1.3649e-02, -3.0914e-02,  1.6815e-02, -4.2816e-02, -2.7893e-02,
        -6.5613e-02, -1.5472e-02,  7.0251e-02,  1.7105e-02,  1.3512e-02,
        -1.6708e-02, -4.0527e-02,  4.2511e-02,  8.1558e-03, -1.8570e-02,
         1.8082e-02, -2.5055e-02,  1.1093e-02, -3.3203e-02, -5.2948e-02,
        -8.3160e-03,  1.6678e-02, -4.9011e-02,  3.2837e-02,  1.5259e-02,
         4.8401e-02, -3.7628e-02, -9.6893e-03,  3.2593e-02, -3.0045e-02,
         9.0790e-03,  1.0773e-01,  5.7373e-02, -1.2306e-02, -7.5493e-03,
         5.4260e-02,  6.0455e-02,  4.3793e-02, -2.2526e-03, -3.5187e-02,
         7.8821e-04,  8.3389e-03,  2.7145e-02, -3.7903e-02,  5.2582e-02,
        -1.6708e-02,  1.6556e-03, -1.5373e-02, -1.5022e-02, -3.1677e-02,
        -6.4819e-02,  5.4321e-02,  1.9073e-02,  3.0197e-02,  1.5961e-02,
        -5.4836e-04, -1.2215e-02, -3.5610e-03, -1.3084e-02,  2.1240e-02,
         2.2247e-02,  2.1561e-02, -1.7410e-02,  5.8746e-02,  6.3629e-03,
         2.4002e-02, -4.2816e-02, -1.0719e-02,  1.6373e-02, -3.9368e-02,
        -3.3875e-02,  4.2267e-02,  3.0193e-03,  2.8595e-02, -8.3847e-03,
        -2.7328e-02, -1.7075e-02, -1.0612e-02, -4.3915e-02,  2.3911e-02,
         6.4316e-03, -4.8218e-03, -4.9500e-02,  2.7435e-02, -3.6407e-02,
        -1.1269e-02, -4.3549e-02, -5.6219e-04,  1.3000e-02,  9.0332e-02,
         6.1874e-03, -2.5959e-03, -8.1604e-02, -2.1835e-02, -1.5556e-02,
         7.8552e-02,  5.9557e-04,  2.2552e-02, -5.6183e-02,  7.2517e-03,
         5.7068e-03,  2.4017e-02, -1.2619e-02,  2.1393e-02,  9.8648e-03,
        -2.1225e-02,  4.7455e-02, -6.6795e-03, -5.8990e-02,  1.7212e-02],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([0.6992, 0.7124, 0.7358, 0.7378, 0.7266, 0.6875, 0.7324, 0.7109, 0.7466,
        0.6270, 0.5771, 0.6997, 0.6587, 0.7002, 0.7285, 0.7168, 0.6406, 0.7109,
        0.6011, 0.6958, 0.5884, 0.6240, 0.5327, 0.5518, 0.5518, 0.6494, 0.5986,
        0.5957, 0.5889, 0.5264, 0.8018, 0.7744, 0.7896, 0.7935, 0.8174, 0.8223,
        0.8594, 0.7793, 0.7549, 0.9995, 0.8076, 0.7349, 0.7466, 0.8120, 0.8594,
        0.7402, 0.8247, 0.7739, 0.7944, 0.8052, 0.5913, 0.6255, 0.6675, 0.6660,
        0.6777, 0.6382, 0.6133, 0.6162, 0.5952, 0.5483, 0.6074, 0.6665, 0.6230,
        0.6919, 0.6655, 0.6011, 0.6318, 0.7139, 0.6548, 0.7183, 0.7246, 0.7222,
        0.7158, 0.7231, 0.7222, 0.7432, 0.6953, 0.6914, 0.7158, 0.7207, 0.7344,
        0.7329, 0.7246, 0.6792, 0.6631, 0.6763, 0.7080, 0.7378, 0.7163, 0.6494,
        0.7090, 0.6729, 0.7207, 0.5732, 0.6567, 0.6533, 0.6909, 0.6890, 0.6006,
        0.6675, 0.7515, 0.7339, 0.7603, 0.7061, 0.8091, 0.7271, 0.7046, 0.7515,
        0.7329, 0.7905, 0.6621, 0.5786, 0.6499, 0.6631, 0.6519, 0.6885, 0.7236,
        0.7212, 0.6577, 0.7500, 0.6299, 0.6553, 0.6543, 0.6987, 0.6880, 0.6812,
        0.7285, 0.6157, 0.5894, 0.6709, 0.6792, 0.7124, 0.6968, 0.6460, 0.6948,
        0.6172, 0.7090, 0.5874, 0.6562, 0.6836, 0.7329, 0.6997, 0.7686, 0.7803,
        0.7515, 0.7017, 0.8208, 0.7729, 0.7080, 0.7905, 0.6416, 0.7539, 0.7085,
        0.6880, 0.5874, 0.6914, 0.6719, 0.7178, 0.7349, 0.7598, 0.7397, 0.6875,
        0.7720, 0.7017, 0.6978, 0.7534, 0.7900, 0.6602, 0.6885, 0.7153, 0.6460,
        0.5562, 0.6138, 0.7192, 0.6714, 0.5991, 0.6421, 0.6953, 0.6284, 0.5771,
        0.7021, 0.6675, 0.6870, 0.7451, 0.5791, 0.6206, 0.6479, 0.6611, 0.5869,
        0.7373, 0.7949, 0.7085, 0.6792, 0.7080, 0.7153, 0.6743, 0.7871, 0.7471,
        0.7319, 0.6729, 0.7153, 0.6250, 0.6719, 0.7139, 0.6890, 0.7441, 0.7554,
        0.7930, 0.7480, 0.7275, 0.6973, 0.8154, 0.7852, 0.6221, 0.7471, 0.7822,
        0.6099, 0.7305, 0.6533, 0.7695, 0.6455, 0.7334, 0.7065, 0.6670, 0.6582,
        0.6616, 0.7065, 0.7837, 0.7388, 0.7285, 0.8447, 0.7749, 0.7783, 0.7026,
        0.7690, 0.7607, 0.7363, 0.7617, 0.7080, 0.8618, 0.6187, 0.5811, 0.6426,
        0.6343, 0.6270, 0.7227, 0.7310, 0.6279, 0.7017, 0.6943, 0.7407, 0.8257,
        0.7686, 0.7578, 0.7856, 0.7856, 0.7856, 0.6997, 0.7764, 0.7598, 0.6445,
        0.6787, 0.6875, 0.6929, 0.6836, 0.7236, 0.7197, 0.7549, 0.6904, 0.7036,
        0.6055, 0.6748, 0.6289, 0.7378, 0.6948, 0.6338, 0.7095, 0.5962, 0.6450,
        0.6177, 0.7251, 0.7422, 0.7441, 0.7368, 0.6992, 0.7222, 0.7129, 0.7300,
        0.7793, 0.6865, 0.7998, 0.7080, 0.6338, 0.6611, 0.8242, 0.7422, 0.6675,
        0.6582, 0.6016, 0.6631, 0.6157, 0.6455, 0.6558, 0.7275, 0.6113, 0.7480,
        0.7173, 0.6621, 0.6880, 0.7090, 0.6865, 0.7163, 0.6543, 0.7012, 0.7803,
        0.6279, 0.6953, 0.7441, 0.7588, 0.6362], device='cuda:0',
       dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([ 4.4220e-02, -2.6520e-02, -3.7689e-02,  6.9519e-02, -2.8168e-02,
         2.0844e-02, -1.0958e-03,  4.8889e-02, -2.1378e-02, -1.2566e-02,
         4.0802e-02,  3.0426e-02,  3.7170e-02,  5.8533e-02, -1.1664e-01,
        -8.9905e-02, -5.0903e-02,  1.1276e-02, -8.2214e-02,  5.5786e-02,
        -3.3646e-03, -6.1157e-02, -1.2988e-01,  7.7087e-02, -1.1877e-01,
         5.6915e-02, -3.4332e-02,  1.1511e-01,  1.9669e-02,  1.0730e-01,
        -4.2969e-02,  3.1830e-02, -1.1218e-01, -2.8671e-02, -7.5562e-02,
        -8.5388e-02, -2.4124e-02, -3.6865e-02, -4.5380e-02, -3.5400e-02,
        -5.8861e-03, -9.5520e-02, -1.6251e-02, -3.4912e-02,  1.1322e-02,
         2.6810e-02, -1.6479e-02, -2.3087e-02, -4.3243e-02,  2.4307e-02,
         2.5101e-02, -6.0272e-02, -3.0243e-02,  1.6083e-02,  5.6732e-02,
         2.8137e-02, -3.7903e-02,  5.3406e-02,  1.7258e-02,  1.9470e-01,
         1.2398e-02, -1.7554e-01, -3.3398e-03, -5.4932e-02,  4.5380e-02,
         5.9784e-02, -5.2986e-03,  5.0354e-02, -1.4603e-02, -2.0981e-02,
        -2.5482e-02, -4.8218e-02,  4.3983e-03,  1.2428e-02,  4.4403e-02,
        -1.4136e-01, -4.0314e-02,  1.1490e-02,  2.8519e-02, -6.1981e-02,
        -8.0383e-02, -5.5206e-02,  1.8907e-04,  1.6699e-01, -1.9604e-01,
        -1.5442e-01, -4.0497e-02,  8.0017e-02, -3.8574e-02, -6.4758e-02,
        -1.7380e-02, -6.6528e-02, -2.5864e-02, -4.0741e-02, -7.2571e-02,
         7.8796e-02,  2.9480e-02, -2.7863e-02, -9.0637e-03, -3.3722e-02,
        -4.3602e-03, -1.5259e-04, -1.4210e-03, -8.3801e-02, -7.2144e-02,
        -7.1373e-03,  4.1107e-02, -7.8186e-02, -9.7473e-02,  1.6321e-01,
         2.0844e-02,  1.9958e-02, -1.0004e-01, -4.6196e-03, -1.1963e-02,
        -1.7639e-02,  3.3905e-02,  1.9257e-02,  2.0203e-02, -4.0665e-03,
         3.1021e-02, -2.4048e-02, -2.0737e-02,  3.5492e-02,  1.6006e-02,
         3.7994e-02, -5.1880e-02, -4.9103e-02, -2.6520e-02,  4.6906e-02,
         3.6591e-02,  2.1515e-02, -4.5349e-02, -1.8358e-04, -8.9172e-02,
        -5.3284e-02,  4.0283e-02,  1.3318e-01,  7.4524e-02, -5.2826e-02,
        -1.4992e-02, -6.7993e-02, -1.5572e-02, -6.6345e-02,  7.2876e-02,
         1.1542e-01,  2.1988e-02, -2.9739e-02, -2.8992e-02,  2.7374e-02,
        -7.9529e-02,  5.7922e-02,  2.5696e-02, -5.0545e-03, -2.2278e-01,
         3.6255e-02,  4.8248e-02, -1.8921e-02,  3.2272e-03,  3.7048e-02,
        -5.6671e-02, -1.5327e-02, -8.2336e-02, -6.5552e-02,  1.0193e-01,
        -8.3435e-02, -3.8330e-02,  3.1082e-02, -1.5991e-02, -5.1025e-02,
         6.7749e-02,  4.4373e-02,  5.3040e-02,  8.5022e-02,  6.8817e-03,
         1.3962e-02, -1.3904e-01, -6.3721e-02,  1.0059e-01, -8.8440e-02,
         1.2489e-02, -1.1644e-03,  1.2756e-01, -1.2354e-01,  9.0820e-02,
        -3.3081e-02, -1.6553e-01, -1.1902e-02,  1.3330e-01, -2.2278e-02,
         3.1860e-02, -6.6772e-02, -3.6896e-02, -7.1594e-02, -1.2636e-03,
        -3.9215e-02,  5.0140e-02,  1.3908e-02,  7.0862e-02, -1.1310e-01,
         4.7699e-02, -2.1194e-02, -8.9172e-02, -4.4708e-02, -2.9938e-02,
        -7.5455e-03, -2.0889e-02, -1.0826e-02, -1.6449e-02, -6.8970e-02,
         8.7952e-02, -5.0171e-02, -1.0529e-02, -3.8391e-02,  4.2343e-03,
         1.5518e-02, -5.4962e-02,  8.2092e-02,  4.8309e-02, -1.0339e-01,
        -5.6877e-03,  8.6288e-03, -4.6563e-04,  2.4689e-02, -3.4561e-03,
         1.5466e-01,  4.3121e-02, -3.2532e-02, -7.2571e-02,  2.1637e-02,
        -2.6550e-02,  2.1759e-02, -1.0547e-01, -2.0248e-02,  4.4342e-02,
         2.8125e-01, -2.3972e-02, -9.2468e-02, -4.3945e-02,  1.1115e-01,
        -6.6528e-02,  4.4594e-03, -2.4460e-02,  8.5602e-03,  2.9892e-02,
        -1.0345e-02, -6.2988e-02, -6.4209e-02, -2.5665e-02, -4.7302e-02,
        -8.1665e-02,  1.9424e-02,  3.7994e-02, -2.6520e-02,  5.1355e-04,
        -2.1240e-02, -1.1023e-01, -7.5684e-02, -2.1133e-03, -1.8663e-03,
        -6.9031e-02, -4.3579e-02,  2.8351e-02,  6.9641e-02,  8.4076e-03,
         2.6672e-02, -8.4686e-03,  4.5349e-02, -4.9652e-02, -6.8970e-02,
        -4.5929e-02,  1.4709e-02,  8.7585e-03,  9.8648e-03,  1.4023e-02,
        -7.5684e-02,  3.7231e-02, -6.3477e-03,  7.7820e-02, -4.8370e-02,
         1.0571e-01,  7.7553e-03, -1.0208e-02,  5.1849e-02, -6.7749e-02,
         1.8036e-02, -3.8025e-02, -2.4094e-02,  4.2755e-02, -4.7722e-03,
         7.7057e-03, -2.5177e-02, -2.6154e-02,  5.4993e-02,  9.6436e-02,
        -5.3955e-02, -1.8661e-02,  4.6021e-02, -1.1548e-01,  9.0759e-02,
         6.1455e-03,  3.7445e-02,  2.0355e-02,  1.1383e-02, -1.1658e-02,
        -4.0817e-03, -1.5305e-02,  8.0139e-02, -1.0864e-01,  8.9661e-02,
        -1.4214e-02,  5.7640e-03, -1.8158e-02,  6.9702e-02, -3.0869e-02,
        -6.7566e-02,  6.0387e-03,  1.7746e-02,  4.7119e-02,  1.0719e-02],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[ 0.0044, -0.0533,  0.0522,  ..., -0.0114, -0.0439,  0.0186],
        [ 0.0275, -0.0466, -0.0080,  ...,  0.0100,  0.0541, -0.0316],
        [ 0.0046, -0.0155, -0.0511,  ..., -0.0077,  0.0272,  0.0111],
        ...,
        [-0.0344, -0.0504, -0.0797,  ...,  0.0293, -0.0116,  0.0161],
        [ 0.0297, -0.0297, -0.0019,  ..., -0.0238,  0.0317,  0.0151],
        [-0.0129,  0.0025, -0.0517,  ...,  0.0196, -0.0109,  0.0288]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([ 0.0138,  0.0909, -0.0376,  0.0459,  0.0948, -0.0353,  0.0485,  0.0208,
        -0.0238, -0.0076,  0.0185, -0.0319,  0.0380,  0.0594,  0.0199,  0.0792,
        -0.0332,  0.0676, -0.0746,  0.0014, -0.0236, -0.0655,  0.0630,  0.0390,
         0.0634,  0.0138,  0.0151, -0.0403,  0.0049,  0.0660,  0.0096,  0.0098,
         0.0636, -0.0094, -0.0614,  0.0500,  0.0368,  0.0800, -0.0329, -0.0141,
         0.0088,  0.0323, -0.0329, -0.0194, -0.0280,  0.1249, -0.0617,  0.0812,
         0.0323, -0.0060, -0.0015,  0.0145, -0.0232, -0.0317, -0.0567,  0.0022,
         0.0127,  0.0447,  0.0390,  0.0084, -0.0006, -0.0192,  0.0175, -0.0183,
         0.0221,  0.0314,  0.0859, -0.0629,  0.0348, -0.0528,  0.0140, -0.0077,
        -0.0884,  0.0398, -0.0709, -0.0806, -0.0739, -0.0322, -0.1246, -0.0080,
        -0.0997, -0.0376, -0.0605,  0.0382, -0.0475,  0.0650,  0.0610,  0.0392,
         0.0016,  0.0433,  0.0050, -0.0223, -0.0593,  0.0101, -0.0015,  0.1045,
         0.0019,  0.0249,  0.1123, -0.0304, -0.1438,  0.0170,  0.0566, -0.1100,
         0.0076,  0.0502,  0.0500,  0.0669, -0.0267, -0.1062, -0.0709, -0.0533,
        -0.0674, -0.0158,  0.0488, -0.0155, -0.0320, -0.0865, -0.0058, -0.0392,
         0.0002, -0.0657,  0.0518, -0.0477, -0.0920, -0.0126,  0.0399, -0.1381,
         0.0037,  0.0012,  0.0660, -0.0301,  0.0517,  0.0031,  0.0267, -0.0226,
         0.0298,  0.0246,  0.0316, -0.1589, -0.0103,  0.0579, -0.0450,  0.0373,
         0.0129,  0.1124, -0.0084, -0.0430, -0.0051, -0.0584,  0.0317,  0.0887,
         0.1100, -0.0048,  0.0633,  0.0464,  0.0655,  0.0742, -0.0191, -0.0181,
         0.0381, -0.0082,  0.0297, -0.1175, -0.0401, -0.0344, -0.0118, -0.0115,
        -0.0479, -0.1173,  0.0119, -0.1045,  0.0938, -0.0379,  0.0173,  0.0469,
         0.0628, -0.0514,  0.0081,  0.0206,  0.0791,  0.0327,  0.0358, -0.0880,
         0.0748,  0.0720,  0.0014, -0.0778,  0.0504,  0.0061,  0.0321, -0.0776,
         0.0567, -0.0044,  0.0125,  0.0251,  0.0594,  0.0877, -0.0121,  0.0698,
        -0.0925,  0.0258,  0.0495, -0.0850,  0.1473, -0.0965, -0.0476, -0.0066,
         0.0227, -0.0080,  0.0372, -0.0466,  0.1052, -0.0207, -0.0134, -0.0195,
         0.0288,  0.0446,  0.0160,  0.0739,  0.0240,  0.1203,  0.0107,  0.0077,
        -0.0027, -0.0840, -0.0216, -0.0626, -0.0063,  0.0037,  0.1118,  0.0758,
         0.0160,  0.0400, -0.0201, -0.0594,  0.0060, -0.0325,  0.1030, -0.0358,
        -0.0190, -0.0369,  0.0328,  0.0424, -0.0502,  0.0030,  0.0168, -0.0418,
        -0.0591, -0.0435, -0.0034, -0.0155, -0.0311, -0.0523, -0.0944, -0.0988,
        -0.0321,  0.0299,  0.0277, -0.0551, -0.0096,  0.0313,  0.0642,  0.0166,
         0.0059, -0.0125, -0.0643, -0.0180, -0.0231, -0.0989,  0.0173, -0.0689,
         0.0997,  0.0016, -0.0323, -0.0593,  0.0761,  0.1437,  0.0336,  0.0481,
        -0.0308, -0.0029, -0.0104, -0.0063, -0.0439, -0.0564,  0.0166,  0.0144,
         0.0244, -0.0218,  0.0794,  0.0012,  0.0740, -0.1432,  0.0247, -0.0075,
         0.0210,  0.0403,  0.0239, -0.0736, -0.0380, -0.0179,  0.0446, -0.0286,
         0.0219, -0.0510,  0.0234, -0.0594, -0.0437, -0.0538, -0.0282, -0.1047,
         0.0065, -0.1718,  0.0038, -0.1488, -0.0164, -0.0670,  0.0461, -0.0418],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([0.7983, 0.7612, 0.8403, 0.7896, 0.7749, 0.8872, 0.8452, 0.9390, 0.9292,
        1.0039, 0.9336, 0.9492, 0.9121, 0.9146, 0.9810, 0.9702, 0.9512, 0.9126,
        0.9731, 0.9722, 0.9492, 1.0049, 0.8032, 0.9937, 0.9185, 0.8862, 0.9814,
        0.9287, 0.9111, 0.8530, 0.9731, 0.9331, 0.9116, 0.9731, 0.9976, 0.9673,
        0.9663, 0.9478, 0.9565, 0.9609, 0.9028, 0.9146, 0.9482, 1.0107, 1.0215,
        0.8887, 0.9399, 0.9717, 0.9072, 0.8960, 0.8540, 1.0000, 0.9702, 0.9443,
        1.0762, 1.0078, 1.0332, 0.9731, 0.8169, 1.0527, 0.8540, 1.1152, 0.8999,
        1.0127, 0.9399, 1.0303, 0.8267, 1.0879, 1.0459, 1.0137, 0.9585, 0.8789,
        0.9331, 1.0088, 0.9810, 0.8862, 0.9976, 0.9668, 0.9546, 0.9341, 1.0400,
        0.9766, 1.0391, 0.9409, 0.9424, 0.9497, 0.9385, 0.8252, 0.9990, 0.9175,
        0.9976, 0.9321, 1.0703, 0.9404, 0.9590, 0.8286, 1.0498, 0.8223, 0.8516,
        0.9233, 1.0586, 1.0107, 0.9487, 0.9609, 0.9634, 0.9126, 0.8281, 0.9785,
        1.0088, 0.9766, 1.0703, 0.8809, 1.0215, 0.9224, 0.9043, 0.9585, 0.9434,
        0.8994, 0.9561, 0.9766, 1.0742, 0.9453, 0.9946, 0.9971, 1.0439, 0.8774,
        0.9688, 0.9019, 1.0234, 0.9268, 1.0186, 0.9619, 0.8911, 0.9570, 0.9038,
        0.8989, 0.9072, 0.9854, 0.9360, 0.9321, 1.0811, 0.9072, 0.9336, 0.9111,
        0.9780, 0.7812, 0.9082, 0.9824, 1.0273, 1.0273, 0.9429, 1.0244, 0.8379,
        0.9209, 0.9766, 0.8696, 0.8091, 0.7612, 0.9360, 0.8960, 0.8799, 1.0400,
        0.9146, 1.0107, 1.0029, 1.0645, 0.9199, 0.9741, 0.9434, 0.9746, 0.9751,
        0.9951, 0.8213, 1.0020, 0.8662, 1.0020, 0.9902, 0.9517, 0.9824, 0.9438,
        0.9604, 0.9263, 1.0244, 0.9956, 1.0752, 0.8315, 1.0146, 0.9424, 0.9092,
        0.8276, 0.9180, 0.9170, 0.8188, 0.8672, 0.9380, 0.8545, 0.9668, 0.8652,
        0.9893, 0.7690, 0.9175, 0.8779, 1.0264, 0.8813, 0.7905, 0.9893, 0.9487,
        1.0605, 1.0674, 0.9795, 0.9604, 0.9736, 0.8740, 0.9253, 0.9409, 0.9858,
        0.9795, 0.9561, 0.9790, 0.8950, 0.9600, 0.7646, 0.9785, 1.0312, 1.0293,
        0.9326, 0.9233, 0.9248, 0.8555, 0.9253, 0.8833, 0.7515, 0.9663, 1.0244,
        0.9395, 0.9067, 1.0801, 0.9688, 0.8198, 0.9541, 0.9922, 0.9048, 0.9893,
        0.9297, 0.9673, 0.8750, 0.9678, 0.9434, 0.9653, 0.9692, 0.9453, 0.9951,
        0.9478, 0.9399, 0.9429, 0.9048, 0.9419, 0.9580, 0.9663, 0.9116, 0.9414,
        0.8711, 0.9990, 0.9048, 0.9912, 0.9995, 0.9824, 0.9492, 1.0039, 0.9595,
        0.9331, 0.8970, 1.0146, 0.8047, 0.9614, 0.9644, 0.8579, 0.7993, 1.0469,
        0.9233, 0.9048, 0.9917, 1.0078, 0.9614, 0.9961, 0.8965, 1.0107, 0.9814,
        0.9302, 0.9668, 1.0859, 0.8398, 0.9126, 0.9565, 0.9780, 1.0049, 0.9453,
        0.9668, 0.8765, 0.9824, 0.9561, 0.9336, 0.9780, 0.9116, 0.9312, 0.9497,
        0.9590, 0.9321, 1.0244, 0.8892, 0.9775, 0.9487, 0.8569, 0.9468, 1.0498,
        0.8862, 0.9692, 0.8994, 0.9526, 1.0264], device='cuda:0',
       dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([-0.0429, -0.1036,  0.0121, -0.0764, -0.0981, -0.0373, -0.0564, -0.0413,
        -0.0554, -0.0258,  0.0070, -0.0061, -0.0304, -0.0255, -0.0167, -0.0422,
        -0.0348, -0.0252, -0.0195, -0.0368, -0.0124,  0.0199, -0.0897, -0.0205,
        -0.0418, -0.0715, -0.0097, -0.0220, -0.0242, -0.0517, -0.0291, -0.0321,
        -0.0407, -0.0054, -0.0262, -0.0076, -0.0435,  0.0329, -0.0449,  0.0054,
        -0.0467, -0.0488, -0.0033, -0.0205, -0.0116, -0.0630, -0.0055,  0.0051,
        -0.0090, -0.0518,  0.0157, -0.0461, -0.0072, -0.0181, -0.0546, -0.0368,
        -0.0460, -0.0133, -0.0984, -0.0349, -0.0711, -0.0238, -0.0963, -0.0099,
         0.0138, -0.0676, -0.0951, -0.0215, -0.0797, -0.0686, -0.0476, -0.0890,
        -0.0162, -0.0402, -0.0885,  0.0059, -0.0302, -0.0334, -0.0184, -0.0618,
        -0.0310, -0.0299, -0.0408, -0.0526, -0.0652, -0.0273, -0.0662, -0.0992,
        -0.0479, -0.0072, -0.0424, -0.0364, -0.0136, -0.0283, -0.0205, -0.1000,
        -0.0184, -0.1014, -0.0970, -0.0625, -0.0359, -0.0792, -0.0714, -0.0630,
         0.0123, -0.0786, -0.0784, -0.0496, -0.0279, -0.0555, -0.0333, -0.0519,
         0.0036, -0.0104, -0.0710, -0.0321, -0.0221, -0.0103, -0.0157, -0.0561,
        -0.0468, -0.0434, -0.0927, -0.0701, -0.0258,  0.0152, -0.0437, -0.0207,
        -0.0620, -0.0125, -0.0453, -0.0359, -0.0671, -0.0651, -0.0326, -0.0337,
        -0.0701, -0.0545,  0.0007, -0.0186, -0.0159, -0.1218, -0.0786, -0.0839,
         0.0107, -0.0746,  0.0080, -0.0511, -0.0572, -0.0709, -0.0446, -0.1029,
        -0.0743, -0.0153, -0.0421, -0.0817, -0.0757, -0.0997, -0.0400, -0.0048,
         0.0394, -0.0575, -0.0268, -0.1033, -0.0187, -0.0547,  0.0222, -0.0696,
        -0.0639, -0.0596, -0.0540, -0.0525, -0.0747, -0.0331, -0.0706, -0.0693,
        -0.0243, -0.0465, -0.0343, -0.0333, -0.0336,  0.0054, -0.0134, -0.0131,
        -0.0172, -0.1044, -0.0288, -0.0320, -0.0327, -0.0858, -0.0399,  0.0069,
        -0.1141, -0.0787, -0.0778, -0.0841, -0.0310, -0.0729, -0.0094, -0.1246,
         0.0580,  0.0079, -0.0279,  0.0071, -0.0590, -0.0352, -0.0267, -0.0817,
        -0.0202, -0.0444, -0.0434, -0.0718, -0.0677, -0.0039, -0.0377, -0.0831,
        -0.0351, -0.0247, -0.0283, -0.0717, -0.0200, -0.1002, -0.0534, -0.0867,
        -0.0009, -0.0257, -0.0076, -0.0108,  0.0499, -0.0332, -0.0802, -0.0834,
        -0.0250, -0.0876, -0.0071, -0.0229, -0.0238, -0.1075, -0.0454, -0.0244,
        -0.0269, -0.0026, -0.0265, -0.0203, -0.0137, -0.0102, -0.0677, -0.0087,
        -0.0308, -0.0398, -0.0456, -0.1208, -0.0041, -0.0428,  0.0094, -0.0041,
        -0.0241, -0.0679,  0.0260, -0.0123, -0.0082, -0.0731, -0.0378, -0.0130,
        -0.0475, -0.0612, -0.0265, -0.0609, -0.0362, -0.0440, -0.0374, -0.0120,
        -0.0336, -0.1015, -0.0039, -0.0390, -0.0653, -0.0984, -0.0114, -0.0728,
         0.0167, -0.0778,  0.0115, -0.0437, -0.0276, -0.0005, -0.0122, -0.0695,
        -0.0308, -0.0386, -0.0140, -0.1094, -0.0448, -0.0245, -0.0058, -0.0978,
        -0.0502, -0.0787, -0.0773, -0.0553, -0.0224,  0.0101, -0.0829, -0.0087,
         0.0053, -0.0507, -0.0444, -0.0329, -0.0008, -0.0067,  0.0338, -0.0425,
         0.0449, -0.0346, -0.0256, -0.0007, -0.0144, -0.0365, -0.0522, -0.0744],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[-0.0318, -0.0732, -0.0552,  ..., -0.0232,  0.0251, -0.0643],
        [ 0.0640, -0.1555,  0.0945,  ...,  0.1718, -0.0362, -0.0009],
        [-0.1586,  0.0839, -0.1826,  ..., -0.1486, -0.0005, -0.0618],
        ...,
        [-0.0226, -0.0108,  0.0080,  ...,  0.0520, -0.0027, -0.0576],
        [ 0.0369, -0.0548,  0.1022,  ...,  0.0360, -0.0247, -0.0424],
        [ 0.0471,  0.0060,  0.0896,  ..., -0.0178,  0.0142,  0.0656]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[-0.0173,  0.0131,  0.0415,  ..., -0.1022,  0.0385,  0.0640],
        [ 0.0546, -0.0383,  0.0789,  ..., -0.0431,  0.0140,  0.0038],
        [ 0.0371,  0.0776, -0.1350,  ...,  0.0148,  0.0986,  0.0214],
        ...,
        [-0.0106,  0.0575,  0.0010,  ...,  0.0505, -0.0226, -0.0088],
        [ 0.0359,  0.0265,  0.0654,  ...,  0.0800, -0.0953,  0.0048],
        [ 0.0230,  0.0188, -0.0006,  ..., -0.0886,  0.0652,  0.0152]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[-0.0304, -0.0169,  0.0130,  ..., -0.0405,  0.0349, -0.0380],
        [ 0.0094, -0.0175, -0.0110,  ...,  0.0195, -0.0201, -0.0037],
        [ 0.0010,  0.0010,  0.0131,  ...,  0.0744, -0.0353, -0.0264],
        ...,
        [ 0.0046, -0.0457, -0.0163,  ..., -0.0040,  0.0381, -0.0227],
        [ 0.0667,  0.0562,  0.0165,  ...,  0.0541, -0.0258,  0.0254],
        [ 0.0507, -0.0008, -0.0692,  ...,  0.0319, -0.0624, -0.0234]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[-0.0374, -0.0599,  0.0344,  ..., -0.0179,  0.0056,  0.0330],
        [ 0.0096, -0.0312, -0.0136,  ...,  0.0216, -0.0107, -0.0078],
        [-0.0363,  0.0556,  0.0061,  ..., -0.0343, -0.0578, -0.0196],
        ...,
        [-0.0024,  0.0249, -0.1027,  ...,  0.0355, -0.0234, -0.0421],
        [-0.0552, -0.0151, -0.0141,  ..., -0.0168,  0.0144, -0.0095],
        [-0.0690, -0.0177, -0.0212,  ...,  0.0290, -0.0179,  0.0563]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([ 4.0222e-02,  1.6571e-02, -2.5558e-02,  4.7485e-02,  4.0894e-02,
        -2.3651e-02, -6.5186e-02, -8.8043e-03,  2.4918e-02,  4.3945e-02,
         1.3748e-02,  1.6418e-02,  1.3649e-02, -2.5520e-03,  3.9886e-02,
        -1.6296e-02,  2.9694e-02, -4.0344e-02,  2.5436e-02,  2.2240e-03,
         2.6733e-02,  3.8696e-02, -5.6732e-02, -1.8311e-02, -3.7079e-02,
        -1.1757e-02, -2.2049e-02, -3.5461e-02, -1.5343e-02, -5.1788e-02,
        -2.9480e-02,  3.5156e-02,  4.5319e-03, -1.8036e-02,  2.8095e-03,
        -5.6061e-02, -3.9062e-03, -4.6844e-03,  7.4654e-03, -2.6932e-02,
         3.4790e-02,  1.2749e-02, -1.1726e-02, -3.1738e-03,  5.2490e-02,
         3.3817e-03,  5.3833e-02,  4.1992e-02,  2.4033e-02, -4.4037e-02,
        -2.0660e-02, -3.4271e-02, -2.5375e-02, -3.1372e-02,  2.9129e-02,
        -2.3136e-03, -4.0070e-02,  3.9307e-02, -5.0507e-03, -3.3783e-02,
        -4.3304e-02,  4.6082e-02, -5.9021e-02, -6.9847e-03,  4.6692e-02,
         4.1473e-02,  2.7435e-02, -2.2335e-03, -4.6906e-02,  2.0584e-02,
        -7.4425e-03,  3.4561e-03,  3.1830e-02, -2.2324e-02,  1.7395e-02,
         2.9640e-03,  2.1988e-02, -6.2180e-03,  3.3295e-02, -3.5095e-02,
        -3.8483e-02,  4.4434e-02,  4.3304e-02,  4.1962e-03, -4.8248e-02,
         1.1398e-02,  9.7351e-03, -3.4351e-03,  2.2400e-02, -1.6037e-02,
        -3.0090e-02,  3.5339e-02,  5.7373e-03,  2.0676e-02,  2.1164e-02,
         1.4290e-02, -6.1274e-04, -9.1934e-03, -2.1591e-02,  2.4445e-02,
        -5.6267e-03,  3.7354e-02, -2.5955e-02,  2.0966e-02,  4.6021e-02,
        -2.3819e-02, -5.6335e-02, -2.4536e-02,  2.0004e-02, -4.2908e-02,
        -1.3687e-02, -2.2324e-02,  2.3193e-02,  2.6474e-02, -1.7731e-02,
         4.3060e-02, -5.2719e-03, -1.2878e-02,  4.9438e-03,  1.1909e-02,
         8.1482e-03,  1.9806e-02,  1.9836e-02, -5.8136e-02, -5.8250e-03,
         1.2884e-03,  3.8147e-02,  1.6586e-02, -2.7069e-02, -1.4458e-03,
         1.7548e-02, -5.0659e-03, -3.5919e-02, -5.2452e-03,  4.7541e-04,
         2.4429e-02, -4.0833e-02,  1.2779e-02,  3.7018e-02,  5.3101e-03,
         1.3363e-04, -2.6093e-03, -2.1973e-02, -5.2826e-02, -1.0376e-02,
        -6.2927e-02,  8.4457e-03, -2.3727e-02,  1.1574e-02,  4.3060e-02,
        -6.6414e-03,  3.0060e-03, -3.9215e-02, -2.8519e-02, -2.4765e-02,
        -1.8066e-02, -5.3467e-02, -5.2826e-02, -1.4603e-02,  1.2947e-02,
         3.8086e-02,  3.6285e-02, -3.9459e-02,  2.0981e-03,  2.3178e-02,
        -1.6546e-03,  5.1941e-02, -1.0506e-02,  1.3191e-02, -5.8960e-02,
        -1.5076e-02, -9.5749e-03, -4.4006e-02, -1.0193e-02, -2.3178e-02,
         6.5346e-03, -2.2964e-03, -4.2419e-02,  6.9771e-03,  4.0161e-02,
        -9.5069e-05,  2.2964e-03, -1.7815e-03,  7.1045e-02,  6.8474e-03,
         5.4312e-04,  1.9455e-03, -2.1652e-02, -5.1193e-03, -3.3600e-02,
        -1.4744e-03,  1.2962e-02,  3.0090e-02, -4.3823e-02,  6.8054e-03,
         7.2174e-03,  2.3346e-03, -1.2436e-02,  3.0304e-02, -1.0236e-01,
         6.7871e-02,  2.8419e-04, -1.6663e-02,  5.7190e-02, -4.8950e-02,
         2.5864e-02, -4.2542e-02,  4.5532e-02,  2.8610e-02,  4.3976e-02,
         3.3783e-02, -3.2288e-02,  1.0727e-02,  1.0178e-02, -2.7573e-02,
        -4.2267e-02, -1.6508e-03,  4.2389e-02,  1.9592e-02, -4.5837e-02,
        -1.2560e-03,  5.5359e-02,  1.6739e-02, -7.2060e-03,  1.2390e-02,
         1.8433e-02,  8.4305e-03,  5.3940e-03,  5.5847e-03,  1.6037e-02,
         9.8038e-03, -1.2866e-01, -3.3875e-02,  3.5187e-02,  1.4015e-02,
        -8.3084e-03, -3.7689e-02,  3.4668e-02,  4.9629e-03,  5.8228e-02,
        -1.3885e-02, -2.1118e-02,  1.5993e-03, -2.1896e-02, -2.9526e-02,
         5.3284e-02,  3.1555e-02,  1.5114e-02, -4.8218e-02,  2.5848e-02,
        -5.1544e-02,  3.0365e-02,  6.7139e-03,  1.4290e-02,  6.1127e-02,
        -1.2070e-02,  3.6011e-02,  1.7042e-03,  2.2461e-02,  2.9510e-02,
         2.7328e-02, -5.0774e-03, -1.5945e-02, -9.0561e-03,  2.8381e-02,
        -5.5359e-02,  4.6600e-02,  4.7089e-02, -3.7567e-02, -1.1993e-02,
         2.0844e-02, -2.1118e-02,  6.0692e-03, -2.6779e-02, -3.1921e-02,
        -2.7725e-02,  1.7868e-02, -1.4687e-02,  1.6006e-02,  5.0262e-02,
         2.5192e-02, -2.3621e-02,  1.0292e-02, -2.1088e-02,  4.6570e-02,
        -1.4534e-02, -5.3673e-03, -3.8208e-02,  1.6769e-02, -1.2503e-03,
         1.2749e-02, -3.9734e-02,  8.3008e-03, -1.8219e-02, -2.1698e-02,
        -2.5787e-02, -3.4119e-02,  3.4122e-03,  3.7384e-02, -2.4704e-02,
        -4.5502e-02,  9.2407e-02,  9.9426e-02,  4.0100e-02,  6.0577e-02,
         3.8208e-02,  1.6525e-02,  3.1161e-04,  4.1748e-02,  3.6926e-02,
         1.3676e-03, -1.4702e-02,  3.8879e-02, -1.9241e-02, -4.0932e-03,
        -3.8361e-02,  3.1342e-02, -3.1342e-02,  1.9798e-03,  2.4216e-02],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([0.9165, 0.9834, 0.8564, 0.7627, 0.7896, 0.9785, 0.8662, 0.9351, 0.9634,
        0.9141, 0.9531, 0.9497, 0.9380, 0.9219, 0.9980, 0.9087, 1.0371, 0.9556,
        0.9951, 1.0391, 0.9834, 0.9712, 0.9761, 0.9453, 0.9697, 0.9663, 1.0518,
        0.9795, 1.0225, 0.9370, 1.0264, 0.9736, 0.9639, 1.0195, 0.9517, 1.0039,
        1.0850, 1.0850, 0.9512, 0.9253, 0.9478, 1.0273, 0.9717, 0.9893, 1.0898,
        0.9575, 1.0752, 0.8813, 1.0820, 0.9424, 0.9702, 1.0029, 1.0264, 0.9136,
        1.0439, 1.0322, 1.0479, 0.9155, 0.9531, 1.0557, 1.0430, 0.9316, 1.0469,
        0.9819, 1.1318, 0.9712, 0.9102, 1.0254, 1.0879, 1.0088, 0.8696, 1.0459,
        0.9990, 0.9736, 0.9834, 0.9810, 1.0469, 0.9761, 0.9648, 1.0469, 1.0049,
        1.0039, 1.0576, 1.0137, 1.0723, 0.9688, 1.0078, 0.9824, 1.0488, 0.9902,
        0.9482, 1.0273, 1.0068, 0.9854, 0.9146, 0.7666, 1.0439, 0.8218, 1.0576,
        0.9326, 1.0586, 0.9829, 0.9429, 1.0371, 1.0215, 0.8804, 0.9341, 0.9463,
        1.0205, 0.9434, 0.9771, 0.9727, 1.0166, 0.9863, 1.0146, 0.9331, 1.0410,
        1.0791, 1.0049, 0.9976, 1.0977, 1.0156, 0.9893, 0.9502, 1.0156, 0.9580,
        0.9736, 0.9219, 1.0254, 1.0898, 1.0195, 1.0195, 1.0020, 0.9565, 0.9150,
        0.9458, 1.0107, 0.9561, 1.0127, 0.9497, 0.9253, 0.9971, 1.0625, 0.9878,
        1.0381, 0.9751, 0.9370, 0.9683, 0.9526, 0.9902, 0.9604, 0.8711, 0.9507,
        0.8931, 0.9336, 0.8872, 0.9424, 0.8540, 0.9448, 0.9731, 0.9473, 0.9966,
        0.9380, 1.0029, 1.0410, 0.9692, 0.9771, 0.9497, 0.9810, 0.8882, 0.9868,
        1.0273, 0.9741, 1.0156, 1.0332, 1.0459, 1.0117, 0.9941, 0.9761, 0.9712,
        0.9834, 1.0156, 1.0039, 0.8501, 0.9712, 0.9624, 0.9619, 1.0381, 0.9517,
        0.9468, 0.8691, 1.0127, 0.9243, 0.9990, 0.9990, 0.9341, 0.9688, 1.0107,
        0.9976, 1.0908, 0.9424, 0.9390, 1.0664, 1.0332, 0.8467, 1.0049, 0.9102,
        0.9800, 0.9448, 1.0059, 0.9585, 0.9199, 0.8076, 0.9604, 0.9268, 0.9878,
        1.0156, 0.9946, 0.9111, 0.9849, 0.8267, 0.7188, 1.0254, 1.0020, 0.9819,
        0.9873, 1.0146, 1.0215, 0.9712, 0.9683, 0.8555, 0.9678, 1.0635, 0.9990,
        1.0273, 1.0166, 0.9873, 1.0332, 0.9287, 0.8940, 1.0518, 0.9922, 0.9712,
        1.0234, 0.9473, 0.9595, 0.9663, 0.9351, 0.9741, 1.0352, 0.9609, 0.9658,
        0.9966, 1.0000, 0.9854, 0.9502, 0.9072, 1.0078, 1.0078, 1.0459, 0.9834,
        1.0234, 0.9980, 1.0420, 0.7686, 0.9453, 0.9834, 0.8628, 1.0449, 0.9512,
        1.0410, 0.9585, 0.9805, 1.0381, 0.9893, 1.0039, 1.0068, 1.0879, 0.9897,
        0.9937, 0.9565, 1.0420, 1.0146, 0.9961, 1.0322, 1.0566, 0.9272, 1.0068,
        0.9951, 0.9365, 1.0527, 0.9849, 0.8970, 1.0312, 0.9189, 1.0273, 1.0674,
        0.9604, 1.0527, 0.9033, 0.9834, 1.0186, 0.8081, 0.9668, 0.9404, 0.9180,
        1.0049, 0.9712, 0.9858, 0.9985, 1.0186, 0.9414, 1.0469, 0.9658, 0.9980,
        0.9707, 0.8994, 1.0029, 1.0225, 1.0518], device='cuda:0',
       dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([-7.8674e-02, -3.8574e-02,  8.9188e-03, -8.1909e-02, -7.9529e-02,
        -1.8845e-02,  1.3641e-02, -3.6591e-02, -7.0381e-04, -4.0466e-02,
        -4.9103e-02, -4.4312e-02,  1.8759e-03, -4.0344e-02, -3.6438e-02,
        -4.1473e-02, -4.5868e-02, -3.5004e-02, -3.5492e-02, -3.3386e-02,
        -1.7883e-02, -2.3209e-02, -3.2166e-02, -2.6093e-02, -3.0838e-02,
        -3.6377e-02, -2.5848e-02, -2.4353e-02, -4.5853e-03, -4.2206e-02,
        -6.6284e-02, -6.3477e-03, -1.0040e-02,  7.6141e-03, -2.2278e-02,
        -6.7940e-03, -2.0126e-02, -4.2603e-02, -2.6596e-02, -2.8854e-02,
        -3.9459e-02, -1.5516e-03, -4.6356e-02, -1.5556e-02, -3.1311e-02,
        -3.8879e-02, -4.2419e-02, -4.5502e-02, -5.8502e-02, -1.7822e-02,
        -4.2358e-02,  1.0284e-02, -4.7424e-02, -3.7109e-02, -4.2908e-02,
        -1.1383e-02, -4.9500e-02, -4.2053e-02, -2.3636e-02, -1.9257e-02,
        -5.0079e-02, -4.1901e-02, -5.4077e-02, -3.4332e-02, -5.0507e-02,
        -5.4779e-02, -8.4656e-02, -2.5726e-02, -4.9591e-02, -2.5635e-02,
        -9.4299e-02, -4.4403e-02, -2.7405e-02, -6.0089e-02, -6.9580e-02,
        -4.0405e-02, -4.6143e-02, -4.0527e-02, -4.1351e-02, -4.8035e-02,
        -1.9730e-02, -4.6722e-02, -4.7821e-02, -3.9215e-02, -4.9438e-02,
        -7.2998e-02, -4.2297e-02, -6.1676e-02, -5.4657e-02, -4.9469e-02,
        -1.7853e-02, -5.2856e-02, -9.2316e-03, -5.0049e-02, -9.9792e-03,
        -9.1309e-02, -3.8147e-02, -8.3252e-02, -2.5467e-02, -6.6895e-02,
        -2.9480e-02, -3.8940e-02, -3.2898e-02, -6.0455e-02, -3.7109e-02,
        -8.2092e-02, -4.8523e-02, -5.7922e-02, -2.7802e-02, -1.8646e-02,
        -3.0640e-02, -5.5115e-02, -3.8300e-02, -4.8615e-02, -4.0527e-02,
        -6.6467e-02, -1.3855e-02, -6.5796e-02, -2.2079e-02, -7.4402e-02,
        -4.6112e-02, -4.6814e-02, -2.7969e-02, -2.2491e-02, -1.5312e-02,
        -4.2267e-02, -1.9592e-02, -2.1500e-02, -5.7907e-03, -7.0618e-02,
        -5.8105e-02, -5.0323e-02, -1.8967e-02, -5.6488e-02, -3.2227e-02,
        -3.2776e-02, -2.5925e-02, -3.5248e-02, -1.7395e-02, -2.7176e-02,
        -2.4612e-02, -9.0332e-02, -3.4576e-02, -7.0068e-02, -2.0294e-02,
        -7.2876e-02, -2.2598e-02, -2.5375e-02, -4.7852e-02, -6.5063e-02,
        -2.9861e-02, -7.2571e-02, -5.0629e-02, -2.0264e-02, -1.2871e-02,
        -1.2901e-02, -2.9892e-02, -7.1899e-02, -7.7896e-03, -3.0350e-02,
        -4.1779e-02, -5.2704e-02, -3.4149e-02, -6.2378e-02, -2.9114e-02,
        -4.6509e-02, -5.7770e-02, -3.2532e-02, -2.4231e-02, -8.8806e-03,
        -3.7811e-02, -4.4189e-02, -3.5278e-02, -1.1865e-01, -3.4180e-02,
        -6.2103e-02, -3.6102e-02, -3.7140e-02, -2.1622e-02, -8.0322e-02,
        -2.0248e-02, -4.3762e-02, -8.5831e-03, -1.0413e-01, -2.5314e-02,
        -6.8787e-02, -1.7365e-02, -5.3253e-02,  2.8801e-03, -5.8136e-02,
        -4.9622e-02, -6.4758e-02, -3.2532e-02, -4.4220e-02, -3.6926e-02,
        -7.1350e-02, -3.4332e-02, -5.6915e-02, -2.1851e-02, -7.1167e-02,
        -6.3293e-02, -4.3091e-02, -3.4698e-02, -6.5491e-02, -6.6223e-02,
        -3.5339e-02,  3.6602e-03, -1.0217e-01, -2.1347e-02, -4.3793e-02,
        -2.6978e-02, -6.8237e-02, -8.2642e-02, -4.9316e-02, -1.0796e-02,
        -6.1890e-02, -1.4244e-02, -5.2185e-02, -5.2826e-02, -3.8361e-02,
        -4.8157e-02, -1.0864e-01, -1.7868e-02, -3.5614e-02, -1.9073e-02,
        -2.6901e-02, -1.4366e-02, -5.6549e-02, -2.8900e-02, -3.8513e-02,
        -5.7465e-02, -4.8126e-02, -1.1292e-02, -5.0385e-02, -3.4058e-02,
        -6.1157e-02, -7.4053e-04, -5.2704e-02, -4.8126e-02, -2.1027e-02,
        -2.1729e-02, -5.7220e-02, -2.4963e-02, -7.4890e-02,  2.6035e-03,
        -6.0242e-02, -1.9577e-02, -2.3438e-02, -8.3008e-03, -4.9652e-02,
        -3.7109e-02, -4.9591e-02, -2.0279e-02, -5.3833e-02, -1.6220e-02,
        -5.2368e-02, -2.5894e-02, -4.1534e-02, -2.3422e-02, -3.9368e-02,
         2.8789e-05, -5.1636e-02, -5.5298e-02, -7.2876e-02, -8.0750e-02,
        -9.5444e-03, -1.9409e-02, -7.5256e-02, -4.3610e-02, -1.3687e-02,
        -2.8931e-02, -2.9663e-02, -2.8687e-02, -7.6782e-02, -1.7929e-02,
        -5.0903e-02, -2.5192e-02, -7.9712e-02, -3.8879e-02, -6.2927e-02,
        -2.7695e-02, -5.6854e-02, -3.3997e-02, -5.1331e-02, -3.3630e-02,
        -6.4270e-02, -5.0293e-02, -6.3049e-02, -5.3802e-02, -3.9001e-02,
        -3.6926e-02, -8.3557e-02, -3.5522e-02, -6.0944e-02, -5.8075e-02,
        -5.4932e-02, -6.4735e-03, -4.9927e-02, -2.8717e-02, -3.2063e-03,
        -5.5122e-03, -6.8481e-02, -8.4473e-02, -3.4332e-02, -3.6835e-02,
        -2.0996e-02, -2.6642e-02, -7.0923e-02, -2.8214e-02, -4.6661e-02,
        -2.5284e-02, -1.4999e-02, -5.3436e-02, -4.7363e-02, -2.5742e-02,
        -2.4155e-02, -9.3536e-03, -5.8350e-02, -2.1835e-02, -7.0679e-02],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[-1.1314e-02,  5.9090e-03, -1.3452e-01,  ..., -4.9210e-03,
          8.1360e-02, -3.7289e-03],
        [-4.2992e-03, -1.2260e-02, -3.1174e-02,  ..., -1.7685e-02,
         -3.3722e-02, -4.6875e-02],
        [ 9.7961e-02, -2.7496e-02,  1.0632e-01,  ..., -6.0120e-02,
         -1.1414e-01, -6.2256e-02],
        ...,
        [ 7.5150e-03, -1.5900e-02,  6.3904e-02,  ...,  9.7733e-03,
         -3.5400e-02,  1.7047e-05],
        [-2.7695e-02,  7.9102e-02, -3.1235e-02,  ..., -8.6426e-02,
         -6.8298e-02,  7.8964e-03],
        [-8.1421e-02,  1.9775e-02, -1.0260e-01,  ...,  2.6566e-02,
          2.0538e-02, -1.9180e-02]], device='cuda:0', dtype=torch.float16,
       requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[ 0.0055,  0.0952, -0.0450,  ...,  0.0841,  0.0357,  0.0018],
        [-0.0106, -0.0135, -0.0240,  ...,  0.0125, -0.0611, -0.0699],
        [ 0.0033, -0.0367,  0.0088,  ...,  0.0051,  0.0612,  0.0235],
        ...,
        [ 0.0015,  0.0421, -0.0041,  ...,  0.0319,  0.0135, -0.0435],
        [-0.0173,  0.0176, -0.0045,  ..., -0.0080,  0.1152,  0.0187],
        [ 0.0035, -0.0285, -0.0311,  ..., -0.0498,  0.0869, -0.0226]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[ 0.0026,  0.0199,  0.0042,  ..., -0.0049,  0.0401, -0.0140],
        [-0.0071,  0.0059, -0.0184,  ..., -0.0400,  0.0258,  0.0018],
        [-0.0010, -0.0576,  0.0191,  ...,  0.0252,  0.0248, -0.0201],
        ...,
        [-0.0083,  0.0060,  0.0151,  ..., -0.0037, -0.0737,  0.0142],
        [ 0.0120,  0.0175, -0.0118,  ..., -0.0514,  0.0215,  0.0542],
        [-0.0623, -0.0072,  0.0359,  ..., -0.0350, -0.0543, -0.0032]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[-0.0119,  0.0642, -0.0302,  ...,  0.0312, -0.0111, -0.0559],
        [-0.0130,  0.0165,  0.0662,  ..., -0.0220, -0.0779, -0.0081],
        [ 0.0402,  0.0038, -0.0355,  ...,  0.0194, -0.0089, -0.0809],
        ...,
        [ 0.0050,  0.0434,  0.0186,  ..., -0.0296, -0.0190,  0.0209],
        [ 0.0118, -0.0067,  0.0089,  ...,  0.0728, -0.0359,  0.1211],
        [ 0.0126,  0.0312,  0.0028,  ...,  0.0284,  0.0153, -0.0460]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([-0.0169,  0.0131, -0.0414, -0.0196,  0.0132,  0.0157, -0.0358, -0.0026,
        -0.0199, -0.0290, -0.0527, -0.0367,  0.0086,  0.0120,  0.0229, -0.0389,
        -0.0092,  0.0071, -0.0562,  0.0259, -0.0110, -0.0041, -0.0190, -0.0373,
         0.0388, -0.0105, -0.0415, -0.0003,  0.0066, -0.0119, -0.0095, -0.0090,
         0.0107,  0.0098,  0.0065, -0.0082,  0.0144, -0.0340, -0.0289,  0.0213,
        -0.0252,  0.0142,  0.0049,  0.0050,  0.0296,  0.0108,  0.0198, -0.0056,
         0.0425, -0.0127, -0.0417, -0.0421, -0.0551,  0.0316,  0.0218, -0.0067,
         0.0342,  0.0154, -0.0239, -0.0298, -0.0089,  0.0325,  0.0305,  0.0041,
        -0.0022,  0.0178,  0.0382, -0.0479,  0.0121,  0.0188,  0.0082, -0.0406,
         0.0137, -0.0054,  0.0076, -0.0358, -0.0189,  0.0249,  0.0065, -0.0229,
         0.0363,  0.0182, -0.0042, -0.0024, -0.0264,  0.0355, -0.0287,  0.0359,
        -0.0331,  0.0115,  0.0344, -0.0272,  0.0378, -0.0233, -0.0166,  0.0127,
         0.0053,  0.0854, -0.0295,  0.0014, -0.0082,  0.0070, -0.0408,  0.0045,
        -0.0203,  0.0386,  0.0114, -0.0233, -0.0267,  0.0374,  0.0178,  0.0377,
         0.0166, -0.0186, -0.0571, -0.0094, -0.0341, -0.0094, -0.0269, -0.0332,
        -0.0277,  0.0508, -0.0247,  0.0420,  0.0238,  0.0005, -0.0557,  0.0517,
        -0.0154,  0.0519, -0.0185,  0.0501,  0.0296,  0.0147, -0.0350, -0.0341,
         0.0185, -0.0072,  0.0496,  0.0105,  0.0262,  0.0113, -0.0594,  0.0454,
         0.0111,  0.0398, -0.0261,  0.0728, -0.0142, -0.0010, -0.0093, -0.0294,
         0.0270,  0.0197,  0.0193,  0.0069,  0.0053, -0.0553, -0.0448,  0.0183,
        -0.0381, -0.0153,  0.0126, -0.0201, -0.0060,  0.0279,  0.0388,  0.0208,
        -0.0534, -0.0009,  0.0288,  0.0493,  0.0461,  0.0113, -0.0032,  0.0001,
        -0.0179, -0.0242, -0.0176, -0.0467, -0.0466,  0.0317,  0.0221,  0.0538,
        -0.0202, -0.0139,  0.0118,  0.0576,  0.0330,  0.0555,  0.0012,  0.0212,
         0.0265,  0.0466, -0.0514,  0.0283,  0.0007,  0.0229, -0.0264,  0.0284,
        -0.0331,  0.0596, -0.0532,  0.0587, -0.0693, -0.0267,  0.0102,  0.0035,
        -0.0271, -0.0139, -0.0299,  0.0144, -0.0356,  0.0608, -0.0301, -0.0224,
         0.0196, -0.0028, -0.0026,  0.0265,  0.0024,  0.0726,  0.0131,  0.0228,
        -0.0281, -0.0024,  0.0029, -0.0057,  0.0107,  0.0011,  0.0091, -0.0679,
         0.0277,  0.0199, -0.0266,  0.0271, -0.0490,  0.0551,  0.0291,  0.0013,
        -0.0328,  0.0493,  0.0135,  0.0288, -0.0158, -0.0200,  0.0107,  0.0082,
         0.0135,  0.0037,  0.0040, -0.0057,  0.0055,  0.0002, -0.0230, -0.0341,
        -0.0563,  0.0334, -0.0094, -0.0105, -0.0218, -0.0161, -0.0303, -0.0068,
         0.0472, -0.0026,  0.0238, -0.0067, -0.0285,  0.0176, -0.0352,  0.0264,
         0.0285, -0.0155, -0.0250,  0.0052, -0.0294,  0.0335,  0.0113,  0.0548,
        -0.0034,  0.0551,  0.0127,  0.0220, -0.0131,  0.0289,  0.0051, -0.0100,
        -0.0063,  0.0175,  0.0291,  0.0360, -0.0234, -0.0029, -0.0120,  0.0368,
        -0.0125, -0.0023,  0.0278, -0.0385, -0.0204,  0.0564, -0.0055,  0.0024,
         0.0320,  0.0061,  0.0231,  0.0233, -0.0239, -0.0242, -0.0300, -0.0089,
         0.0199, -0.0349, -0.0002,  0.0341,  0.0182, -0.0072, -0.0357,  0.0152],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([1.0625, 1.0664, 0.8667, 0.8252, 0.8213, 1.0039, 0.7749, 1.0449, 1.0498,
        0.8892, 1.0459, 1.0049, 0.9678, 1.0225, 1.0146, 0.9736, 1.1045, 0.9775,
        1.0430, 1.0596, 0.9448, 1.0479, 1.0576, 1.0146, 0.9736, 1.0742, 1.0166,
        1.0088, 0.9907, 1.0186, 1.0508, 0.9385, 0.9541, 0.9858, 1.0039, 0.9834,
        0.9902, 1.0303, 0.9976, 0.9106, 1.0371, 1.0439, 1.0156, 1.0615, 0.9824,
        1.0557, 1.0791, 0.9092, 0.9785, 1.0479, 0.9937, 1.0322, 1.0303, 1.0234,
        0.9990, 0.9946, 1.0430, 0.9429, 0.9570, 1.0215, 1.0166, 1.0254, 1.0254,
        1.0371, 1.0098, 1.0518, 1.0117, 0.9751, 1.0049, 1.0000, 0.8677, 1.1055,
        1.0361, 1.0449, 0.9976, 0.9268, 1.0547, 1.0264, 1.0664, 1.0195, 1.0127,
        0.9863, 1.0283, 1.0137, 1.0342, 0.9878, 1.0049, 1.0488, 0.9712, 1.0195,
        0.9351, 0.9600, 1.0137, 0.9595, 0.9346, 0.8027, 1.0674, 0.8384, 1.1338,
        1.0225, 1.0078, 1.0332, 1.0400, 1.0312, 0.9932, 1.0635, 1.1152, 1.0420,
        1.0742, 1.0293, 1.0371, 0.9741, 1.0850, 1.0801, 1.0410, 0.9614, 1.0791,
        1.0371, 1.0225, 1.0645, 1.0420, 1.0254, 1.0254, 0.9707, 1.0195, 1.0088,
        0.9951, 1.0068, 1.0957, 1.0410, 1.0049, 1.0049, 0.9995, 0.9697, 1.0234,
        0.9878, 1.0850, 0.9429, 1.0391, 0.9810, 1.0049, 0.9741, 1.0625, 1.0752,
        1.0967, 1.0889, 1.0332, 0.9873, 1.0811, 1.1182, 0.9575, 1.0225, 1.0020,
        0.8848, 1.0137, 0.9292, 0.9600, 0.9790, 1.1016, 1.0635, 1.0205, 0.9248,
        0.9946, 0.9956, 1.0771, 1.0645, 1.0713, 1.0508, 0.9941, 0.7993, 1.0391,
        1.0225, 0.9604, 1.0293, 1.0352, 0.9834, 0.9546, 0.9570, 0.9907, 1.0381,
        1.0293, 1.0234, 1.0918, 0.8491, 1.0049, 0.9980, 1.0498, 0.9551, 1.0361,
        0.9497, 0.9775, 0.9453, 0.9634, 1.0322, 0.9692, 0.9941, 0.9790, 0.9824,
        1.0400, 0.9971, 0.9663, 1.0273, 0.9922, 1.0615, 1.0146, 0.9800, 0.9551,
        0.9595, 0.9961, 1.0068, 1.0625, 0.9814, 0.8296, 0.9668, 0.9995, 1.0273,
        0.9834, 0.9766, 0.9551, 0.9893, 0.8706, 0.7441, 1.0381, 0.9805, 1.0801,
        1.0254, 1.0840, 0.9546, 1.0049, 1.0830, 0.8945, 0.8643, 1.0225, 0.9927,
        1.0156, 1.0107, 1.0195, 0.9580, 1.0713, 0.8945, 1.0322, 1.0029, 0.9580,
        0.9922, 1.0254, 0.9458, 1.0449, 0.9697, 1.0195, 1.0674, 1.0107, 1.0361,
        1.0205, 0.9956, 1.0576, 1.0889, 0.9941, 1.0449, 1.0020, 1.0186, 1.0195,
        1.1211, 0.9844, 1.1035, 0.7646, 0.8906, 1.0400, 0.8804, 0.9795, 0.8804,
        1.0400, 1.0889, 0.9624, 0.9561, 1.0654, 1.0156, 1.0166, 0.9424, 1.0312,
        1.0186, 0.9702, 1.0723, 1.0889, 1.0576, 1.0010, 0.9795, 1.0527, 0.9438,
        1.0898, 0.9858, 0.9883, 0.9653, 0.9424, 0.9956, 1.0410, 1.1055, 1.0723,
        1.0020, 1.0303, 0.9097, 1.0518, 0.9395, 0.7896, 1.0283, 1.0205, 1.0605,
        0.9878, 0.9648, 0.9448, 0.9810, 1.0254, 1.1240, 1.0898, 0.9995, 1.0664,
        0.9966, 1.0605, 0.9663, 1.0664, 1.0771], device='cuda:0',
       dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([ 0.0728,  0.0750,  0.0533, -0.0417, -0.0323,  0.0374,  0.0678,  0.0525,
        -0.0720,  0.0066, -0.0712, -0.0502, -0.0534, -0.0046, -0.0056,  0.0470,
        -0.0397, -0.0055, -0.0558,  0.1064,  0.0332,  0.1181, -0.0732, -0.1163,
        -0.0118,  0.1083, -0.0535, -0.0028, -0.0297, -0.0903, -0.0434, -0.0113,
         0.1024,  0.0121, -0.0341,  0.0266, -0.0427,  0.0928, -0.0092, -0.0603,
        -0.0319, -0.0467, -0.0096, -0.0511,  0.0483,  0.0182,  0.1228, -0.0309,
         0.0648,  0.0670, -0.1619, -0.1053, -0.0143,  0.0180, -0.0014,  0.0096,
        -0.0352, -0.0387,  0.0014, -0.0392,  0.0886,  0.0313, -0.0532, -0.0237,
         0.0551, -0.0452,  0.0683,  0.0021, -0.0679, -0.0575, -0.0057, -0.0510,
        -0.0564,  0.0212,  0.1085,  0.0315, -0.0127,  0.0104, -0.0022,  0.1033,
        -0.0194,  0.0109,  0.0479,  0.0550,  0.1092,  0.0079,  0.0187, -0.0122,
         0.0526,  0.0243,  0.0188,  0.0162, -0.0178,  0.0383, -0.0320, -0.0444,
         0.0233, -0.0581, -0.0920,  0.0667,  0.0152, -0.0464,  0.0562,  0.0252,
         0.0660,  0.1475, -0.0306,  0.0412,  0.0564,  0.0549, -0.0762,  0.0170,
         0.0410, -0.0193, -0.0405,  0.0489, -0.0999,  0.1213, -0.0473, -0.0207,
         0.0507,  0.0540, -0.0324,  0.0074, -0.0461, -0.0485, -0.0265, -0.0220,
        -0.0869,  0.0707,  0.0648,  0.0338,  0.0195,  0.0815, -0.0242, -0.0164,
         0.1013, -0.0100,  0.0315, -0.0296, -0.0422,  0.1002, -0.0520,  0.0570,
        -0.1058,  0.0086, -0.0293,  0.0821,  0.0645, -0.0760,  0.0425,  0.0621,
        -0.0099,  0.0537, -0.0761, -0.0193,  0.0458,  0.0343, -0.0936, -0.0651,
         0.0010,  0.0204, -0.0210, -0.0003, -0.0387, -0.0614,  0.0352,  0.0823,
         0.0177,  0.0226,  0.0649,  0.1147,  0.0082,  0.0704, -0.0158,  0.0844,
        -0.0153, -0.0442, -0.0657, -0.1095,  0.0039, -0.0117, -0.0999, -0.0423,
         0.0186, -0.0348,  0.0159,  0.0372, -0.0793, -0.0048,  0.0552,  0.0464,
         0.0088,  0.0472, -0.0188, -0.0055,  0.0570,  0.0396,  0.0061,  0.0890,
         0.0039,  0.0933, -0.0431,  0.0961,  0.0892,  0.0234,  0.0570,  0.1028,
        -0.0245,  0.0391,  0.0511,  0.0203, -0.1144, -0.0254,  0.0508,  0.0602,
         0.0186,  0.0798, -0.0803,  0.0368, -0.0316, -0.1052,  0.0874, -0.0064,
         0.0501, -0.0095,  0.1021, -0.0495, -0.0302,  0.1157,  0.0015,  0.0803,
         0.0163,  0.0126, -0.0594,  0.0358, -0.0249,  0.0974,  0.0622, -0.0175,
         0.0548,  0.0539,  0.0473,  0.0694, -0.0572, -0.0079, -0.1277,  0.0135,
        -0.0427, -0.0464, -0.0051,  0.1442,  0.0103, -0.0562,  0.0259, -0.0897,
        -0.0086, -0.0207, -0.0967,  0.0271, -0.0245, -0.0239, -0.0518,  0.0423,
        -0.0800,  0.0180, -0.0022, -0.0312, -0.0363, -0.0145,  0.1149,  0.0920,
        -0.0704,  0.0726,  0.0276,  0.0482, -0.0082,  0.0428,  0.0468,  0.0852,
        -0.0050,  0.0234,  0.0955,  0.0995, -0.0145, -0.0571, -0.0168,  0.0236,
         0.0370, -0.0317,  0.0711,  0.0723,  0.0334,  0.0314,  0.0581, -0.0517,
        -0.0449,  0.0563,  0.0698,  0.0103, -0.0335,  0.0014, -0.0007, -0.0456,
         0.0211, -0.0812,  0.0468,  0.0135,  0.0207,  0.0385, -0.0980, -0.1097,
         0.0734, -0.0153,  0.0189, -0.0401, -0.0657,  0.0994, -0.0671,  0.0635],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[ 0.0377,  0.0149,  0.0145,  ..., -0.0534, -0.0385,  0.0082],
        [-0.0555,  0.0306,  0.0231,  ...,  0.0182,  0.0050, -0.0386],
        [ 0.0323, -0.0580,  0.0365,  ..., -0.0233,  0.0807,  0.0420],
        ...,
        [-0.0490, -0.0142, -0.0433,  ..., -0.0135,  0.0268,  0.0252],
        [ 0.0319,  0.0034, -0.0136,  ..., -0.0164,  0.0225, -0.0117],
        [ 0.0046,  0.0079, -0.0395,  ..., -0.0017,  0.0085, -0.0083]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([ 0.0468, -0.0148,  0.0184,  ...,  0.0035,  0.0119,  0.0522],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[-0.0108,  0.0084, -0.0343,  ..., -0.0233, -0.0174, -0.0405],
        [ 0.0334, -0.0200, -0.0103,  ..., -0.0267,  0.0072, -0.0342],
        [-0.0070,  0.0389,  0.0707,  ...,  0.0372, -0.0339,  0.0489],
        ...,
        [ 0.0258,  0.0418, -0.0534,  ..., -0.0458,  0.0385, -0.0875],
        [-0.0052,  0.0186, -0.0135,  ...,  0.0172, -0.0268, -0.0691],
        [-0.0026, -0.0227, -0.0245,  ...,  0.0038, -0.0108, -0.1225]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([ 0.0779, -0.0533, -0.0052,  0.0503,  0.1226,  0.0421,  0.0342,  0.0237,
        -0.0305,  0.0527,  0.0489, -0.0072,  0.0088,  0.0516,  0.0435,  0.0321,
         0.0029, -0.0522, -0.0257,  0.0033,  0.0067, -0.0317, -0.0664, -0.0266,
         0.0019,  0.0283, -0.0470, -0.0004, -0.0167, -0.0735, -0.0056, -0.0201,
        -0.0104, -0.0291,  0.0061, -0.0339, -0.0572,  0.0385, -0.0724,  0.0329,
        -0.0085, -0.0486,  0.0143,  0.0549,  0.0410, -0.0715,  0.0404,  0.0773,
         0.0028,  0.0906, -0.0007, -0.0940, -0.0435,  0.0417,  0.0490,  0.0280,
        -0.0053,  0.0684, -0.0518, -0.0471,  0.0685,  0.0395, -0.0364, -0.0296,
        -0.0507, -0.0587,  0.0773, -0.1025, -0.0149, -0.0148,  0.0561, -0.0313,
        -0.0465, -0.0033, -0.0613, -0.0324, -0.0434,  0.0684,  0.0656,  0.0474,
        -0.0060, -0.0651,  0.0211, -0.0586,  0.0141,  0.0253, -0.0094, -0.0315,
         0.0684,  0.0170, -0.0538,  0.0057, -0.0182,  0.0246,  0.0209,  0.0660,
         0.0133,  0.0341, -0.0765, -0.0018, -0.0208, -0.0157, -0.0113,  0.0092,
         0.0059,  0.0515, -0.0046,  0.0750, -0.0244,  0.0235, -0.0460, -0.0178,
         0.0174,  0.0492, -0.0784,  0.0710, -0.0221,  0.0078, -0.0751, -0.0650,
         0.0139,  0.0176, -0.0073, -0.1057,  0.0107,  0.0514, -0.0344, -0.0165,
        -0.0003, -0.0074, -0.0194, -0.0286,  0.0537,  0.0545,  0.0291, -0.0077,
        -0.0302, -0.0716, -0.0287, -0.0126, -0.0843,  0.0112, -0.0446,  0.0845,
        -0.0300, -0.0371,  0.0059,  0.0038, -0.0341, -0.0119,  0.0430, -0.0327,
         0.0372, -0.0869,  0.0055, -0.0287,  0.0529,  0.0063, -0.0423, -0.0273,
        -0.0246, -0.0110, -0.0496,  0.0083, -0.0740, -0.0234, -0.0142, -0.0031,
        -0.0173, -0.0186,  0.0764, -0.0263,  0.0564, -0.0242,  0.0206, -0.0103,
         0.0197, -0.0192,  0.0947, -0.0630,  0.0424,  0.0592,  0.0225, -0.0046,
         0.0419,  0.0206,  0.0052,  0.0716, -0.0305,  0.0247,  0.0511, -0.0676,
         0.0104, -0.0302, -0.0634,  0.0063,  0.0506,  0.0286, -0.0356,  0.0239,
         0.0536, -0.0122, -0.0934,  0.0762,  0.0111, -0.0592, -0.0101,  0.0180,
        -0.0344,  0.0045,  0.0192,  0.0312,  0.0626,  0.0109,  0.0435,  0.0248,
        -0.0535,  0.0037,  0.0197,  0.0417,  0.0357,  0.0443, -0.0490, -0.0192,
         0.0016, -0.0687,  0.0428, -0.0325, -0.0278,  0.0164,  0.0349, -0.0443,
        -0.0069,  0.0076, -0.0022, -0.0334, -0.0502,  0.0437,  0.0635, -0.0708,
        -0.0005, -0.0066,  0.0005,  0.0801, -0.0692,  0.0060,  0.0010, -0.0474,
        -0.0691, -0.0188,  0.0471,  0.0261, -0.0066, -0.0596, -0.0063, -0.0457,
        -0.0848, -0.0064,  0.0226, -0.0405,  0.0003,  0.0073,  0.0354,  0.0382,
         0.0024, -0.0498, -0.0049,  0.0762, -0.0212, -0.0858,  0.0378,  0.0490,
        -0.0299,  0.0235, -0.0214, -0.0049,  0.0118, -0.0036,  0.0369,  0.0316,
        -0.0187,  0.0329,  0.0420,  0.0002,  0.0445, -0.0893, -0.0171, -0.0185,
        -0.0202, -0.0751,  0.0469,  0.0367,  0.0183,  0.0700,  0.0603,  0.0339,
        -0.0399,  0.0278,  0.0433, -0.0205, -0.1167, -0.0002,  0.0798, -0.0739,
         0.0171, -0.0638,  0.0679,  0.0667,  0.0219, -0.0007, -0.0139,  0.0521,
        -0.0799, -0.0621, -0.0252,  0.0014, -0.0540, -0.0255,  0.0193,  0.0110],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[-0.0620,  0.0465, -0.0141,  ...,  0.0278, -0.0221, -0.0581],
        [ 0.0105, -0.0133,  0.0071,  ...,  0.0039,  0.0350, -0.0265],
        [ 0.0277,  0.0466, -0.0560,  ...,  0.0722,  0.0443,  0.0407],
        ...,
        [ 0.0332,  0.0732, -0.0679,  ..., -0.0276, -0.0630,  0.0103],
        [ 0.0192, -0.0293, -0.0586,  ..., -0.0037, -0.0404, -0.0096],
        [-0.0665,  0.0244,  0.0023,  ...,  0.0081, -0.1102, -0.0137]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([-0.0131, -0.0121, -0.0035, -0.0225, -0.0246,  0.0039,  0.0089, -0.0316,
        -0.0210, -0.0127, -0.0079,  0.0213, -0.0161,  0.0354,  0.0452, -0.0477,
        -0.0284,  0.0853, -0.0226, -0.0465, -0.0032, -0.0116,  0.0045,  0.0448,
        -0.0737,  0.0171, -0.0016, -0.0133, -0.0381, -0.0148, -0.0545, -0.0551,
         0.0582, -0.0122, -0.0157,  0.0403,  0.0063, -0.0453,  0.0106, -0.0312,
         0.0153, -0.0139, -0.0042,  0.0439, -0.0115,  0.0073,  0.0251,  0.0469,
         0.0195,  0.0309,  0.0094,  0.0083,  0.0541, -0.0272, -0.0031,  0.0400,
        -0.0603, -0.0019, -0.0290,  0.0173,  0.0939, -0.0040,  0.0188,  0.0353,
         0.0117, -0.0153, -0.0225,  0.0408,  0.0105, -0.0273,  0.0053,  0.0770,
         0.0147,  0.0186,  0.0199,  0.0137,  0.0430,  0.0251,  0.0151,  0.0027,
         0.0080,  0.0155, -0.0315, -0.0467, -0.0368, -0.0325,  0.0172, -0.0325,
         0.0027, -0.0275, -0.0125, -0.0229, -0.0293,  0.0113, -0.0110,  0.0472,
         0.0320,  0.0144,  0.0116,  0.0154,  0.0037, -0.0148, -0.0320,  0.0024,
         0.0250,  0.0055,  0.0064,  0.0648,  0.0282, -0.0099, -0.0096,  0.0060,
        -0.0209, -0.0261,  0.0025,  0.0274,  0.0431,  0.0380, -0.0159,  0.0320,
        -0.0038, -0.0243, -0.0544, -0.0459, -0.0381, -0.0209, -0.0335,  0.0342,
        -0.0427, -0.0316, -0.0141, -0.0606, -0.0283, -0.0229, -0.0411, -0.0525,
        -0.0392, -0.0119, -0.0220, -0.0144, -0.0410,  0.0363,  0.0412,  0.0297,
         0.0267,  0.0003,  0.0218,  0.0023,  0.0358,  0.0967,  0.0302,  0.0190,
         0.0106,  0.0294,  0.0435,  0.0272,  0.0308,  0.0124, -0.0076,  0.0590,
         0.0386,  0.0191, -0.0080,  0.0018,  0.0530,  0.0142,  0.0659,  0.0223,
        -0.0077, -0.0275, -0.0182,  0.0002,  0.0218,  0.0251,  0.0544,  0.0105,
        -0.0509, -0.0093,  0.0520, -0.0139, -0.0270,  0.0530,  0.0134,  0.0195,
        -0.0691,  0.0177, -0.0293,  0.0168,  0.0534, -0.0337, -0.0260,  0.0359,
         0.0438,  0.0551,  0.0051, -0.0358, -0.0084,  0.0186,  0.0102,  0.0139,
        -0.0085,  0.0075, -0.0790,  0.0816,  0.0263,  0.0039, -0.0272,  0.0580,
         0.0419,  0.0186, -0.0050,  0.0172, -0.0531, -0.0417,  0.0221, -0.0539,
        -0.0034, -0.0192, -0.0338,  0.0140, -0.0043, -0.0455, -0.0012, -0.0412,
        -0.0739,  0.0175, -0.0030, -0.0044, -0.0430, -0.0226, -0.0309, -0.0075,
         0.0734, -0.0602, -0.0241, -0.0164, -0.0006, -0.0199,  0.0189,  0.0219,
         0.0779,  0.0688,  0.0005,  0.0724,  0.0557,  0.0085, -0.0173, -0.0620,
        -0.0417,  0.0063, -0.0663, -0.0512, -0.0820, -0.0040, -0.0358,  0.0278,
        -0.0918,  0.0040, -0.0072, -0.0401, -0.0245, -0.0344, -0.0244, -0.0447,
        -0.0146,  0.0024, -0.0394, -0.0097, -0.0060, -0.0527,  0.0063, -0.0121,
        -0.0794, -0.0309,  0.0050,  0.0396, -0.0176,  0.0335, -0.0176, -0.0080,
         0.0061, -0.0055,  0.0105, -0.0004,  0.0402, -0.0009,  0.0247, -0.0262,
        -0.0105,  0.0020,  0.0156,  0.0442, -0.0043,  0.0215, -0.1064,  0.0368,
         0.0340,  0.0147,  0.0313, -0.0324, -0.0443, -0.0790, -0.0048, -0.0028,
        -0.0176,  0.0240, -0.0575, -0.0172, -0.0480,  0.0088, -0.0255, -0.0274,
        -0.0750, -0.0025, -0.0414, -0.0322,  0.0021, -0.0351, -0.0360, -0.0260],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([0.9258, 0.8169, 0.8989,  ..., 0.8232, 0.8457, 0.8867], device='cuda:0',
       dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([-0.0069,  0.0018, -0.0543,  ...,  0.0451, -0.0489, -0.0123],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[ 0.0371, -0.0226, -0.0656,  ..., -0.0634,  0.0076, -0.0097],
        [-0.0605,  0.0077, -0.0012,  ..., -0.0040,  0.0338,  0.0606],
        [-0.0216, -0.0494,  0.0378,  ..., -0.0080, -0.0038,  0.0164],
        ...,
        [ 0.0147,  0.0118,  0.0123,  ..., -0.0011,  0.0322, -0.0484],
        [ 0.0085,  0.0476, -0.0115,  ...,  0.0311, -0.0356,  0.0055],
        [-0.0227,  0.0372, -0.0334,  ...,  0.0205, -0.0349,  0.0103]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([ 0.0216,  0.0249,  0.0303,  ..., -0.0303,  0.0333, -0.0084],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([0.6875, 0.6636, 0.7334,  ..., 0.8750, 0.6396, 0.8862], device='cuda:0',
       dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([-0.1440, -0.1924, -0.1820,  ..., -0.1768, -0.2079, -0.1934],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[ 0.0158,  0.0079, -0.0120,  ..., -0.0017,  0.0091, -0.0094],
        [-0.0400, -0.0064, -0.0161,  ..., -0.0003, -0.0221, -0.0232],
        [-0.0161, -0.0085,  0.0090,  ..., -0.0062,  0.0034,  0.0116],
        ...,
        [-0.0389,  0.0342, -0.0042,  ..., -0.0201,  0.0101,  0.0087],
        [ 0.0206, -0.0111, -0.0052,  ...,  0.0017,  0.0156,  0.0003],
        [ 0.0292, -0.0206,  0.0234,  ...,  0.0191,  0.0022, -0.0155]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[ 0.0048, -0.0045,  0.0205,  ..., -0.0061,  0.0187,  0.0071],
        [ 0.0070, -0.0212,  0.0231,  ..., -0.0078,  0.0014, -0.0217],
        [ 0.0050,  0.0196, -0.0046,  ..., -0.0275,  0.0150,  0.0021],
        ...,
        [ 0.0211,  0.0044, -0.0053,  ..., -0.0207,  0.0146, -0.0183],
        [ 0.0073,  0.0154, -0.0075,  ..., -0.0208, -0.0139,  0.0329],
        [-0.0098, -0.0046, -0.0349,  ..., -0.0284, -0.0220,  0.0304]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[ 0.0100, -0.0084, -0.0037,  ...,  0.0161, -0.0121, -0.0031],
        [ 0.0041, -0.0288, -0.0160,  ..., -0.0209, -0.0360,  0.0091],
        [-0.0100,  0.0235,  0.0012,  ..., -0.0379, -0.0020,  0.0309],
        ...,
        [-0.0009, -0.0067, -0.0266,  ..., -0.0001,  0.0091,  0.0278],
        [ 0.0152, -0.0037,  0.0301,  ...,  0.0230, -0.0192,  0.0300],
        [ 0.0205, -0.0226, -0.0105,  ..., -0.0135,  0.0166,  0.0226]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[ 0.0024,  0.0188,  0.0066,  ..., -0.0019, -0.0084, -0.0197],
        [-0.0035, -0.0092,  0.0063,  ...,  0.0020, -0.0101, -0.0123],
        [-0.0163,  0.0172,  0.0006,  ...,  0.0121, -0.0126, -0.0156],
        ...,
        [-0.0116, -0.0330,  0.0157,  ..., -0.0281,  0.0154,  0.0132],
        [ 0.0016, -0.0045, -0.0168,  ..., -0.0159, -0.0199,  0.0041],
        [-0.0213,  0.0171,  0.0213,  ..., -0.0253, -0.0399,  0.0164]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([-0.0131, -0.0140,  0.0045,  ..., -0.0146,  0.0051, -0.0154],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([0.6919, 0.6416, 0.6860,  ..., 0.8765, 0.6724, 0.8765], device='cuda:0',
       dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([-0.1682, -0.1573, -0.1393,  ..., -0.2069, -0.1609, -0.1935],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[ 0.0081,  0.0051, -0.0195,  ...,  0.0262, -0.0106,  0.0298],
        [ 0.0403, -0.0533,  0.0272,  ...,  0.0144,  0.0143, -0.0154],
        [ 0.0493, -0.0149,  0.0351,  ...,  0.0124, -0.0268,  0.0056],
        ...,
        [-0.0232, -0.0106, -0.0061,  ...,  0.0081,  0.0063, -0.0198],
        [-0.0039, -0.0112,  0.0139,  ..., -0.0017, -0.0266, -0.0094],
        [-0.0162,  0.0037,  0.0234,  ..., -0.0066, -0.0155,  0.0090]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[-4.1695e-03, -2.1622e-02, -2.2827e-02,  ...,  1.7822e-02,
          8.3008e-03, -1.0605e-02],
        [-3.6011e-02, -4.8187e-02, -2.1038e-03,  ...,  2.2293e-02,
         -3.3913e-03,  7.6447e-03],
        [-6.2447e-03, -4.5204e-04, -2.1057e-02,  ...,  2.5894e-02,
          1.4153e-02, -2.9022e-02],
        ...,
        [-7.4387e-05, -3.0594e-02, -1.1063e-02,  ..., -2.7451e-02,
         -1.2238e-02, -4.2915e-03],
        [-1.0071e-02,  4.5013e-03, -1.3664e-02,  ..., -2.9049e-03,
         -9.6741e-03, -7.9269e-03],
        [-2.3788e-02, -1.4374e-02, -3.3600e-02,  ...,  2.3727e-03,
         -1.0254e-02, -7.4310e-03]], device='cuda:0', dtype=torch.float16,
       requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[ 0.0339,  0.0263,  0.0347,  ..., -0.0164, -0.0025, -0.0112],
        [ 0.0145,  0.0243, -0.0074,  ...,  0.0050, -0.0197,  0.0240],
        [ 0.0092, -0.0057,  0.0106,  ..., -0.0351, -0.0011,  0.0327],
        ...,
        [ 0.0242, -0.0191,  0.0107,  ..., -0.0090,  0.0135, -0.0075],
        [-0.0010, -0.0048,  0.0267,  ..., -0.0045, -0.0041,  0.0104],
        [ 0.0019,  0.0168,  0.0001,  ..., -0.0077,  0.0183, -0.0024]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[-0.0186,  0.0355, -0.0108,  ...,  0.0083,  0.0163, -0.0126],
        [-0.0289, -0.0064, -0.0096,  ...,  0.0240, -0.0264,  0.0516],
        [-0.0119, -0.0030,  0.0025,  ..., -0.0190, -0.0317, -0.0031],
        ...,
        [ 0.0076, -0.0211,  0.0080,  ...,  0.0417,  0.0177, -0.0046],
        [ 0.0092,  0.0210,  0.0028,  ...,  0.0176,  0.0027,  0.0001],
        [-0.0143, -0.0166,  0.0172,  ..., -0.0158, -0.0004, -0.0399]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([-0.0113, -0.0340, -0.0151,  ...,  0.0370, -0.0072,  0.0206],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([0.9634, 0.9492, 0.9707,  ..., 0.9678, 0.9834, 0.9468], device='cuda:0',
       dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([ 0.0161, -0.0118, -0.0278,  ...,  0.0480,  0.0257,  0.0231],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[-0.0321,  0.0017,  0.0313,  ...,  0.0134,  0.0030,  0.0065],
        [ 0.0098, -0.0278, -0.0156,  ...,  0.0007,  0.0287, -0.0366],
        [-0.0088, -0.0284,  0.0025,  ...,  0.0060,  0.0081,  0.0138],
        ...,
        [ 0.0485, -0.0051,  0.0337,  ..., -0.0277,  0.0161,  0.0148],
        [ 0.0116,  0.0006,  0.0075,  ..., -0.0287, -0.0491,  0.0016],
        [-0.0215, -0.0087, -0.0426,  ..., -0.0095, -0.0057, -0.0073]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([-0.0128,  0.0133, -0.0356,  ..., -0.0297,  0.0008, -0.0127],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[ 0.0065, -0.0050, -0.0119,  ..., -0.0010, -0.0016,  0.0116],
        [ 0.0130,  0.0157, -0.0011,  ..., -0.0023, -0.0148,  0.0621],
        [-0.0019,  0.0366, -0.0020,  ..., -0.0192,  0.0060, -0.0048],
        ...,
        [ 0.0105, -0.0051, -0.0051,  ...,  0.0159, -0.0083,  0.0242],
        [ 0.0121,  0.0181,  0.0080,  ...,  0.0019,  0.0225, -0.0020],
        [ 0.0090,  0.0219, -0.0025,  ..., -0.0055,  0.0060, -0.0147]],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([-0.0088, -0.0352, -0.0110,  ..., -0.0278, -0.0299,  0.0144],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Gradient for Parameter containing:
tensor([[-1.0719e-03,  7.1030e-03,  6.0310e-03,  ...,  1.4214e-02,
         -6.0822e-02,  1.9035e-03],
        [ 9.3460e-03, -3.0869e-02, -7.4768e-03,  ...,  2.1286e-02,
         -2.6474e-02, -3.6438e-02],
        [ 8.9493e-03, -1.7853e-02,  3.3813e-02,  ..., -1.3802e-02,
         -1.9669e-02, -3.7575e-03],
        ...,
        [ 6.3477e-03,  3.2074e-02, -2.9480e-02,  ...,  2.5749e-05,
         -2.5452e-02,  1.3702e-02],
        [-1.3885e-03, -4.6196e-03, -9.6054e-03,  ..., -1.3313e-02,
          8.6746e-03,  5.7129e-02],
        [ 8.4000e-03, -2.4887e-02, -6.5422e-03,  ...,  1.3855e-02,
          3.8624e-03,  2.0203e-02]], device='cuda:0', dtype=torch.float16,
       requires_grad=True) is not None
Gradient for Parameter containing:
tensor([ 0.0200,  0.0103, -0.0229,  ..., -0.0090, -0.0165, -0.0003],
       device='cuda:0', dtype=torch.float16, requires_grad=True) is not None
Traceback (most recent call last):
  File "/home/dreamyou070/Prun/tests/distill.py", line 591, in <module>
    main(args)
  File "/home/dreamyou070/Prun/tests/distill.py", line 490, in main
    scaler.unscale_(optimizer)  # gradients를 FP32로 변환
  File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/torch/amp/grad_scaler.py", line 338, in unscale_
    optimizer_state["found_inf_per_device"] = self._unscale_grads_(
  File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/torch/amp/grad_scaler.py", line 260, in _unscale_grads_
    raise ValueError("Attempting to unscale FP16 gradients.")
ValueError: Attempting to unscale FP16 gradients.
[rank0]: Traceback (most recent call last):
[rank0]:   File "/home/dreamyou070/Prun/tests/distill.py", line 591, in <module>
[rank0]:     main(args)
[rank0]:   File "/home/dreamyou070/Prun/tests/distill.py", line 490, in main
[rank0]:     scaler.unscale_(optimizer)  # gradients를 FP32로 변환
[rank0]:   File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/torch/amp/grad_scaler.py", line 338, in unscale_
[rank0]:     optimizer_state["found_inf_per_device"] = self._unscale_grads_(
[rank0]:   File "/home/dreamyou070/.conda/envs/venv_prun3/lib/python3.9/site-packages/torch/amp/grad_scaler.py", line 260, in _unscale_grads_
[rank0]:     raise ValueError("Attempting to unscale FP16 gradients.")
[rank0]: ValueError: Attempting to unscale FP16 gradients.
